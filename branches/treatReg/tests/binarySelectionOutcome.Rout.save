
R version 3.2.2 (2015-08-14) -- "Fire Safety"
Copyright (C) 2015 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> 
> options( digits = 3 )
> library( "sampleSelection" )
Loading required package: maxLik
Loading required package: miscTools

Please cite the 'maxLik' package as:
Henningsen, Arne and Toomet, Ott (2011). maxLik: A package for maximum likelihood estimation in R. Computational Statistics 26(3), 443-458. DOI 10.1007/s00180-010-0217-1.

If you have questions, suggestions, or comments regarding the 'maxLik' package, please use a forum or 'tracker' at maxLik's R-Forge site:
https://r-forge.r-project.org/projects/maxlik/
> set.seed(0)
>                            # Note: library() may change RNG state!
> 
> ## Leeman Lucas (and many others): binary outcome
> 
> N <- 500
> rho <- 0.7
> library( "mvtnorm" )
> eps <- rmvnorm(N, c(0,0), matrix(c(1,rho,rho,1), 2, 2) )
> simDat <- data.frame( xs = runif(N) )
> simDat$ysX <- 3 * simDat$xs + eps[,1]
> simDat$ys <- simDat$ysX > 0
> simDat$xo <- runif(N)
> simDat$yoX <- -1 + 2 * simDat$xo + eps[,2]
> simDat$yo <- factor( (simDat$yoX > 0) * (simDat$ys > 0))
>                            # binary outcome, only observable if ys>0
> print(table(simDat$ys, simDat$yo, exclude=NULL))
       
          0   1 <NA>
  FALSE  74   0    0
  TRUE  202 224    0
  <NA>    0   0    0
> 
> # estimation with BHHH method
> ss <- selection( ys ~ xs, yo ~ xo, data = simDat, steptol = 1e-12 )
> print( ss )

Call:
 selection(selection = ys ~ xs, outcome = yo ~ xo, data = simDat,      steptol = 1e-12) 

Coefficients:
S:(Intercept)           S:xs  O:(Intercept)           O:xo            rho  
       -0.122          3.329         -1.055          1.987          0.817  

> summary( ss )
--------------------------------------------
Tobit 2 model (sample selection model)
Maximum Likelihood estimation
BHHH maximisation, 6 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -398 
500 observations (74 censored and 426 observed)
5 free parameters (df = 495)
Probit selection equation:
            Estimate Std. error t value Pr(> t)    
(Intercept)   -0.122      0.130   -0.94    0.35    
xs             3.329      0.393    8.48  <2e-16 ***
Outcome equation:
            Estimate Std. error t value Pr(> t)    
(Intercept)   -1.055      0.121   -8.71  <2e-16 ***
xo             1.987      0.228    8.73  <2e-16 ***
   Error terms:
    Estimate Std. error t value Pr(> t)    
rho    0.817      0.141    5.77 7.8e-09 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
--------------------------------------------
> coef( ss )
S:(Intercept)           S:xs  O:(Intercept)           O:xo            rho  
       -0.122          3.329         -1.055          1.987          0.817  
> coef( ss, part = "outcome" )
(Intercept)           xo  
      -1.05         1.99  
> coef( summary( ss ) )
            Estimate Std. error t value  Pr(> t)
(Intercept)   -0.122      0.130  -0.944 3.45e-01
xs             3.329      0.393   8.476 2.32e-17
(Intercept)   -1.055      0.121  -8.713 2.95e-18
xo             1.987      0.228   8.727 2.61e-18
rho            0.817      0.141   5.772 7.81e-09
> coef( summary( ss ), part = "outcome" )
            Estimate Std. error t value  Pr(> t)
(Intercept)    -1.05      0.121   -8.71 2.95e-18
xo              1.99      0.228    8.73 2.61e-18
> stdEr( ss )
(Intercept)          xs (Intercept)          xo         rho 
      0.130       0.393       0.121       0.228       0.141 
> vcov( ss )
            (Intercept)       xs (Intercept)       xo       rho
(Intercept)     0.01681 -0.04000    0.001870 -0.00409  0.006358
xs             -0.04000  0.15422   -0.003141  0.01406 -0.015359
(Intercept)     0.00187 -0.00314    0.014652 -0.02269  0.000289
xo             -0.00409  0.01406   -0.022694  0.05186 -0.009832
rho             0.00636 -0.01536    0.000289 -0.00983  0.020017
> vcov( ss, part = "outcome" )
            (Intercept)      xo
(Intercept)      0.0147 -0.0227
xo              -0.0227  0.0519
> nobs( ss )
[1] 500
> nObs( ss )
[1] 500
> round( fitted( ss ), 3 )
    1     2     3     4     5     6     7     8     9    10    11    12    13 
0.338 0.496 0.182 0.737 0.415 0.818    NA 0.772 0.154 0.251 0.386 0.329 0.498 
   14    15    16    17    18    19    20    21    22    23    24    25    26 
0.653 0.800    NA 0.214 0.561 0.820 0.193 0.766 0.349 0.454 0.241 0.361 0.241 
   27    28    29    30    31    32    33    34    35    36    37    38    39 
0.596 0.279 0.767    NA 0.783 0.474    NA    NA 0.265 0.327 0.746 0.253 0.738 
   40    41    42    43    44    45    46    47    48    49    50    51    52 
0.796 0.305 0.731    NA 0.674 0.433 0.801 0.582 0.233 0.403 0.814 0.223    NA 
   53    54    55    56    57    58    59    60    61    62    63    64    65 
0.253    NA 0.699 0.657 0.670    NA    NA 0.441 0.291    NA 0.425 0.684 0.212 
   66    67    68    69    70    71    72    73    74    75    76    77    78 
0.816 0.713 0.815 0.163 0.529 0.399 0.442 0.400 0.533 0.295 0.753 0.821 0.786 
   79    80    81    82    83    84    85    86    87    88    89    90    91 
0.817 0.600 0.325 0.748 0.610 0.467 0.577 0.625 0.611    NA 0.623 0.824 0.289 
   92    93    94    95    96    97    98    99   100   101   102   103   104 
0.459 0.153 0.290 0.343 0.611 0.667 0.354 0.309 0.659 0.576 0.581 0.266 0.772 
  105   106   107   108   109   110   111   112   113   114   115   116   117 
   NA 0.236 0.619 0.204    NA 0.793 0.224 0.546 0.755 0.242 0.453    NA 0.196 
  118   119   120   121   122   123   124   125   126   127   128   129   130 
0.316 0.285 0.648 0.504 0.323    NA 0.775 0.161 0.552 0.225 0.537 0.440    NA 
  131   132   133   134   135   136   137   138   139   140   141   142   143 
0.496    NA 0.786    NA 0.285 0.754 0.245 0.191 0.281 0.744 0.726 0.369 0.248 
  144   145   146   147   148   149   150   151   152   153   154   155   156 
   NA 0.429 0.457    NA 0.190    NA 0.583 0.255 0.296 0.337    NA 0.171    NA 
  157   158   159   160   161   162   163   164   165   166   167   168   169 
0.533 0.163 0.154 0.253 0.353 0.312 0.247 0.258    NA 0.402 0.748 0.306 0.670 
  170   171   172   173   174   175   176   177   178   179   180   181   182 
0.353 0.803 0.577 0.734 0.208 0.520 0.687 0.295 0.475 0.543 0.464 0.561 0.155 
  183   184   185   186   187   188   189   190   191   192   193   194   195 
0.384 0.384 0.179    NA 0.679 0.705 0.258 0.779    NA    NA 0.486 0.215 0.351 
  196   197   198   199   200   201   202   203   204   205   206   207   208 
0.264    NA    NA 0.350 0.221    NA 0.172 0.566 0.694 0.539 0.497 0.406 0.654 
  209   210   211   212   213   214   215   216   217   218   219   220   221 
0.758 0.204    NA 0.372 0.291 0.208 0.541    NA 0.539 0.547 0.813 0.286 0.458 
  222   223   224   225   226   227   228   229   230   231   232   233   234 
0.231 0.696 0.194    NA 0.183    NA 0.252 0.643 0.801 0.663 0.293    NA 0.215 
  235   236   237   238   239   240   241   242   243   244   245   246   247 
0.243 0.185 0.303 0.429 0.640    NA 0.225 0.554 0.763 0.389    NA 0.709 0.206 
  248   249   250   251   252   253   254   255   256   257   258   259   260 
0.679 0.211 0.740 0.505 0.552 0.746 0.748 0.174    NA 0.354 0.720 0.499 0.426 
  261   262   263   264   265   266   267   268   269   270   271   272   273 
0.173 0.287 0.396 0.202    NA    NA 0.737    NA    NA 0.645 0.193 0.459 0.211 
  274   275   276   277   278   279   280   281   282   283   284   285   286 
0.298 0.273 0.246 0.154 0.310 0.208 0.402 0.696 0.199 0.354 0.348    NA    NA 
  287   288   289   290   291   292   293   294   295   296   297   298   299 
0.695 0.702 0.271 0.449 0.339 0.511 0.810 0.224 0.370    NA 0.544 0.507 0.752 
  300   301   302   303   304   305   306   307   308   309   310   311   312 
0.682 0.437 0.791 0.522 0.532 0.200 0.389 0.813 0.269 0.269 0.311 0.207    NA 
  313   314   315   316   317   318   319   320   321   322   323   324   325 
0.312 0.589 0.803 0.181 0.164 0.165 0.411 0.290 0.201 0.744 0.225 0.514 0.484 
  326   327   328   329   330   331   332   333   334   335   336   337   338 
   NA 0.619 0.667 0.799 0.369 0.357 0.440    NA 0.499 0.147 0.745 0.521    NA 
  339   340   341   342   343   344   345   346   347   348   349   350   351 
0.798 0.769 0.627    NA 0.447    NA 0.428 0.809 0.309 0.814 0.619 0.773 0.609 
  352   353   354   355   356   357   358   359   360   361   362   363   364 
0.408 0.787 0.224 0.154 0.536    NA 0.316 0.307 0.561    NA 0.317    NA 0.718 
  365   366   367   368   369   370   371   372   373   374   375   376   377 
   NA 0.817 0.567 0.726 0.279 0.683 0.174 0.487 0.744 0.817 0.395 0.451 0.413 
  378   379   380   381   382   383   384   385   386   387   388   389   390 
0.778 0.462 0.793 0.210 0.526 0.655    NA 0.577    NA 0.188 0.614    NA 0.194 
  391   392   393   394   395   396   397   398   399   400   401   402   403 
0.397    NA 0.700 0.574 0.401 0.147 0.561 0.549 0.775    NA    NA 0.292    NA 
  404   405   406   407   408   409   410   411   412   413   414   415   416 
0.496 0.439 0.493 0.188 0.553 0.619 0.515    NA 0.321 0.312    NA 0.235 0.779 
  417   418   419   420   421   422   423   424   425   426   427   428   429 
0.820 0.667 0.470 0.788 0.568 0.391 0.253 0.647 0.789 0.626 0.762 0.274 0.513 
  430   431   432   433   434   435   436   437   438   439   440   441   442 
0.260 0.505 0.808 0.706 0.258 0.398 0.723 0.429 0.394 0.160 0.216 0.615 0.176 
  443   444   445   446   447   448   449   450   451   452   453   454   455 
0.823 0.204    NA 0.158 0.201 0.439 0.704 0.727    NA 0.311 0.588    NA 0.505 
  456   457   458   459   460   461   462   463   464   465   466   467   468 
0.422 0.650 0.239 0.338 0.388    NA 0.308 0.643 0.344 0.556 0.495 0.744 0.502 
  469   470   471   472   473   474   475   476   477   478   479   480   481 
0.202    NA 0.176 0.636    NA 0.691 0.693 0.517 0.740 0.262 0.275    NA 0.432 
  482   483   484   485   486   487   488   489   490   491   492   493   494 
0.601 0.184 0.355 0.709 0.359 0.171 0.746 0.521    NA 0.677 0.512 0.458 0.358 
  495   496   497   498   499   500 
   NA 0.798 0.296 0.200 0.291 0.243 
> all.equal( fitted( ss ), fitted( ss, part = "outcome" ) )
[1] TRUE
> round( fitted( ss, part = "selection" ), 3 )
    1     2     3     4     5     6     7     8     9    10    11    12    13 
0.878 0.997 0.999 0.997 0.909 0.697 0.560 0.966 0.545 0.949 0.926 0.515 0.968 
   14    15    16    17    18    19    20    21    22    23    24    25    26 
0.994 0.969 0.488 0.884 0.591 0.483 0.996 0.833 0.804 0.996 0.896 0.465 0.521 
   27    28    29    30    31    32    33    34    35    36    37    38    39 
0.990 0.549 0.545 0.977 0.895 0.905 0.558 0.788 0.994 0.572 0.788 0.630 0.982 
   40    41    42    43    44    45    46    47    48    49    50    51    52 
0.999 0.720 0.868 0.607 0.993 0.538 0.994 0.614 0.993 0.860 0.973 0.998 0.590 
   53    54    55    56    57    58    59    60    61    62    63    64    65 
0.988 0.655 0.773 0.993 0.968 0.577 0.657 0.986 0.780 0.807 0.960 0.848 0.999 
   66    67    68    69    70    71    72    73    74    75    76    77    78 
0.723 0.967 0.892 0.953 0.995 0.465 0.983 0.998 0.892 0.998 0.995 0.521 0.999 
   79    80    81    82    83    84    85    86    87    88    89    90    91 
0.938 0.937 0.708 0.984 0.955 0.972 0.817 0.664 0.997 0.680 0.966 0.999 0.951 
   92    93    94    95    96    97    98    99   100   101   102   103   104 
0.995 0.980 0.993 0.497 0.959 0.609 0.985 0.998 0.959 0.964 0.945 0.981 0.967 
  105   106   107   108   109   110   111   112   113   114   115   116   117 
0.557 0.654 0.999 0.999 0.805 0.994 0.985 0.887 0.885 0.998 0.996 0.777 0.685 
  118   119   120   121   122   123   124   125   126   127   128   129   130 
0.999 0.996 0.849 0.996 0.465 0.723 0.998 0.516 0.997 0.980 0.728 0.464 0.556 
  131   132   133   134   135   136   137   138   139   140   141   142   143 
0.992 0.495 0.993 0.883 0.994 0.495 0.864 0.715 0.999 0.961 0.911 0.995 0.666 
  144   145   146   147   148   149   150   151   152   153   154   155   156 
0.714 0.850 0.916 0.587 0.970 0.584 0.999 0.965 0.670 0.946 0.523 0.805 0.494 
  157   158   159   160   161   162   163   164   165   166   167   168   169 
0.895 0.988 0.909 0.928 0.873 0.993 0.999 0.912 0.788 0.980 0.992 0.967 0.864 
  170   171   172   173   174   175   176   177   178   179   180   181   182 
0.942 0.640 0.778 0.676 0.998 0.960 0.846 0.794 0.991 0.960 0.961 0.976 0.999 
  183   184   185   186   187   188   189   190   191   192   193   194   195 
0.993 0.992 0.650 0.865 0.998 0.937 0.488 0.916 0.487 0.475 0.997 0.999 0.998 
  196   197   198   199   200   201   202   203   204   205   206   207   208 
0.997 0.614 0.731 0.985 0.979 0.572 0.969 0.999 0.620 0.948 0.999 0.911 0.888 
  209   210   211   212   213   214   215   216   217   218   219   220   221 
0.863 0.963 0.591 0.981 0.994 0.659 0.938 0.633 0.985 0.930 0.715 0.988 0.838 
  222   223   224   225   226   227   228   229   230   231   232   233   234 
0.949 0.968 0.992 0.504 0.976 0.672 0.987 0.776 0.558 0.988 0.991 0.672 0.723 
  235   236   237   238   239   240   241   242   243   244   245   246   247 
0.631 0.828 0.981 0.920 0.731 0.517 0.996 0.921 0.511 0.836 0.852 0.747 0.717 
  248   249   250   251   252   253   254   255   256   257   258   259   260 
0.800 0.809 0.998 0.992 0.589 0.992 0.896 0.730 0.460 0.491 0.761 0.730 0.817 
  261   262   263   264   265   266   267   268   269   270   271   272   273 
0.998 0.999 0.935 0.669 0.694 0.697 0.940 0.559 0.994 0.962 0.999 0.997 0.987 
  274   275   276   277   278   279   280   281   282   283   284   285   286 
0.603 0.660 0.840 0.999 0.998 0.951 0.758 0.998 0.991 0.998 0.980 0.479 0.578 
  287   288   289   290   291   292   293   294   295   296   297   298   299 
0.999 0.998 0.919 0.994 0.708 0.821 0.950 0.687 0.951 0.850 0.943 0.994 0.911 
  300   301   302   303   304   305   306   307   308   309   310   311   312 
0.797 0.999 0.492 0.997 0.912 0.976 0.993 0.791 0.613 0.998 0.890 0.992 0.597 
  313   314   315   316   317   318   319   320   321   322   323   324   325 
0.842 0.955 0.820 0.914 0.889 0.933 0.910 0.778 0.980 0.750 0.995 0.995 0.967 
  326   327   328   329   330   331   332   333   334   335   336   337   338 
0.954 0.513 0.902 0.978 0.452 0.997 0.585 0.578 0.993 0.490 0.845 0.994 0.601 
  339   340   341   342   343   344   345   346   347   348   349   350   351 
0.852 0.836 0.986 0.854 0.891 0.817 0.999 0.985 0.998 0.999 0.991 0.996 0.994 
  352   353   354   355   356   357   358   359   360   361   362   363   364 
0.998 0.996 0.867 0.997 0.995 0.680 0.663 0.999 0.913 0.555 0.999 0.472 0.936 
  365   366   367   368   369   370   371   372   373   374   375   376   377 
0.903 0.873 0.990 0.790 0.980 0.993 0.989 0.999 0.954 0.981 0.786 0.885 0.959 
  378   379   380   381   382   383   384   385   386   387   388   389   390 
0.999 0.999 0.727 0.882 0.990 0.985 0.841 0.985 0.651 0.998 0.998 0.632 0.499 
  391   392   393   394   395   396   397   398   399   400   401   402   403 
0.855 0.873 0.973 0.941 0.842 0.835 0.963 0.519 0.887 0.772 0.670 0.530 0.521 
  404   405   406   407   408   409   410   411   412   413   414   415   416 
0.999 0.994 0.493 0.954 0.475 0.993 0.992 0.465 0.995 0.997 0.900 0.977 0.898 
  417   418   419   420   421   422   423   424   425   426   427   428   429 
0.831 0.992 0.987 0.998 0.972 0.525 0.990 0.998 0.987 0.964 0.961 0.864 0.958 
  430   431   432   433   434   435   436   437   438   439   440   441   442 
0.998 0.783 0.996 0.983 0.998 0.807 0.877 0.998 0.993 0.954 0.996 0.998 0.812 
  443   444   445   446   447   448   449   450   451   452   453   454   455 
0.861 0.999 0.899 0.960 0.994 0.929 0.997 0.987 0.620 0.980 0.994 0.751 0.997 
  456   457   458   459   460   461   462   463   464   465   466   467   468 
0.929 0.835 0.999 0.992 0.926 0.769 0.876 0.808 0.993 0.905 0.980 0.753 0.805 
  469   470   471   472   473   474   475   476   477   478   479   480   481 
0.999 0.634 0.931 0.995 0.840 0.955 0.518 0.985 0.948 0.877 0.727 0.517 0.842 
  482   483   484   485   486   487   488   489   490   491   492   493   494 
0.949 0.859 0.999 0.513 0.547 0.983 0.662 0.965 0.571 0.980 0.857 0.700 0.984 
  495   496   497   498   499   500 
0.492 0.910 0.999 0.895 0.998 0.582 
> round( residuals( ss ), 3 )
     1      2      3      4      5      6      7      8      9     10     11 
-0.909  1.184 -0.633  0.781  1.326  0.633     NA  0.720 -0.579 -0.759  1.381 
    12     13     14     15     16     17     18     19     20     21     22 
 1.492  1.181  0.924  0.669     NA -0.694  1.075  0.629 -0.655  0.731 -0.926 
    23     24     25     26     27     28     29     30     31     32     33 
-1.100 -0.743 -0.946 -0.742  1.017 -0.809  0.729     NA  0.700 -1.133     NA 
    34     35     36     37     38     39     40     41     42     43     44 
    NA -0.785 -0.890  0.766  1.658  0.780 -1.783  1.540  0.792     NA  0.889 
    45     46     47     48     49     50     51     52     53     54     55 
 1.293  0.667 -1.321 -0.729  1.348  0.642 -0.710     NA -0.765     NA  0.847 
    56     57     58     59     60     61     62     63     64     65     66 
-1.462  0.895     NA     NA  1.280 -0.830     NA  1.309  0.872 -0.691  0.637 
    67     68     69     70     71     72     73     74     75     76     77 
 0.822  0.640 -0.596 -1.227  1.356 -1.080 -1.011 -1.234 -0.837  0.754  0.628 
    78     79     80     81     82     83     84     85     86     87     88 
 0.693  0.635 -1.354 -0.887  0.762  0.994  1.234 -1.312  0.970 -1.374     NA 
    89     90     91     92     93     94     95     96     97     98     99 
-1.396 -1.865 -0.826  1.249 -0.576 -0.827  1.464  0.993  0.899  1.441 -0.860 
   100    101    102    103    104    105    106    107    108    109    110 
-1.468 -1.310  1.042  1.628  0.719     NA -0.734 -1.389  1.784     NA -1.774 
   111    112    113    114    115    116    117    118    119    120    121 
-0.712  1.100 -1.678 -0.744  1.259     NA  1.806 -0.872 -0.820  0.931 -1.185 
   122    123    124    125    126    127    128    129    130    131    132 
 1.504     NA  0.715 -0.593  1.090  1.727  1.115  1.282     NA  1.183     NA 
   133    134    135    136    137    138    139    140    141    142    143 
 0.695     NA -0.819  0.752 -0.749 -0.651  1.593 -1.652 -1.608  1.411  1.670 
   144    145    146    147    148    149    150    151    152    153    154 
    NA -1.059  1.251     NA -0.649     NA  1.039  1.654  1.560 -0.906     NA 
   155    156    157    158    159    160    161    162    163    164    165 
-0.612     NA  1.122  1.904 -0.579 -0.764 -0.933 -0.864  1.673 -0.773     NA 
   166    167    168    169    170    171    172    173    174    175    176 
 1.350  0.762 -0.855  0.894 -0.933  0.662  1.049  0.786 -0.684 -1.211  0.866 
   177    178    179    180    181    182    183    184    185    186    187 
-0.836  1.220  1.106 -1.116  1.074  1.929 -0.985 -0.984 -0.627     NA  0.880 
   188    189    190    191    192    193    194    195    196    197    198 
 0.836 -0.773 -1.738     NA     NA  1.201  1.755  1.447  1.632     NA     NA 
   199    200    201    202    203    204    205    206    207    208    209 
-0.928 -0.708     NA -0.614 -1.291  0.855  1.112  1.182 -1.020  0.921  0.744 
   210    211    212    213    214    215    216    217    218    219    220 
 1.783     NA -0.965 -0.830  1.773  1.108     NA -1.244 -1.259  0.644 -0.821 
   221    222    223    224    225    226    227    228    229    230    231 
 1.250  1.712  0.851 -0.656     NA -0.636     NA -0.762 -1.435  0.666  0.907 
   232    233    234    235    236    237    238    239    240    241    242 
-0.832     NA -0.695 -0.746  1.837 -0.850  1.302  0.944     NA -0.714 -1.271 
   243    244    245    246    247    248    249    250    251    252    253 
 0.736  1.374     NA  0.830 -0.679  0.880 -0.688  0.776  1.169 -1.267  0.766 
   254    255    256    257    258    259    260    261    262    263    264 
 0.761 -0.619     NA  1.441  0.810  1.179 -1.054 -0.616 -0.822  1.361  1.788 
   265    266    267    268    269    270    271    272    273    274    275 
    NA     NA  0.780     NA     NA -1.439 -0.656  1.248 -0.689 -0.842 -0.799 
   276    277    278    279    280    281    282    283    284    285    286 
-0.751 -0.578 -0.862 -0.683  1.349  0.851  1.796 -0.934 -0.924     NA     NA 
   287    288    289    290    291    292    293    294    295    296    297 
 0.853 -1.556 -0.795 -1.092 -0.911 -1.196 -1.821 -0.713 -0.961     NA -1.254 
   298    299    300    301    302    303    304    305    306    307    308 
-1.190  0.754  0.874 -1.072  0.684  1.140 -1.232 -0.668 -0.993  0.644 -0.792 
   309    310    311    312    313    314    315    316    317    318    319 
-0.791 -0.863 -0.681     NA -0.865  1.028  0.662 -0.631 -0.598 -0.600  1.334 
   320    321    322    323    324    325    326    327    328    329    330 
 1.573 -0.669  0.769 -0.715  1.153  1.204     NA  0.980  0.899  0.670 -0.960 
   331    332    333    334    335    336    337    338    339    340    341 
-0.940  1.282     NA  1.180  1.958 -1.653 -1.213     NA  0.672 -1.711  0.966 
   342    343    344    345    346    347    348    349    350    351    352 
    NA -1.088     NA  1.303  0.652 -0.860  0.642  0.980  0.717  0.996  1.340 
   353    354    355    356    357    358    359    360    361    362    363 
-1.759 -0.712 -0.578  1.116     NA  1.518 -0.856  1.075     NA -0.873     NA 
   364    365    366    367    368    369    370    371    372    373    374 
 0.813     NA  0.636 -1.294  0.801 -0.810  0.872 -0.619 -1.156  0.769  0.636 
   375    376    377    378    379    380    381    382    383    384    385 
 1.363  1.263 -1.033  0.709  1.243  0.680  1.768  1.133  0.920     NA  1.049 
   386    387    388    389    390    391    392    393    394    395    396 
    NA -0.646  0.988     NA  1.811  1.360     NA  0.845  1.054 -1.013  1.958 
   397    398    399    400    401    402    403    404    405    406    407 
 1.074  1.096  0.715     NA     NA -0.831     NA  1.185 -1.076  1.190 -0.646 
   408    409    410    411    412    413    414    415    416    417    418 
 1.089 -1.390 -1.203     NA -0.879  1.526     NA -0.733  0.707  0.630 -1.483 
   419    420    421    422    423    424    425    426    427    428    429 
-1.126  0.691  1.063  1.370  1.657 -1.442  0.689  0.968 -1.693 -0.801 -1.199 
   430    431    432    433    434    435    436    437    438    439    440 
-0.776 -1.186  0.652  0.835 -0.773  1.357  0.805 -1.059  1.365 -0.591 -0.698 
   441    442    443    444    445    446    447    448    449    450    451 
 0.987 -0.622  0.624 -0.675     NA -0.586 -0.669  1.282  0.838 -1.612     NA 
   452    453    454    455    456    457    458    459    460    461    462 
-0.863  1.030     NA  1.169  1.314  0.929 -0.740  1.473 -0.992     NA -0.858 
   463    464    465    466    467    468    469    470    471    472    473 
-1.436  1.461  1.084 -1.168  0.769  1.175 -0.672     NA  1.863 -1.421     NA 
   474    475    476    477    478    479    480    481    482    483    484 
-1.532 -1.536 -1.207  0.775 -0.779 -0.802     NA  1.295 -1.356  1.840 -0.936 
   485    486    487    488    489    490    491    492    493    494    495 
 0.830  1.431 -0.612  0.766 -1.213     NA -1.503  1.157  1.249 -0.941     NA 
   496    497    498    499    500 
 0.672 -0.838  1.795  1.571 -0.747 
> all.equal( residuals( ss ), residuals( ss, part = "outcome" ) )
[1] TRUE
> all.equal( residuals( ss ),
+    residuals( ss, part = "outcome", type = "deviance"  ) )
[1] TRUE
> round( residuals( ss, type = "pearson" ), 3 )
     1      2      3      4      5      6      7      8      9     10     11 
-0.715  1.007 -0.471  0.597  1.187  0.471     NA  0.544 -0.427 -0.578  1.262 
    12     13     14     15     16     17     18     19     20     21     22 
 1.429  1.004  0.730  0.501     NA -0.522  0.884  0.468 -0.489  0.553 -0.731 
    23     24     25     26     27     28     29     30     31     32     33 
-0.911 -0.564 -0.752 -0.563  0.823 -0.622  0.552     NA  0.527 -0.949     NA 
    34     35     36     37     38     39     40     41     42     43     44 
    NA -0.601 -0.697  0.584  1.719  0.596 -1.975  1.508  0.607     NA  0.696 
    45     46     47     48     49     50     51     52     53     54     55 
 1.144  0.499 -1.181 -0.551  1.217  0.478 -0.535     NA -0.583     NA  0.657 
    56     57     58     59     60     61     62     63     64     65     66 
-1.383  0.702     NA     NA  1.126 -0.641     NA  1.164  0.680 -0.519  0.475 
    67     68     69     70     71     72     73     74     75     76     77 
 0.634  0.477 -0.441 -1.060  1.228 -0.890 -0.817 -1.068 -0.648  0.573  0.467 
    78     79     80     81     82     83     84     85     86     87     88 
 0.521  0.472 -1.225 -0.694  0.580  0.800  1.068 -1.168  0.775 -1.253     NA 
    89     90     91     92     93     94     95     96     97     98     99 
-1.284 -2.167 -0.637  1.086 -0.425 -0.639  1.385  0.798  0.706  1.350 -0.669 
   100    101    102    103    104    105    106    107    108    109    110 
-1.391 -1.165  0.849  1.662  0.543     NA -0.556 -1.275  1.977     NA -1.956 
   111    112    113    114    115    116    117    118    119    120    121 
-0.537  0.911 -1.756 -0.565  1.100     NA  2.027 -0.680 -0.632  0.736 -1.009 
   122    123    124    125    126    127    128    129    130    131    132 
 1.449     NA  0.539 -0.439  0.901  1.855  0.928  1.129     NA  1.007     NA 
   133    134    135    136    137    138    139    140    141    142    143 
 0.522     NA -0.631  0.571 -0.569 -0.485  1.599 -1.707 -1.627  1.307  1.742 
   144    145    146    147    148    149    150    151    152    153    154 
    NA -0.867  1.089     NA -0.485     NA  0.846  1.711  1.541 -0.713     NA 
   155    156    157    158    159    160    161    162    163    164    165 
-0.454     NA  0.936  2.264 -0.427 -0.582 -0.739 -0.673  1.747 -0.590     NA 
   166    167    168    169    170    171    172    173    174    175    176 
 1.219  0.580 -0.664  0.701 -0.738  0.495  0.856  0.602 -0.513 -1.040  0.674 
   177    178    179    180    181    182    183    184    185    186    187 
-0.647  1.052  0.918 -0.930  0.884  2.331 -0.790 -0.789 -0.466     NA  0.687 
   188    189    190    191    192    193    194    195    196    197    198 
 0.647 -0.590 -1.878     NA     NA  1.028  1.913  1.360  1.670     NA     NA 
   199    200    201    202    203    204    205    206    207    208    209 
-0.733 -0.533     NA -0.456 -1.141  0.664  0.926  1.006 -0.826  0.727  0.564 
   210    211    212    213    214    215    216    217    218    219    220 
 1.975     NA -0.770 -0.641  1.954  0.920     NA -1.081 -1.100  0.480 -0.633 
   221    222    223    224    225    226    227    228    229    230    231 
 1.089  1.826  0.661 -0.490     NA -0.473     NA -0.580 -1.341  0.499  0.714 
   232    233    234    235    236    237    238    239    240    241    242 
-0.643     NA -0.523 -0.567  2.098 -0.659  1.155  0.750     NA -0.539 -1.115 
   243    244    245    246    247    248    249    250    251    252    253 
 0.558  1.254     NA  0.641 -0.510  0.688 -0.517  0.593  0.990 -1.110  0.584 
   254    255    256    257    258    259    260    261    262    263    264 
 0.580 -0.459     NA  1.350  0.623  1.002 -0.862 -0.457 -0.634  1.235  1.986 
   265    266    267    268    269    270    271    272    273    274    275 
    NA     NA  0.597     NA     NA -1.348 -0.490  1.085 -0.518 -0.652 -0.613 
   276    277    278    279    280    281    282    283    284    285    286 
-0.571 -0.426 -0.671 -0.512  1.218  0.661  2.005 -0.739 -0.730     NA     NA 
   287    288    289    290    291    292    293    294    295    296    297 
 0.663 -1.535 -0.610 -0.903 -0.717 -1.022 -2.062 -0.538 -0.766     NA -1.093 
   298    299    300    301    302    303    304    305    306    307    308 
-1.015  0.574  0.682 -0.881  0.513  0.957 -1.066 -0.500 -0.798  0.480 -0.607 
   309    310    311    312    313    314    315    316    317    318    319 
-0.606 -0.671 -0.511     NA -0.674  0.835  0.495 -0.469 -0.442 -0.444  1.198 
   320    321    322    323    324    325    326    327    328    329    330 
 1.565 -0.501  0.586 -0.540  0.972  1.032     NA  0.785  0.706  0.501 -0.765 
   331    332    333    334    335    336    337    338    339    340    341 
-0.745  1.129     NA  1.003  2.408 -1.708 -1.042     NA  0.503 -1.822  0.771 
   342    343    344    345    346    347    348    349    350    351    352 
    NA -0.898     NA  1.157  0.486 -0.668  0.478  0.785  0.541  0.801  1.206 
   353    354    355    356    357    358    359    360    361    362    363 
-1.923 -0.537 -0.426  0.930     NA  1.472 -0.665  0.884     NA -0.681     NA 
   364    365    366    367    368    369    370    371    372    373    374 
 0.626     NA  0.473 -1.144  0.615 -0.623  0.681 -0.459 -0.975  0.586  0.473 
   375    376    377    378    379    380    381    382    383    384    385 
 1.237  1.104 -0.840  0.534  1.080  0.510  1.942  0.949  0.726     NA  0.856 
   386    387    388    389    390    391    392    393    394    395    396 
    NA -0.482  0.793     NA  2.039  1.233     NA  0.655  0.862 -0.819  2.409 
   397    398    399    400    401    402    403    404    405    406    407 
 0.884  0.907  0.539     NA     NA -0.642     NA  1.009 -0.885  1.014 -0.482 
   408    409    410    411    412    413    414    415    416    417    418 
 0.899 -1.275 -1.030     NA -0.687  1.484     NA -0.555  0.533  0.469 -1.415 
   419    420    421    422    423    424    425    426    427    428    429 
-0.941  0.519  0.872  1.248  1.717 -1.353  0.518  0.773 -1.787 -0.615 -1.025 
   430    431    432    433    434    435    436    437    438    439    440 
-0.593 -1.010  0.487  0.645 -0.590  1.230  0.618 -0.867  1.241 -0.437 -0.525 
   441    442    443    444    445    446    447    448    449    450    451 
 0.792 -0.462  0.463 -0.506     NA -0.433 -0.501  1.129  0.649 -1.633     NA 
   452    453    454    455    456    457    458    459    460    461    462 
-0.672  0.837     NA  0.990  1.171  0.734 -0.561  1.400 -0.797     NA -0.667 
   463    464    465    466    467    468    469    470    471    472    473 
-1.343  1.381  0.894 -0.989  0.587  0.997 -0.504     NA  2.162 -1.321     NA 
   474    475    476    477    478    479    480    481    482    483    484 
-1.495 -1.502 -1.035  0.592 -0.596 -0.616     NA  1.146 -1.228  2.106 -0.741 
   485    486    487    488    489    490    491    492    493    494    495 
 0.641  1.336 -0.454  0.584 -1.042     NA -1.446  0.977  1.087 -0.746     NA 
   496    497    498    499    500 
 0.503 -0.649  2.001  1.561 -0.567 
> all.equal( residuals( ss, type = "pearson" ),
+    residuals( ss, part = "outcome", type = "pearson" ) )
[1] TRUE
> round( residuals( ss, type = "deviance" ), 3 )
     1      2      3      4      5      6      7      8      9     10     11 
-0.909  1.184 -0.633  0.781  1.326  0.633     NA  0.720 -0.579 -0.759  1.381 
    12     13     14     15     16     17     18     19     20     21     22 
 1.492  1.181  0.924  0.669     NA -0.694  1.075  0.629 -0.655  0.731 -0.926 
    23     24     25     26     27     28     29     30     31     32     33 
-1.100 -0.743 -0.946 -0.742  1.017 -0.809  0.729     NA  0.700 -1.133     NA 
    34     35     36     37     38     39     40     41     42     43     44 
    NA -0.785 -0.890  0.766  1.658  0.780 -1.783  1.540  0.792     NA  0.889 
    45     46     47     48     49     50     51     52     53     54     55 
 1.293  0.667 -1.321 -0.729  1.348  0.642 -0.710     NA -0.765     NA  0.847 
    56     57     58     59     60     61     62     63     64     65     66 
-1.462  0.895     NA     NA  1.280 -0.830     NA  1.309  0.872 -0.691  0.637 
    67     68     69     70     71     72     73     74     75     76     77 
 0.822  0.640 -0.596 -1.227  1.356 -1.080 -1.011 -1.234 -0.837  0.754  0.628 
    78     79     80     81     82     83     84     85     86     87     88 
 0.693  0.635 -1.354 -0.887  0.762  0.994  1.234 -1.312  0.970 -1.374     NA 
    89     90     91     92     93     94     95     96     97     98     99 
-1.396 -1.865 -0.826  1.249 -0.576 -0.827  1.464  0.993  0.899  1.441 -0.860 
   100    101    102    103    104    105    106    107    108    109    110 
-1.468 -1.310  1.042  1.628  0.719     NA -0.734 -1.389  1.784     NA -1.774 
   111    112    113    114    115    116    117    118    119    120    121 
-0.712  1.100 -1.678 -0.744  1.259     NA  1.806 -0.872 -0.820  0.931 -1.185 
   122    123    124    125    126    127    128    129    130    131    132 
 1.504     NA  0.715 -0.593  1.090  1.727  1.115  1.282     NA  1.183     NA 
   133    134    135    136    137    138    139    140    141    142    143 
 0.695     NA -0.819  0.752 -0.749 -0.651  1.593 -1.652 -1.608  1.411  1.670 
   144    145    146    147    148    149    150    151    152    153    154 
    NA -1.059  1.251     NA -0.649     NA  1.039  1.654  1.560 -0.906     NA 
   155    156    157    158    159    160    161    162    163    164    165 
-0.612     NA  1.122  1.904 -0.579 -0.764 -0.933 -0.864  1.673 -0.773     NA 
   166    167    168    169    170    171    172    173    174    175    176 
 1.350  0.762 -0.855  0.894 -0.933  0.662  1.049  0.786 -0.684 -1.211  0.866 
   177    178    179    180    181    182    183    184    185    186    187 
-0.836  1.220  1.106 -1.116  1.074  1.929 -0.985 -0.984 -0.627     NA  0.880 
   188    189    190    191    192    193    194    195    196    197    198 
 0.836 -0.773 -1.738     NA     NA  1.201  1.755  1.447  1.632     NA     NA 
   199    200    201    202    203    204    205    206    207    208    209 
-0.928 -0.708     NA -0.614 -1.291  0.855  1.112  1.182 -1.020  0.921  0.744 
   210    211    212    213    214    215    216    217    218    219    220 
 1.783     NA -0.965 -0.830  1.773  1.108     NA -1.244 -1.259  0.644 -0.821 
   221    222    223    224    225    226    227    228    229    230    231 
 1.250  1.712  0.851 -0.656     NA -0.636     NA -0.762 -1.435  0.666  0.907 
   232    233    234    235    236    237    238    239    240    241    242 
-0.832     NA -0.695 -0.746  1.837 -0.850  1.302  0.944     NA -0.714 -1.271 
   243    244    245    246    247    248    249    250    251    252    253 
 0.736  1.374     NA  0.830 -0.679  0.880 -0.688  0.776  1.169 -1.267  0.766 
   254    255    256    257    258    259    260    261    262    263    264 
 0.761 -0.619     NA  1.441  0.810  1.179 -1.054 -0.616 -0.822  1.361  1.788 
   265    266    267    268    269    270    271    272    273    274    275 
    NA     NA  0.780     NA     NA -1.439 -0.656  1.248 -0.689 -0.842 -0.799 
   276    277    278    279    280    281    282    283    284    285    286 
-0.751 -0.578 -0.862 -0.683  1.349  0.851  1.796 -0.934 -0.924     NA     NA 
   287    288    289    290    291    292    293    294    295    296    297 
 0.853 -1.556 -0.795 -1.092 -0.911 -1.196 -1.821 -0.713 -0.961     NA -1.254 
   298    299    300    301    302    303    304    305    306    307    308 
-1.190  0.754  0.874 -1.072  0.684  1.140 -1.232 -0.668 -0.993  0.644 -0.792 
   309    310    311    312    313    314    315    316    317    318    319 
-0.791 -0.863 -0.681     NA -0.865  1.028  0.662 -0.631 -0.598 -0.600  1.334 
   320    321    322    323    324    325    326    327    328    329    330 
 1.573 -0.669  0.769 -0.715  1.153  1.204     NA  0.980  0.899  0.670 -0.960 
   331    332    333    334    335    336    337    338    339    340    341 
-0.940  1.282     NA  1.180  1.958 -1.653 -1.213     NA  0.672 -1.711  0.966 
   342    343    344    345    346    347    348    349    350    351    352 
    NA -1.088     NA  1.303  0.652 -0.860  0.642  0.980  0.717  0.996  1.340 
   353    354    355    356    357    358    359    360    361    362    363 
-1.759 -0.712 -0.578  1.116     NA  1.518 -0.856  1.075     NA -0.873     NA 
   364    365    366    367    368    369    370    371    372    373    374 
 0.813     NA  0.636 -1.294  0.801 -0.810  0.872 -0.619 -1.156  0.769  0.636 
   375    376    377    378    379    380    381    382    383    384    385 
 1.363  1.263 -1.033  0.709  1.243  0.680  1.768  1.133  0.920     NA  1.049 
   386    387    388    389    390    391    392    393    394    395    396 
    NA -0.646  0.988     NA  1.811  1.360     NA  0.845  1.054 -1.013  1.958 
   397    398    399    400    401    402    403    404    405    406    407 
 1.074  1.096  0.715     NA     NA -0.831     NA  1.185 -1.076  1.190 -0.646 
   408    409    410    411    412    413    414    415    416    417    418 
 1.089 -1.390 -1.203     NA -0.879  1.526     NA -0.733  0.707  0.630 -1.483 
   419    420    421    422    423    424    425    426    427    428    429 
-1.126  0.691  1.063  1.370  1.657 -1.442  0.689  0.968 -1.693 -0.801 -1.199 
   430    431    432    433    434    435    436    437    438    439    440 
-0.776 -1.186  0.652  0.835 -0.773  1.357  0.805 -1.059  1.365 -0.591 -0.698 
   441    442    443    444    445    446    447    448    449    450    451 
 0.987 -0.622  0.624 -0.675     NA -0.586 -0.669  1.282  0.838 -1.612     NA 
   452    453    454    455    456    457    458    459    460    461    462 
-0.863  1.030     NA  1.169  1.314  0.929 -0.740  1.473 -0.992     NA -0.858 
   463    464    465    466    467    468    469    470    471    472    473 
-1.436  1.461  1.084 -1.168  0.769  1.175 -0.672     NA  1.863 -1.421     NA 
   474    475    476    477    478    479    480    481    482    483    484 
-1.532 -1.536 -1.207  0.775 -0.779 -0.802     NA  1.295 -1.356  1.840 -0.936 
   485    486    487    488    489    490    491    492    493    494    495 
 0.830  1.431 -0.612  0.766 -1.213     NA -1.503  1.157  1.249 -0.941     NA 
   496    497    498    499    500 
 0.672 -0.838  1.795  1.571 -0.747 
> all.equal( residuals( ss, type = "deviance" ),
+    residuals( ss, part = "outcome", type = "deviance" ) )
[1] TRUE
> all.equal( residuals( ss, part = "outcome", type = "response" ),
+    ( simDat$yo == 1 ) - fitted( ss, part = "outcome" ) )
[1] TRUE
> round( residuals( ss, part = "selection" ), 3 )
     1      2      3      4      5      6      7      8      9     10     11 
 0.510  0.074  0.044  0.076  0.437  0.849 -1.282  0.265  1.103  0.324  0.391 
    12     13     14     15     16     17     18     19     20     21     22 
 1.152  0.254  0.110  0.250 -1.158  0.497  1.025  1.206  0.086  0.605  0.660 
    23     24     25     26     27     28     29     30     31     32     33 
 0.094  0.470  1.238  1.142  0.145  1.096  1.103 -2.750  0.471  0.446 -1.277 
    34     35     36     37     38     39     40     41     42     43     44 
-1.762  0.108  1.057  0.691  0.962  0.193  0.041  0.811  0.533 -1.367  0.114 
    45     46     47     48     49     50     51     52     53     54     55 
 1.113  0.114  0.988  0.117  0.549  0.234  0.058 -1.336  0.155 -1.458  0.718 
    56     57     58     59     60     61     62     63     64     65     66 
 0.119  0.254 -1.312 -1.464  0.165  0.704 -1.813  0.286  0.575  0.037  0.805 
    67     68     69     70     71     72     73     74     75     76     77 
 0.257  0.477  0.310  0.100  1.237  0.184  0.071  0.479  0.066  0.101  1.143 
    78     79     80     81     82     83     84     85     86     87     88 
 0.048  0.358  0.359  0.831  0.180  0.302  0.240  0.636  0.905  0.084 -1.509 
    89     90     91     92     93     94     95     96     97     98     99 
 0.262  0.043  0.317  0.100  0.203  0.121  1.182  0.290  0.996  0.176  0.059 
   100    101    102    103    104    105    106    107    108    109    110 
 0.288  0.272  0.337  0.198  0.260 -1.276  0.921  0.040  0.038 -1.808  0.111 
   111    112    113    114    115    116    117    118    119    120    121 
 0.175  0.489  0.495  0.068  0.095 -1.731  0.870  0.047  0.088  0.572  0.086 
   122    123    124    125    126    127    128    129    130    131    132 
 1.238 -1.602  0.059  1.151  0.074  0.199  0.796  1.240 -1.275  0.123 -1.170 
   133    134    135    136    137    138    139    140    141    142    143 
 0.119 -2.071  0.113  1.185  0.542  0.819  0.045  0.283  0.432  0.103  0.902 
   144    145    146    147    148    149    150    151    152    153    154 
-1.581  0.569  0.419 -1.331  0.248 -1.325  0.047  0.267  0.895  0.334 -1.217 
   155    156    157    158    159    160    161    162    163    164    165 
 0.659 -1.168  0.471  0.158  0.436  0.386  0.521  0.116  0.046  0.428 -1.760 
   166    167    168    169    170    171    172    173    174    175    176 
 0.202  0.130  0.259  0.540  0.345  0.945  0.709  0.885  0.065  0.286  0.579 
   177    178    179    180    181    182    183    184    185    186    187 
 0.678  0.134  0.286  0.283  0.218  0.045  0.122  0.126  0.928 -2.000  0.059 
   188    189    190    191    192    193    194    195    196    197    198 
 0.361  1.198  0.420 -1.156 -1.136  0.074  0.047  0.066  0.080 -1.379 -1.620 
   199    200    201    202    203    204    205    206    207    208    209 
 0.173  0.205 -1.303  0.253  0.050  0.978  0.327  0.054  0.431  0.488  0.543 
   210    211    212    213    214    215    216    217    218    219    220 
 0.275 -1.338  0.198  0.105  0.913  0.357 -1.416  0.174  0.380  0.818  0.153 
   221    222    223    224    225    226    227    228    229    230    231 
 0.594  0.322  0.255  0.127 -1.184  0.220 -1.493  0.161  0.712  1.081  0.156 
   232    233    234    235    236    237    238    239    240    241    242 
 0.132 -1.492  0.805  0.960  0.615  0.196  0.409  0.792 -1.207  0.085  0.406 
   243    244    245    246    247    248    249    250    251    252    253 
 1.160  0.600 -1.954  0.764  0.815  0.668  0.650  0.066  0.125  1.030  0.128 
   254    255    256    257    258    259    260    261    262    263    264 
 0.469  0.793 -1.110  1.192  0.739  0.794  0.636  0.061  0.052  0.366  0.897 
   265    266    267    268    269    270    271    272    273    274    275 
-1.538 -1.545  0.352 -1.279 -3.208  0.277  0.044  0.072  0.162  1.006  0.911 
   276    277    278    279    280    281    282    283    284    285    286 
 0.591  0.039  0.059  0.316  0.745  0.057  0.131  0.063  0.203 -1.142 -1.314 
   287    288    289    290    291    292    293    294    295    296    297 
 0.049  0.068  0.412  0.112  0.831  0.628  0.322  0.867  0.319 -1.948  0.344 
   298    299    300    301    302    303    304    305    306    307    308 
 0.109  0.432  0.674  0.053  1.192  0.083  0.429  0.219  0.116  0.684  0.989 
   309    310    311    312    313    314    315    316    317    318    319 
 0.066  0.482  0.130 -1.349  0.586  0.303  0.629  0.424  0.484  0.373  0.435 
   320    321    322    323    324    325    326    327    328    329    330 
 0.708  0.203  0.759  0.099  0.101  0.259 -2.479  1.155  0.453  0.212  1.260 
   331    332    333    334    335    336    337    338    339    340    341 
 0.076  1.036 -1.313  0.117  1.194  0.580  0.112 -1.355  0.567  0.599  0.168 
   342    343    344    345    346    347    348    349    350    351    352 
-1.962  0.481 -1.842  0.046  0.173  0.069  0.053  0.137  0.087  0.106  0.066 
   353    354    355    356    357    358    359    360    361    362    363 
 0.091  0.535  0.074  0.105 -1.510  0.906  0.050  0.427 -1.273  0.040 -1.131 
   364    365    366    367    368    369    370    371    372    373    374 
 0.363 -2.159  0.520  0.141  0.686  0.199  0.116  0.151  0.041  0.306  0.196 
   375    376    377    378    379    380    381    382    383    384    385 
 0.694  0.495  0.289  0.041  0.045  0.799  0.501  0.143  0.172 -1.918  0.173 
   386    387    388    389    390    391    392    393    394    395    396 
-1.451  0.067  0.068 -1.414  1.179  0.559 -2.030  0.235  0.349  0.587  0.601 
   397    398    399    400    401    402    403    404    405    406    407 
 0.275  1.146  0.489 -1.719 -1.489  1.126 -1.213  0.043  0.108  1.189  0.307 
   408    409    410    411    412    413    414    415    416    417    418 
 1.221  0.118  0.129 -1.119  0.097  0.080 -2.147  0.217  0.464  0.608  0.124 
   419    420    421    422    423    424    425    426    427    428    429 
 0.162  0.058  0.239  1.135  0.141  0.062  0.164  0.270  0.282  0.540  0.292 
   430    431    432    433    434    435    436    437    438    439    440 
 0.065  0.699  0.093  0.183  0.064  0.656  0.512  0.062  0.115  0.307  0.093 
   441    442    443    444    445    446    447    448    449    450    451 
 0.056  0.646  0.546  0.046 -2.140  0.284  0.105  0.383  0.074  0.165 -1.391 
   452    453    454    455    456    457    458    459    460    461    462 
 0.203  0.106 -1.667  0.077  0.383  0.600  0.038  0.127  0.392 -1.712  0.515 
   463    464    465    466    467    468    469    470    471    472    473 
 0.654  0.122  0.448  0.199  0.752  0.658  0.054 -1.417  0.378  0.104 -1.914 
   474    475    476    477    478    479    480    481    482    483    484 
 0.302  1.146  0.176  0.326  0.512  0.799 -1.206  0.585  0.324  0.551  0.038 
   485    486    487    488    489    490    491    492    493    494    495 
 1.156  1.099  0.183  0.908  0.268 -1.302  0.199  0.555  0.844  0.179 -1.163 
   496    497    498    499    500 
 0.435  0.043  0.472  0.057  1.041 
> all.equal( residuals( ss, part = "selection" ),
+    residuals( ss, part = "selection", type = "deviance" ) )
[1] TRUE
> round( residuals( ss, part = "selection", type = "pearson" ), digits = 3 )
      1       2       3       4       5       6       7       8       9      10 
  0.372   0.052   0.031   0.054   0.316   0.659  -1.129   0.189   0.915   0.232 
     11      12      13      14      15      16      17      18      19      20 
  0.282   0.970   0.181   0.078   0.178  -0.977   0.362   0.831   1.034   0.061 
     21      22      23      24      25      26      27      28      29      30 
  0.449   0.493   0.067   0.341   1.073   0.959   0.103   0.907   0.915  -6.543 
     31      32      33      34      35      36      37      38      39      40 
  0.343   0.324  -1.123  -1.929   0.077   0.865   0.519   0.767   0.137   0.029 
     41      42      43      44      45      46      47      48      49      50 
  0.624   0.390  -1.243   0.081   0.926   0.081   0.793   0.083   0.403   0.166 
     51      52      53      54      55      56      57      58      59      60 
  0.041  -1.200   0.110  -1.377   0.542   0.084   0.181  -1.169  -1.385   0.117 
     61      62      63      64      65      66      67      68      69      70 
  0.530  -2.043   0.204   0.424   0.026   0.618   0.184   0.347   0.222   0.071 
     71      72      73      74      75      76      77      78      79      80 
  1.072   0.131   0.050   0.348   0.047   0.072   0.960   0.034   0.257   0.258 
     81      82      83      84      85      86      87      88      89      90 
  0.642   0.128   0.216   0.171   0.473   0.711   0.059  -1.457   0.187   0.030 
     91      92      93      94      95      96      97      98      99     100 
  0.227   0.071   0.145   0.086   1.006   0.207   0.801   0.125   0.042   0.206 
    101     102     103     104     105     106     107     108     109     110 
  0.194   0.241   0.140   0.185  -1.122   0.727   0.028   0.027  -2.030   0.079 
    111     112     113     114     115     116     117     118     119     120 
  0.124   0.357   0.361   0.048   0.067  -1.864   0.679   0.033   0.062   0.422 
    121     122     123     124     125     126     127     128     129     130 
  0.061   1.073  -1.616   0.042   0.969   0.052   0.142   0.611   1.075  -1.119 
    131     132     133     134     135     136     137     138     139     140 
  0.087  -0.991   0.084  -2.744   0.080   1.009   0.397   0.631   0.031   0.202 
    141     142     143     144     145     146     147     148     149     150 
  0.313   0.073   0.708  -1.578   0.419   0.303  -1.193   0.177  -1.185   0.033 
    151     152     153     154     155     156     157     158     159     160 
  0.191   0.702   0.240  -1.048   0.492  -0.989   0.342   0.112   0.316   0.278 
    161     162     163     164     165     166     167     168     169     170 
  0.381   0.082   0.032   0.310  -1.926   0.143   0.092   0.185   0.397   0.248 
    171     172     173     174     175     176     177     178     179     180 
  0.750   0.534   0.692   0.046   0.204   0.427   0.509   0.095   0.204   0.202 
    181     182     183     184     185     186     187     188     189     190 
  0.155   0.032   0.086   0.089   0.733  -2.529   0.042   0.259   1.024   0.304 
    191     192     193     194     195     196     197     198     199     200 
 -0.975  -0.952   0.052   0.033   0.047   0.057  -1.260  -1.648   0.123   0.146 
    201     202     203     204     205     206     207     208     209     210 
 -1.157   0.180   0.036   0.783   0.235   0.038   0.312   0.355   0.398   0.196 
    211     212     213     214     215     216     217     218     219     220 
 -1.203   0.141   0.074   0.719   0.257  -1.313   0.123   0.274   0.631   0.109 
    221     222     223     224     225     226     227     228     229     230 
  0.439   0.231   0.182   0.090  -1.008   0.157  -1.430   0.114   0.537   0.891 
    231     232     233     234     235     236     237     238     239     240 
  0.111   0.094  -1.430   0.618   0.766   0.456   0.139   0.295   0.607  -1.035 
    241     242     243     244     245     246     247     248     249     250 
  0.060   0.293   0.979   0.444  -2.398   0.583   0.628   0.500   0.485   0.047 
    251     252     253     254     255     256     257     258     259     260 
  0.089   0.836   0.091   0.341   0.608  -0.923   1.017   0.560   0.609   0.474 
    261     262     263     264     265     266     267     268     269     270 
  0.043   0.037   0.263   0.704  -1.505  -1.516   0.253  -1.125 -13.072   0.198 
    271     272     273     274     275     276     277     278     279     280 
  0.031   0.051   0.115   0.811   0.717   0.437   0.028   0.042   0.226   0.565 
    281     282     283     284     285     286     287     288     289     290 
  0.040   0.093   0.044   0.144  -0.958  -1.170   0.034   0.048   0.297   0.079 
    291     292     293     294     295     296     297     298     299     300 
  0.643   0.467   0.230   0.675   0.228  -2.380   0.247   0.077   0.313   0.505 
    301     302     303     304     305     306     307     308     309     310 
  0.038   1.017   0.059   0.311   0.156   0.082   0.513   0.794   0.047   0.351 
    311     312     313     314     315     316     317     318     319     320 
  0.092  -1.218   0.433   0.217   0.468   0.307   0.353   0.268   0.315   0.534 
    321     322     323     324     325     326     327     328     329     330 
  0.144   0.578   0.070   0.072   0.185  -4.536   0.974   0.329   0.151   1.101 
    331     332     333     334     335     336     337     338     339     340 
  0.054   0.843  -1.170   0.083   1.019   0.428   0.080  -1.227   0.417   0.443 
    341     342     343     344     345     346     347     348     349     350 
  0.119  -2.421   0.350  -2.111   0.033   0.123   0.049   0.037   0.097   0.062 
    351     352     353     354     355     356     357     358     359     360 
  0.075   0.047   0.064   0.392   0.052   0.074  -1.458   0.713   0.035   0.309 
    361     362     363     364     365     366     367     368     369     370 
 -1.117   0.028  -0.946   0.261  -3.048   0.381   0.100   0.515   0.141   0.082 
    371     372     373     374     375     376     377     378     379     380 
  0.107   0.029   0.219   0.139   0.522   0.361   0.207   0.029   0.032   0.613 
    381     382     383     384     385     386     387     388     389     390 
  0.365   0.101   0.122  -2.300   0.122  -1.366   0.047   0.048  -1.310   1.002 
    391     392     393     394     395     396     397     398     399     400 
  0.411  -2.618   0.167   0.251   0.433   0.445   0.196   0.964   0.356  -1.840 
    401     402     403     404     405     406     407     408     409     410 
 -1.424   0.941  -1.043   0.030   0.077   1.014   0.219   1.052   0.083   0.091 
    411     412     413     414     415     416     417     418     419     420 
 -0.933   0.068   0.057  -3.005   0.155   0.337   0.451   0.088   0.115   0.041 
    421     422     423     424     425     426     427     428     429     430 
  0.170   0.951   0.100   0.044   0.117   0.193   0.202   0.396   0.209   0.046 
    431     432     433     434     435     436     437     438     439     440 
  0.526   0.066   0.130   0.045   0.490   0.374   0.044   0.082   0.220   0.066 
    441     442     443     444     445     446     447     448     449     450 
  0.039   0.481   0.401   0.032  -2.979   0.203   0.074   0.276   0.052   0.117 
    451     452     453     454     455     456     457     458     459     460 
 -1.277   0.144   0.075  -1.736   0.054   0.276   0.444   0.027   0.090   0.283 
    461     462     463     464     465     466     467     468     469     470 
 -1.824   0.377   0.488   0.086   0.325   0.142   0.572   0.492   0.038  -1.316 
    471     472     473     474     475     476     477     478     479     480 
  0.272   0.074  -2.290   0.216   0.964   0.125   0.233   0.374   0.613  -1.034 
    481     482     483     484     485     486     487     488     489     490 
  0.432   0.232   0.405   0.027   0.975   0.911   0.130   0.714   0.191  -1.154 
    491     492     493     494     495     496     497     498     499     500 
  0.141   0.408   0.654   0.127  -0.984   0.315   0.030   0.343   0.041   0.848 
> round( residuals( ss, part = "selection", type = "response" ), digits = 3 )
     1      2      3      4      5      6      7      8      9     10     11 
 0.122  0.003  0.001  0.003  0.091  0.303 -0.560  0.034  0.455  0.051  0.074 
    12     13     14     15     16     17     18     19     20     21     22 
 0.485  0.032  0.006  0.031 -0.488  0.116  0.409  0.517  0.004  0.167  0.196 
    23     24     25     26     27     28     29     30     31     32     33 
 0.004  0.104  0.535  0.479  0.010  0.451  0.455 -0.977  0.105  0.095 -0.558 
    34     35     36     37     38     39     40     41     42     43     44 
-0.788  0.006  0.428  0.212  0.370  0.018  0.001  0.280  0.132 -0.607  0.007 
    45     46     47     48     49     50     51     52     53     54     55 
 0.462  0.006  0.386  0.007  0.140  0.027  0.002 -0.590  0.012 -0.655  0.227 
    56     57     58     59     60     61     62     63     64     65     66 
 0.007  0.032 -0.577 -0.657  0.014  0.220 -0.807  0.040  0.152  0.001  0.277 
    67     68     69     70     71     72     73     74     75     76     77 
 0.033  0.108  0.047  0.005  0.535  0.017  0.002  0.108  0.002  0.005  0.479 
    78     79     80     81     82     83     84     85     86     87     88 
 0.001  0.062  0.063  0.292  0.016  0.045  0.028  0.183  0.336  0.003 -0.680 
    89     90     91     92     93     94     95     96     97     98     99 
 0.034  0.001  0.049  0.005  0.020  0.007  0.503  0.041  0.391  0.015  0.002 
   100    101    102    103    104    105    106    107    108    109    110 
 0.041  0.036  0.055  0.019  0.033 -0.557  0.346  0.001  0.001 -0.805  0.006 
   111    112    113    114    115    116    117    118    119    120    121 
 0.015  0.113  0.115  0.002  0.004 -0.777  0.315  0.001  0.004  0.151  0.004 
   122    123    124    125    126    127    128    129    130    131    132 
 0.535 -0.723  0.002  0.484  0.003  0.020  0.272  0.536 -0.556  0.008 -0.495 
   133    134    135    136    137    138    139    140    141    142    143 
 0.007 -0.883  0.006  0.505  0.136  0.285  0.001  0.039  0.089  0.005  0.334 
   144    145    146    147    148    149    150    151    152    153    154 
-0.714  0.150  0.084 -0.587  0.030 -0.584  0.001  0.035  0.330  0.054 -0.523 
   155    156    157    158    159    160    161    162    163    164    165 
 0.195 -0.494  0.105  0.012  0.091  0.072  0.127  0.007  0.001  0.088 -0.788 
   166    167    168    169    170    171    172    173    174    175    176 
 0.020  0.008  0.033  0.136  0.058  0.360  0.222  0.324  0.002  0.040  0.154 
   177    178    179    180    181    182    183    184    185    186    187 
 0.206  0.009  0.040  0.039  0.024  0.001  0.007  0.008  0.350 -0.865  0.002 
   188    189    190    191    192    193    194    195    196    197    198 
 0.063  0.512  0.084 -0.487 -0.475  0.003  0.001  0.002  0.003 -0.614 -0.731 
   199    200    201    202    203    204    205    206    207    208    209 
 0.015  0.021 -0.572  0.031  0.001  0.380  0.052  0.001  0.089  0.112  0.137 
   210    211    212    213    214    215    216    217    218    219    220 
 0.037 -0.591  0.019  0.006  0.341  0.062 -0.633  0.015  0.070  0.285  0.012 
   221    222    223    224    225    226    227    228    229    230    231 
 0.162  0.051  0.032  0.008 -0.504  0.024 -0.672  0.013  0.224  0.442  0.012 
   232    233    234    235    236    237    238    239    240    241    242 
 0.009 -0.672  0.277  0.369  0.172  0.019  0.080  0.269 -0.517  0.004  0.079 
   243    244    245    246    247    248    249    250    251    252    253 
 0.489  0.164 -0.852  0.253  0.283  0.200  0.191  0.002  0.008  0.411  0.008 
   254    255    256    257    258    259    260    261    262    263    264 
 0.104  0.270 -0.460  0.509  0.239  0.270  0.183  0.002  0.001  0.065  0.331 
   265    266    267    268    269    270    271    272    273    274    275 
-0.694 -0.697  0.060 -0.559 -0.994  0.038  0.001  0.003  0.013  0.397  0.340 
   276    277    278    279    280    281    282    283    284    285    286 
 0.160  0.001  0.002  0.049  0.242  0.002  0.009  0.002  0.020 -0.479 -0.578 
   287    288    289    290    291    292    293    294    295    296    297 
 0.001  0.002  0.081  0.006  0.292  0.179  0.050  0.313  0.049 -0.850  0.057 
   298    299    300    301    302    303    304    305    306    307    308 
 0.006  0.089  0.203  0.001  0.508  0.003  0.088  0.024  0.007  0.209  0.387 
   309    310    311    312    313    314    315    316    317    318    319 
 0.002  0.110  0.008 -0.597  0.158  0.045  0.180  0.086  0.111  0.067  0.090 
   320    321    322    323    324    325    326    327    328    329    330 
 0.222  0.020  0.250  0.005  0.005  0.033 -0.954  0.487  0.098  0.022  0.548 
   331    332    333    334    335    336    337    338    339    340    341 
 0.003  0.415 -0.578  0.007  0.510  0.155  0.006 -0.601  0.148  0.164  0.014 
   342    343    344    345    346    347    348    349    350    351    352 
-0.854  0.109 -0.817  0.001  0.015  0.002  0.001  0.009  0.004  0.006  0.002 
   353    354    355    356    357    358    359    360    361    362    363 
 0.004  0.133  0.003  0.005 -0.680  0.337  0.001  0.087 -0.555  0.001 -0.472 
   364    365    366    367    368    369    370    371    372    373    374 
 0.064 -0.903  0.127  0.010  0.210  0.020  0.007  0.011  0.001  0.046  0.019 
   375    376    377    378    379    380    381    382    383    384    385 
 0.214  0.115  0.041  0.001  0.001  0.273  0.118  0.010  0.015 -0.841  0.015 
   386    387    388    389    390    391    392    393    394    395    396 
-0.651  0.002  0.002 -0.632  0.501  0.145 -0.873  0.027  0.059  0.158  0.165 
   397    398    399    400    401    402    403    404    405    406    407 
 0.037  0.481  0.113 -0.772 -0.670  0.470 -0.521  0.001  0.006  0.507  0.046 
   408    409    410    411    412    413    414    415    416    417    418 
 0.525  0.007  0.008 -0.465  0.005  0.003 -0.900  0.023  0.102  0.169  0.008 
   419    420    421    422    423    424    425    426    427    428    429 
 0.013  0.002  0.028  0.475  0.010  0.002  0.013  0.036  0.039  0.136  0.042 
   430    431    432    433    434    435    436    437    438    439    440 
 0.002  0.217  0.004  0.017  0.002  0.193  0.123  0.002  0.007  0.046  0.004 
   441    442    443    444    445    446    447    448    449    450    451 
 0.002  0.188  0.139  0.001 -0.899  0.040  0.006  0.071  0.003  0.013 -0.620 
   452    453    454    455    456    457    458    459    460    461    462 
 0.020  0.006 -0.751  0.003  0.071  0.165  0.001  0.008  0.074 -0.769  0.124 
   463    464    465    466    467    468    469    470    471    472    473 
 0.192  0.007  0.095  0.020  0.247  0.195  0.001 -0.634  0.069  0.005 -0.840 
   474    475    476    477    478    479    480    481    482    483    484 
 0.045  0.482  0.015  0.052  0.123  0.273 -0.517  0.158  0.051  0.141  0.001 
   485    486    487    488    489    490    491    492    493    494    495 
 0.487  0.453  0.017  0.338  0.035 -0.571  0.020  0.143  0.300  0.016 -0.492 
   496    497    498    499    500 
 0.090  0.001  0.105  0.002  0.418 
> all.equal( residuals( ss, part = "selection", type = "response" ),
+    simDat$ys - fitted( ss, part = "selection" ) )
[1] TRUE
> model.matrix( ss )
    (Intercept)      xo
1             1 0.32067
2             1 0.52602
3             1 0.07334
4             1 0.84974
5             1 0.42306
6             1 0.98810
7            NA      NA
8             1 0.90569
9             1 0.01851
10            1 0.19214
11            1 0.38431
12            1 0.30744
13            1 0.52829
14            1 0.72823
15            1 0.95356
16           NA      NA
17            1 0.13202
18            1 0.60847
19            1 0.99187
20            1 0.09471
21            1 0.89528
22            1 0.33486
23            1 0.47218
24            1 0.17712
25            1 0.35166
26            1 0.17656
27            1 0.65305
28            1 0.23610
29            1 0.89716
30           NA      NA
31            1 0.92380
32            1 0.49774
33           NA      NA
34           NA      NA
35            1 0.21483
36            1 0.30531
37            1 0.86350
38            1 0.19572
39            1 0.85095
40            1 0.94697
41            1 0.27456
42            1 0.83986
43           NA      NA
44            1 0.75705
45            1 0.44613
46            1 0.95543
47            1 0.63533
48            1 0.16410
49            1 0.40697
50            1 0.97976
51            1 0.14694
52           NA      NA
53            1 0.19670
54           NA      NA
55            1 0.79254
56            1 0.73380
57            1 0.75172
58           NA      NA
59           NA      NA
60            1 0.45588
61            1 0.25400
62           NA      NA
63            1 0.43530
64            1 0.77113
65            1 0.12916
66            1 0.98392
67            1 0.81418
68            1 0.98168
69            1 0.03634
70            1 0.56741
71            1 0.40172
72            1 0.45705
73            1 0.40332
74            1 0.57221
75            1 0.26025
76            1 0.87409
77            1 0.99309
78            1 0.93020
79            1 0.98653
80            1 0.65834
81            1 0.30239
82            1 0.86742
83            1 0.67126
84            1 0.48920
85            1 0.62858
86            1 0.69066
87            1 0.67229
88           NA      NA
89            1 0.68774
90            1 0.99986
91            1 0.25054
92            1 0.47847
93            1 0.01510
94            1 0.25202
95            1 0.32666
96            1 0.67213
97            1 0.74844
98            1 0.34244
99            1 0.28026
100           1 0.73738
101           1 0.62697
102           1 0.63354
103           1 0.21598
104           1 0.90594
105          NA      NA
106           1 0.16858
107           1 0.68320
108           1 0.11399
109          NA      NA
110           1 0.94151
111           1 0.14895
112           1 0.58912
113           1 0.87828
114           1 0.17816
115           1 0.47083
116          NA      NA
117           1 0.09938
118           1 0.29035
119           1 0.24548
120           1 0.72256
121           1 0.53627
122           1 0.29900
123          NA      NA
124           1 0.91018
125           1 0.03297
126           1 0.59632
127           1 0.15091
128           1 0.57765
129           1 0.45448
130          NA      NA
131           1 0.52621
132          NA      NA
133           1 0.92890
134          NA      NA
135           1 0.24476
136           1 0.87626
137           1 0.18266
138           1 0.09032
139           1 0.23916
140           1 0.86143
141           1 0.83256
142           1 0.36291
143           1 0.18791
144          NA      NA
145           1 0.44079
146           1 0.47671
147          NA      NA
148           1 0.08918
149          NA      NA
150           1 0.63567
151           1 0.19854
152           1 0.26161
153           1 0.31876
154          NA      NA
155           1 0.05209
156          NA      NA
157           1 0.57226
158           1 0.03691
159           1 0.01809
160           1 0.19655
161           1 0.34098
162           1 0.28365
163           1 0.18633
164           1 0.20442
165          NA      NA
166           1 0.40610
167           1 0.86717
168           1 0.27581
169           1 0.75255
170           1 0.34063
171           1 0.96010
172           1 0.62854
173           1 0.84531
174           1 0.12228
175           1 0.55571
176           1 0.77643
177           1 0.25938
178           1 0.49898
179           1 0.58442
180           1 0.48475
181           1 0.60854
182           1 0.02086
183           1 0.38280
184           1 0.38162
185           1 0.06741
186          NA      NA
187           1 0.76474
188           1 0.80158
189           1 0.20403
190           1 0.91786
191          NA      NA
192          NA      NA
193           1 0.51343
194           1 0.13278
195           1 0.33798
196           1 0.21300
197          NA      NA
198          NA      NA
199           1 0.33625
200           1 0.14465
201          NA      NA
202           1 0.05432
203           1 0.61388
204           1 0.78563
205           1 0.57945
206           1 0.52717
207           1 0.41051
208           1 0.73052
209           1 0.88360
210           1 0.11448
211          NA      NA
212           1 0.36676
213           1 0.25395
214           1 0.12075
215           1 0.58297
216          NA      NA
217           1 0.57975
218           1 0.59065
219           1 0.97719
220           1 0.24613
221           1 0.47724
222           1 0.16025
223           1 0.78917
224           1 0.09575
225          NA      NA
226           1 0.07575
227          NA      NA
228           1 0.19411
229           1 0.71458
230           1 0.95579
231           1 0.74186
232           1 0.25603
233          NA      NA
234           1 0.13282
235           1 0.18019
236           1 0.07994
237           1 0.27118
238           1 0.44013
239           1 0.71146
240          NA      NA
241           1 0.15047
242           1 0.59951
243           1 0.89062
244           1 0.38870
245          NA      NA
246           1 0.80721
247           1 0.11808
248           1 0.76427
249           1 0.12625
250           1 0.85453
251           1 0.53677
252           1 0.59619
253           1 0.86305
254           1 0.86744
255           1 0.05909
256          NA      NA
257           1 0.34248
258           1 0.82457
259           1 0.52929
260           1 0.43724
261           1 0.05643
262           1 0.24777
263           1 0.39809
264           1 0.11121
265          NA      NA
266          NA      NA
267           1 0.85053
268          NA      NA
269          NA      NA
270           1 0.71772
271           1 0.09516
272           1 0.47922
273           1 0.12714
274           1 0.26424
275           1 0.22704
276           1 0.18450
277           1 0.01726
278           1 0.28163
279           1 0.12104
280           1 0.40643
281           1 0.78917
282           1 0.10587
283           1 0.34159
284           1 0.33359
285          NA      NA
286          NA      NA
287           1 0.78717
288           1 0.79759
289           1 0.22391
290           1 0.46616
291           1 0.32234
292           1 0.54453
293           1 0.97157
294           1 0.14930
295           1 0.36368
296          NA      NA
297           1 0.58661
298           1 0.53979
299           1 0.87389
300           1 0.76943
301           1 0.45084
302           1 0.93905
303           1 0.55859
304           1 0.57100
305           1 0.10731
306           1 0.38876
307           1 0.97748
308           1 0.22145
309           1 0.22006
310           1 0.28217
311           1 0.11922
312          NA      NA
313           1 0.28445
314           1 0.64428
315           1 0.96036
316           1 0.07109
317           1 0.03792
318           1 0.04046
319           1 0.41692
320           1 0.25226
321           1 0.10859
322           1 0.86088
323           1 0.15139
324           1 0.54888
325           1 0.51072
326          NA      NA
327           1 0.68298
328           1 0.74844
329           1 0.95252
330           1 0.36261
331           1 0.34629
332           1 0.45423
333          NA      NA
334           1 0.52909
335           1 0.00282
336           1 0.86187
337           1 0.55689
338          NA      NA
339           1 0.95033
340           1 0.90017
341           1 0.69395
342          NA      NA
343           1 0.46319
344          NA      NA
345           1 0.43910
346           1 0.96992
347           1 0.27955
348           1 0.97947
349           1 0.68293
350           1 0.90801
351           1 0.66998
352           1 0.41306
353           1 0.93139
354           1 0.14916
355           1 0.01702
356           1 0.57650
357          NA      NA
358           1 0.28937
359           1 0.27640
360           1 0.60834
361          NA      NA
362           1 0.29098
363          NA      NA
364           1 0.82154
365          NA      NA
366           1 0.98572
367           1 0.61545
368           1 0.83248
369           1 0.23662
370           1 0.77090
371           1 0.05877
372           1 0.51490
373           1 0.86101
374           1 0.98540
375           1 0.39676
376           1 0.46828
377           1 0.42066
378           1 0.91563
379           1 0.48231
380           1 0.94241
381           1 0.12418
382           1 0.56371
383           1 0.73124
384          NA      NA
385           1 0.62836
386          NA      NA
387           1 0.08576
388           1 0.67620
389          NA      NA
390           1 0.09610
391           1 0.39890
392          NA      NA
393           1 0.79457
394           1 0.62454
395           1 0.40501
396           1 0.00259
397           1 0.60858
398           1 0.59234
399           1 0.91016
400          NA      NA
401          NA      NA
402           1 0.25509
403          NA      NA
404           1 0.52525
405           1 0.45407
406           1 0.52172
407           1 0.08570
408           1 0.59755
409           1 0.68352
410           1 0.54936
411          NA      NA
412           1 0.29624
413           1 0.28450
414          NA      NA
415           1 0.16767
416           1 0.91739
417           1 0.99091
418           1 0.74767
419           1 0.49254
420           1 0.93281
421           1 0.61704
422           1 0.39170
423           1 0.19638
424           1 0.72008
425           1 0.93417
426           1 0.69264
427           1 0.88858
428           1 0.22867
429           1 0.54657
430           1 0.20700
431           1 0.53705
432           1 0.96928
433           1 0.80323
434           1 0.20405
435           1 0.40065
436           1 0.82912
437           1 0.44113
438           1 0.39505
439           1 0.03089
440           1 0.13587
441           1 0.67718
442           1 0.06249
443           1 0.99754
444           1 0.11385
445          NA      NA
446           1 0.02559
447           1 0.10831
448           1 0.45408
449           1 0.80019
450           1 0.83482
451          NA      NA
452           1 0.28282
453           1 0.64290
454          NA      NA
455           1 0.53711
456           1 0.43145
457           1 0.72412
458           1 0.17412
459           1 0.32032
460           1 0.38798
461          NA      NA
462           1 0.27792
463           1 0.71545
464           1 0.32855
465           1 0.60146
466           1 0.52392
467           1 0.86055
468           1 0.53277
469           1 0.11142
470          NA      NA
471           1 0.06294
472           1 0.70529
473          NA      NA
474           1 0.78132
475           1 0.78414
476           1 0.55258
477           1 0.85511
478           1 0.20987
479           1 0.23006
480          NA      NA
481           1 0.44478
482           1 0.66007
483           1 0.07782
484           1 0.34325
485           1 0.80745
486           1 0.34898
487           1 0.05208
488           1 0.86328
489           1 0.55692
490          NA      NA
491           1 0.76130
492           1 0.54554
493           1 0.47788
494           1 0.34743
495          NA      NA
496           1 0.95077
497           1 0.26138
498           1 0.10681
499           1 0.25376
500           1 0.18090
attr(,"assign")
[1] 0 1
> all.equal( model.matrix( ss ), model.matrix( ss, part = "outcome" ) )
[1] TRUE
> model.matrix( ss, part = "selection" )
    (Intercept)       xs
1             1 0.387113
2             1 0.871805
3             1 0.967197
4             1 0.866916
5             1 0.437715
6             1 0.191938
7             1 0.082294
8             1 0.583452
9             1 0.070361
10            1 0.527663
11            1 0.472288
12            1 0.048191
13            1 0.594541
14            1 0.791271
15            1 0.598869
16            1 0.027916
17            1 0.395727
18            1 0.106244
19            1 0.024111
20            1 0.840898
21            1 0.326400
22            1 0.294298
23            1 0.822898
24            1 0.414347
25            1 0.010171
26            1 0.052408
27            1 0.730370
28            1 0.073395
29            1 0.070357
30            1 0.637172
31            1 0.413306
32            1 0.430718
33            1 0.080246
34            1 0.277117
35            1 0.794071
36            1 0.091097
37            1 0.276682
38            1 0.136255
39            1 0.663476
40            1 0.979130
41            1 0.211811
42            1 0.372027
43            1 0.118365
44            1 0.782724
45            1 0.065578
46            1 0.783775
47            1 0.123852
48            1 0.777342
49            1 0.361349
50            1 0.615930
51            1 0.917043
52            1 0.105220
53            1 0.715546
54            1 0.156367
55            1 0.261576
56            1 0.773791
57            1 0.594759
58            1 0.095377
59            1 0.158468
60            1 0.701091
61            1 0.269183
62            1 0.296830
63            1 0.562665
64            1 0.345177
65            1 0.996363
66            1 0.214890
67            1 0.590747
68            1 0.408991
69            1 0.539929
70            1 0.809807
71            1 0.010653
72            1 0.674990
73            1 0.880182
74            1 0.408089
75            1 0.894052
76            1 0.807851
77            1 0.052268
78            1 0.951139
79            1 0.498940
80            1 0.497459
81            1 0.201222
82            1 0.680997
83            1 0.547304
84            1 0.609578
85            1 0.308183
86            1 0.164061
87            1 0.847400
88            1 0.177071
89            1 0.586211
90            1 0.972557
91            1 0.534099
92            1 0.810916
93            1 0.650907
94            1 0.770981
95            1 0.034558
96            1 0.558660
97            1 0.120087
98            1 0.686300
99            1 0.914126
100           1 0.560350
101           1 0.575576
102           1 0.516750
103           1 0.658049
104           1 0.588397
105           1 0.079925
106           1 0.156136
107           1 0.985081
108           1 0.991830
109           1 0.294756
110           1 0.788712
111           1 0.686831
112           1 0.400827
113           1 0.396841
114           1 0.887414
115           1 0.822078
116           1 0.265245
117           1 0.181171
118           1 0.956474
119           1 0.837400
120           1 0.346653
121           1 0.842086
122           1 0.010130
123           1 0.214542
124           1 0.913735
125           1 0.048655
126           1 0.871231
127           1 0.655788
128           1 0.219372
129           1 0.009437
130           1 0.079214
131           1 0.767451
132           1 0.033288
133           1 0.774952
134           1 0.393960
135           1 0.784817
136           1 0.033332
137           1 0.366152
138           1 0.207688
139           1 0.965913
140           1 0.564966
141           1 0.441116
142           1 0.803868
143           1 0.165633
144           1 0.206119
145           1 0.348587
146           1 0.450815
147           1 0.103177
148           1 0.600618
149           1 0.100578
150           1 0.957186
151           1 0.580974
152           1 0.168894
153           1 0.518571
154           1 0.054323
155           1 0.295023
156           1 0.032474
157           1 0.413448
158           1 0.710805
159           1 0.438294
160           1 0.476030
161           1 0.379705
162           1 0.779968
163           1 0.961577
164           1 0.443998
165           1 0.276577
166           1 0.652875
167           1 0.754724
168           1 0.588706
169           1 0.366898
170           1 0.509391
171           1 0.144229
172           1 0.266655
173           1 0.173821
174           1 0.896527
175           1 0.562343
176           1 0.342454
177           1 0.283730
178           1 0.747538
179           1 0.562850
180           1 0.565386
181           1 0.633332
182           1 0.962587
183           1 0.768941
184           1 0.761524
185           1 0.152722
186           1 0.367798
187           1 0.913616
188           1 0.496350
189           1 0.027735
190           1 0.450139
191           1 0.027188
192           1 0.018271
193           1 0.871962
194           1 0.955189
195           1 0.892738
196           1 0.856309
197           1 0.123533
198           1 0.221655
199           1 0.690272
200           1 0.648772
201           1 0.091445
202           1 0.595570
203           1 0.944378
204           1 0.128658
205           1 0.524702
206           1 0.931876
207           1 0.441982
208           1 0.401972
209           1 0.365523
210           1 0.572830
211           1 0.106167
212           1 0.657214
213           1 0.800479
214           1 0.160081
215           1 0.499150
216           1 0.138866
217           1 0.688598
218           1 0.480642
219           1 0.207813
220           1 0.717721
221           1 0.333421
222           1 0.529427
223           1 0.593499
224           1 0.759889
225           1 0.039696
226           1 0.631180
227           1 0.170350
228           1 0.707257
229           1 0.264722
230           1 0.080322
231           1 0.713207
232           1 0.750814
233           1 0.170226
234           1 0.214822
235           1 0.136855
236           1 0.320705
237           1 0.659653
238           1 0.458247
239           1 0.221784
240           1 0.049692
241           1 0.842967
242           1 0.460356
243           1 0.044669
244           1 0.330020
245           1 0.350482
246           1 0.236221
247           1 0.209323
248           1 0.289585
249           1 0.299830
250           1 0.893524
251           1 0.762661
252           1 0.104029
253           1 0.758670
254           1 0.414734
255           1 0.221036
256           1 0.006719
257           1 0.030251
258           1 0.250102
259           1 0.220495
260           1 0.308081
261           1 0.908893
262           1 0.938503
263           1 0.491905
264           1 0.168020
265           1 0.188895
266           1 0.191555
267           1 0.503482
268           1 0.081112
269           1 0.794697
270           1 0.571347
271           1 0.967688
272           1 0.875769
273           1 0.705853
274           1 0.115355
275           1 0.160992
276           1 0.335154
277           1 0.988609
278           1 0.914079
279           1 0.535097
280           1 0.246894
281           1 0.922347
282           1 0.753490
283           1 0.903507
284           1 0.651548
285           1 0.020779
286           1 0.095879
287           1 0.949587
288           1 0.888177
289           1 0.456234
290           1 0.786744
291           1 0.201027
292           1 0.312703
293           1 0.529762
294           1 0.182999
295           1 0.532406
296           1 0.348114
297           1 0.510248
298           1 0.792196
299           1 0.441211
300           1 0.286292
301           1 0.933560
302           1 0.030451
303           1 0.848986
304           1 0.443183
305           1 0.632075
306           1 0.779914
307           1 0.280474
308           1 0.123204
309           1 0.893433
310           1 0.405973
311           1 0.755108
312           1 0.110817
313           1 0.338309
314           1 0.546493
315           1 0.312132
316           1 0.447295
317           1 0.404281
318           1 0.486564
319           1 0.439168
320           1 0.266864
321           1 0.651878
322           1 0.239049
323           1 0.813316
324           1 0.808245
325           1 0.589045
326           1 0.541867
327           1 0.046548
328           1 0.425856
329           1 0.640640
330           1 0.000656
331           1 0.866388
332           1 0.101045
333           1 0.095740
334           1 0.777240
335           1 0.029511
336           1 0.342072
337           1 0.786316
338           1 0.113463
339           1 0.350253
340           1 0.330214
341           1 0.696677
342           1 0.353614
343           1 0.406179
344           1 0.308030
345           1 0.959203
346           1 0.690269
347           1 0.885740
348           1 0.935855
349           1 0.744080
350           1 0.838446
351           1 0.799357
352           1 0.893640
353           1 0.831137
354           1 0.370750
355           1 0.871980
356           1 0.800762
357           1 0.177285
358           1 0.163278
359           1 0.944489
360           1 0.444638
361           1 0.078393
362           1 0.985572
363           1 0.015838
364           1 0.494883
365           1 0.426626
366           1 0.380065
367           1 0.736944
368           1 0.279538
369           1 0.656284
370           1 0.779726
371           1 0.722053
372           1 0.982406
373           1 0.543323
374           1 0.659888
375           1 0.275039
376           1 0.396944
377           1 0.559185
378           1 0.980950
379           1 0.964967
380           1 0.218040
381           1 0.393171
382           1 0.734231
383           1 0.691589
384           1 0.336752
385           1 0.690482
386           1 0.153450
387           1 0.890399
388           1 0.888446
389           1 0.138003
390           1 0.035949
391           1 0.355017
392           1 0.378946
393           1 0.614777
394           1 0.506189
395           1 0.337955
396           1 0.329130
397           1 0.573297
398           1 0.050710
399           1 0.400963
400           1 0.260631
401           1 0.168700
402           1 0.059731
403           1 0.052582
404           1 0.972770
405           1 0.794608
406           1 0.031668
407           1 0.543285
408           1 0.017597
409           1 0.776670
410           1 0.757301
411           1 0.010548
412           1 0.817914
413           1 0.856346
414           1 0.422310
415           1 0.634296
416           1 0.418075
417           1 0.324664
418           1 0.765787
419           1 0.704656
420           1 0.919051
421           1 0.610137
422           1 0.055855
423           1 0.736152
424           1 0.903968
425           1 0.701815
426           1 0.577700
427           1 0.565839
428           1 0.367176
429           1 0.556922
430           1 0.897090
431           1 0.272231
432           1 0.826333
433           1 0.675996
434           1 0.899367
435           1 0.296660
436           1 0.385464
437           1 0.905350
438           1 0.781176
439           1 0.542551
440           1 0.826008
441           1 0.925736
442           1 0.302508
443           1 0.363235
444           1 0.960561
445           1 0.419576
446           1 0.564240
447           1 0.800476
448           1 0.478195
449           1 0.871664
450           1 0.701587
451           1 0.128367
452           1 0.651634
453           1 0.799508
454           1 0.240165
455           1 0.863995
456           1 0.478795
457           1 0.329742
458           1 0.995426
459           1 0.759542
460           1 0.471065
461           1 0.257584
462           1 0.383511
463           1 0.297954
464           1 0.768626
465           1 0.429740
466           1 0.655967
467           1 0.242657
468           1 0.295185
469           1 0.929919
470           1 0.139466
471           1 0.482361
472           1 0.801726
473           1 0.335298
474           1 0.547301
475           1 0.050614
476           1 0.685185
477           1 0.526017
478           1 0.385401
479           1 0.218078
480           1 0.049256
481           1 0.338604
482           1 0.527543
483           1 0.360100
484           1 0.991589
485           1 0.046358
486           1 0.071902
487           1 0.676367
488           1 0.162360
489           1 0.580374
490           1 0.090766
491           1 0.656099
492           1 0.357507
493           1 0.194491
494           1 0.681934
495           1 0.030555
496           1 0.439074
497           1 0.973690
498           1 0.412593
499           1 0.919770
500           1 0.098764
attr(,"assign")
[1] 0 1
> model.frame( ss )
       ys       xs yo       xo
1    TRUE 0.387113  0 0.320667
2    TRUE 0.871805  1 0.526019
3    TRUE 0.967197  0 0.073335
4    TRUE 0.866916  1 0.849742
5    TRUE 0.437715  1 0.423058
6    TRUE 0.191938  1 0.988096
7   FALSE 0.082294  0 0.478874
8    TRUE 0.583452  1 0.905694
9    TRUE 0.070361  0 0.018506
10   TRUE 0.527663  0 0.192144
11   TRUE 0.472288  1 0.384307
12   TRUE 0.048191  1 0.307436
13   TRUE 0.594541  1 0.528291
14   TRUE 0.791271  1 0.728226
15   TRUE 0.598869  1 0.953557
16  FALSE 0.027916  0 0.495994
17   TRUE 0.395727  0 0.132017
18   TRUE 0.106244  1 0.608469
19   TRUE 0.024111  1 0.991869
20   TRUE 0.840898  0 0.094710
21   TRUE 0.326400  1 0.895283
22   TRUE 0.294298  0 0.334861
23   TRUE 0.822898  0 0.472178
24   TRUE 0.414347  0 0.177118
25   TRUE 0.010171  0 0.351655
26   TRUE 0.052408  0 0.176559
27   TRUE 0.730370  1 0.653046
28   TRUE 0.073395  0 0.236101
29   TRUE 0.070357  1 0.897164
30  FALSE 0.637172  0 0.339148
31   TRUE 0.413306  1 0.923796
32   TRUE 0.430718  0 0.497739
33  FALSE 0.080246  0 0.569841
34  FALSE 0.277117  0 0.736780
35   TRUE 0.794071  0 0.214828
36   TRUE 0.091097  0 0.305313
37   TRUE 0.276682  1 0.863500
38   TRUE 0.136255  1 0.195720
39   TRUE 0.663476  1 0.850946
40   TRUE 0.979130  0 0.946971
41   TRUE 0.211811  1 0.274561
42   TRUE 0.372027  1 0.839856
43  FALSE 0.118365  0 0.143856
44   TRUE 0.782724  1 0.757050
45   TRUE 0.065578  1 0.446127
46   TRUE 0.783775  1 0.955432
47   TRUE 0.123852  0 0.635325
48   TRUE 0.777342  0 0.164101
49   TRUE 0.361349  1 0.406969
50   TRUE 0.615930  1 0.979760
51   TRUE 0.917043  0 0.146939
52  FALSE 0.105220  0 0.889985
53   TRUE 0.715546  0 0.196703
54  FALSE 0.156367  0 0.620587
55   TRUE 0.261576  1 0.792541
56   TRUE 0.773791  0 0.733796
57   TRUE 0.594759  1 0.751720
58  FALSE 0.095377  0 0.524456
59  FALSE 0.158468  0 0.629952
60   TRUE 0.701091  1 0.455877
61   TRUE 0.269183  0 0.254005
62  FALSE 0.296830  0 0.057486
63   TRUE 0.562665  1 0.435303
64   TRUE 0.345177  1 0.771135
65   TRUE 0.996363  0 0.129155
66   TRUE 0.214890  1 0.983916
67   TRUE 0.590747  1 0.814177
68   TRUE 0.408991  1 0.981681
69   TRUE 0.539929  0 0.036340
70   TRUE 0.809807  0 0.567414
71   TRUE 0.010653  1 0.401718
72   TRUE 0.674990  0 0.457046
73   TRUE 0.880182  0 0.403324
74   TRUE 0.408089  0 0.572206
75   TRUE 0.894052  0 0.260251
76   TRUE 0.807851  1 0.874088
77   TRUE 0.052268  1 0.993087
78   TRUE 0.951139  1 0.930202
79   TRUE 0.498940  1 0.986528
80   TRUE 0.497459  0 0.658343
81   TRUE 0.201222  0 0.302385
82   TRUE 0.680997  1 0.867420
83   TRUE 0.547304  1 0.671260
84   TRUE 0.609578  1 0.489200
85   TRUE 0.308183  0 0.628584
86   TRUE 0.164061  1 0.690660
87   TRUE 0.847400  0 0.672291
88  FALSE 0.177071  0 0.882118
89   TRUE 0.586211  0 0.687738
90   TRUE 0.972557  0 0.999863
91   TRUE 0.534099  0 0.250536
92   TRUE 0.810916  1 0.478467
93   TRUE 0.650907  0 0.015101
94   TRUE 0.770981  0 0.252020
95   TRUE 0.034558  1 0.326658
96   TRUE 0.558660  1 0.672132
97   TRUE 0.120087  1 0.748441
98   TRUE 0.686300  1 0.342436
99   TRUE 0.914126  0 0.280260
100  TRUE 0.560350  0 0.737378
101  TRUE 0.575576  0 0.626969
102  TRUE 0.516750  1 0.633542
103  TRUE 0.658049  1 0.215981
104  TRUE 0.588397  1 0.905941
105 FALSE 0.079925  0 0.586246
106  TRUE 0.156136  0 0.168584
107  TRUE 0.985081  0 0.683198
108  TRUE 0.991830  1 0.113991
109 FALSE 0.294756  0 0.527885
110  TRUE 0.788712  0 0.941510
111  TRUE 0.686831  0 0.148946
112  TRUE 0.400827  1 0.589122
113  TRUE 0.396841  0 0.878276
114  TRUE 0.887414  0 0.178157
115  TRUE 0.822078  1 0.470834
116 FALSE 0.265245  0 0.141462
117  TRUE 0.181171  1 0.099383
118  TRUE 0.956474  0 0.290351
119  TRUE 0.837400  0 0.245476
120  TRUE 0.346653  1 0.722559
121  TRUE 0.842086  0 0.536275
122  TRUE 0.010130  1 0.299001
123 FALSE 0.214542  0 0.199700
124  TRUE 0.913735  1 0.910177
125  TRUE 0.048655  0 0.032971
126  TRUE 0.871231  1 0.596324
127  TRUE 0.655788  1 0.150905
128  TRUE 0.219372  1 0.577648
129  TRUE 0.009437  1 0.454477
130 FALSE 0.079214  0 0.493809
131  TRUE 0.767451  1 0.526207
132 FALSE 0.033288  0 0.383013
133  TRUE 0.774952  1 0.928898
134 FALSE 0.393960  0 0.433418
135  TRUE 0.784817  0 0.244762
136  TRUE 0.033332  1 0.876257
137  TRUE 0.366152  0 0.182660
138  TRUE 0.207688  0 0.090324
139  TRUE 0.965913  1 0.239160
140  TRUE 0.564966  0 0.861430
141  TRUE 0.441116  0 0.832556
142  TRUE 0.803868  1 0.362913
143  TRUE 0.165633  1 0.187907
144 FALSE 0.206119  0 0.768746
145  TRUE 0.348587  0 0.440788
146  TRUE 0.450815  1 0.476709
147 FALSE 0.103177  0 0.980657
148  TRUE 0.600618  0 0.089181
149 FALSE 0.100578  0 0.097385
150  TRUE 0.957186  1 0.635669
151  TRUE 0.580974  1 0.198539
152  TRUE 0.168894  1 0.261605
153  TRUE 0.518571  0 0.318762
154 FALSE 0.054323  0 0.869577
155  TRUE 0.295023  0 0.052089
156 FALSE 0.032474  0 0.203911
157  TRUE 0.413448  1 0.572259
158  TRUE 0.710805  1 0.036906
159  TRUE 0.438294  0 0.018092
160  TRUE 0.476030  0 0.196550
161  TRUE 0.379705  0 0.340977
162  TRUE 0.779968  0 0.283653
163  TRUE 0.961577  1 0.186334
164  TRUE 0.443998  0 0.204422
165 FALSE 0.276577  0 0.231853
166  TRUE 0.652875  1 0.406102
167  TRUE 0.754724  1 0.867170
168  TRUE 0.588706  0 0.275813
169  TRUE 0.366898  1 0.752555
170  TRUE 0.509391  0 0.340631
171  TRUE 0.144229  1 0.960103
172  TRUE 0.266655  1 0.628541
173  TRUE 0.173821  1 0.845313
174  TRUE 0.896527  0 0.122284
175  TRUE 0.562343  0 0.555707
176  TRUE 0.342454  1 0.776426
177  TRUE 0.283730  0 0.259379
178  TRUE 0.747538  1 0.498980
179  TRUE 0.562850  1 0.584417
180  TRUE 0.565386  0 0.484753
181  TRUE 0.633332  1 0.608540
182  TRUE 0.962587  1 0.020863
183  TRUE 0.768941  0 0.382800
184  TRUE 0.761524  0 0.381620
185  TRUE 0.152722  0 0.067407
186 FALSE 0.367798  0 0.289226
187  TRUE 0.913616  1 0.764743
188  TRUE 0.496350  1 0.801585
189  TRUE 0.027735  0 0.204031
190  TRUE 0.450139  0 0.917860
191 FALSE 0.027188  0 0.102161
192 FALSE 0.018271  0 0.890885
193  TRUE 0.871962  1 0.513431
194  TRUE 0.955189  1 0.132782
195  TRUE 0.892738  1 0.337982
196  TRUE 0.856309  1 0.213000
197 FALSE 0.123533  0 0.828702
198 FALSE 0.221655  0 0.464334
199  TRUE 0.690272  0 0.336253
200  TRUE 0.648772  0 0.144650
201 FALSE 0.091445  0 0.868071
202  TRUE 0.595570  0 0.054323
203  TRUE 0.944378  0 0.613883
204  TRUE 0.128658  1 0.785630
205  TRUE 0.524702  1 0.579447
206  TRUE 0.931876  1 0.527169
207  TRUE 0.441982  0 0.410513
208  TRUE 0.401972  1 0.730523
209  TRUE 0.365523  1 0.883600
210  TRUE 0.572830  1 0.114475
211 FALSE 0.106167  0 0.324148
212  TRUE 0.657214  0 0.366757
213  TRUE 0.800479  0 0.253949
214  TRUE 0.160081  1 0.120749
215  TRUE 0.499150  1 0.582968
216 FALSE 0.138866  0 0.203435
217  TRUE 0.688598  0 0.579752
218  TRUE 0.480642  0 0.590648
219  TRUE 0.207813  1 0.977187
220  TRUE 0.717721  0 0.246125
221  TRUE 0.333421  1 0.477242
222  TRUE 0.529427  1 0.160246
223  TRUE 0.593499  1 0.789169
224  TRUE 0.759889  0 0.095748
225 FALSE 0.039696  0 0.482404
226  TRUE 0.631180  0 0.075754
227 FALSE 0.170350  0 0.937550
228  TRUE 0.707257  0 0.194111
229  TRUE 0.264722  0 0.714579
230  TRUE 0.080322  1 0.955791
231  TRUE 0.713207  1 0.741858
232  TRUE 0.750814  0 0.256030
233 FALSE 0.170226  0 0.612532
234  TRUE 0.214822  0 0.132818
235  TRUE 0.136855  0 0.180193
236  TRUE 0.320705  1 0.079936
237  TRUE 0.659653  0 0.271181
238  TRUE 0.458247  1 0.440128
239  TRUE 0.221784  1 0.711458
240 FALSE 0.049692  0 0.346788
241  TRUE 0.842967  0 0.150468
242  TRUE 0.460356  0 0.599506
243  TRUE 0.044669  1 0.890618
244  TRUE 0.330020  1 0.388701
245 FALSE 0.350482  0 0.098134
246  TRUE 0.236221  1 0.807212
247  TRUE 0.209323  0 0.118084
248  TRUE 0.289585  1 0.764266
249  TRUE 0.299830  0 0.126254
250  TRUE 0.893524  1 0.854532
251  TRUE 0.762661  1 0.536769
252  TRUE 0.104029  0 0.596192
253  TRUE 0.758670  1 0.863054
254  TRUE 0.414734  1 0.867438
255  TRUE 0.221036  0 0.059093
256 FALSE 0.006719  0 0.469490
257  TRUE 0.030251  1 0.342482
258  TRUE 0.250102  1 0.824571
259  TRUE 0.220495  1 0.529290
260  TRUE 0.308081  0 0.437236
261  TRUE 0.908893  0 0.056426
262  TRUE 0.938503  0 0.247775
263  TRUE 0.491905  1 0.398086
264  TRUE 0.168020  1 0.111213
265 FALSE 0.188895  0 0.421623
266 FALSE 0.191555  0 0.239189
267  TRUE 0.503482  1 0.850532
268 FALSE 0.081112  0 0.227025
269 FALSE 0.794697  0 0.747712
270  TRUE 0.571347  0 0.717719
271  TRUE 0.967688  0 0.095165
272  TRUE 0.875769  1 0.479225
273  TRUE 0.705853  0 0.127142
274  TRUE 0.115355  0 0.264237
275  TRUE 0.160992  0 0.227042
276  TRUE 0.335154  0 0.184503
277  TRUE 0.988609  0 0.017256
278  TRUE 0.914079  0 0.281634
279  TRUE 0.535097  0 0.121040
280  TRUE 0.246894  1 0.406426
281  TRUE 0.922347  1 0.789168
282  TRUE 0.753490  1 0.105868
283  TRUE 0.903507  0 0.341595
284  TRUE 0.651548  0 0.333594
285 FALSE 0.020779  0 0.774402
286 FALSE 0.095879  0 0.537167
287  TRUE 0.949587  1 0.787171
288  TRUE 0.888177  0 0.797589
289  TRUE 0.456234  0 0.223906
290  TRUE 0.786744  0 0.466158
291  TRUE 0.201027  0 0.322344
292  TRUE 0.312703  0 0.544530
293  TRUE 0.529762  0 0.971569
294  TRUE 0.182999  0 0.149301
295  TRUE 0.532406  0 0.363683
296 FALSE 0.348114  0 0.787107
297  TRUE 0.510248  0 0.586609
298  TRUE 0.792196  0 0.539789
299  TRUE 0.441211  1 0.873886
300  TRUE 0.286292  1 0.769427
301  TRUE 0.933560  0 0.450837
302  TRUE 0.030451  1 0.939054
303  TRUE 0.848986  1 0.558589
304  TRUE 0.443183  0 0.571000
305  TRUE 0.632075  0 0.107309
306  TRUE 0.779914  0 0.388762
307  TRUE 0.280474  1 0.977478
308  TRUE 0.123204  0 0.221452
309  TRUE 0.893433  0 0.220063
310  TRUE 0.405973  0 0.282171
311  TRUE 0.755108  0 0.119221
312 FALSE 0.110817  0 0.180134
313  TRUE 0.338309  0 0.284447
314  TRUE 0.546493  1 0.644276
315  TRUE 0.312132  1 0.960355
316  TRUE 0.447295  0 0.071095
317  TRUE 0.404281  0 0.037918
318  TRUE 0.486564  0 0.040461
319  TRUE 0.439168  1 0.416925
320  TRUE 0.266864  1 0.252264
321  TRUE 0.651878  0 0.108593
322  TRUE 0.239049  1 0.860879
323  TRUE 0.813316  0 0.151392
324  TRUE 0.808245  1 0.548880
325  TRUE 0.589045  1 0.510725
326 FALSE 0.541867  0 0.310565
327  TRUE 0.046548  1 0.682978
328  TRUE 0.425856  1 0.748440
329  TRUE 0.640640  1 0.952518
330  TRUE 0.000656  0 0.362615
331  TRUE 0.866388  0 0.346294
332  TRUE 0.101045  1 0.454230
333 FALSE 0.095740  0 0.668705
334  TRUE 0.777240  1 0.529092
335  TRUE 0.029511  1 0.002821
336  TRUE 0.342072  0 0.861873
337  TRUE 0.786316  0 0.556886
338 FALSE 0.113463  0 0.901920
339  TRUE 0.350253  1 0.950326
340  TRUE 0.330214  0 0.900168
341  TRUE 0.696677  1 0.693946
342 FALSE 0.353614  0 0.836224
343  TRUE 0.406179  0 0.463189
344 FALSE 0.308030  0 0.629100
345  TRUE 0.959203  1 0.439101
346  TRUE 0.690269  1 0.969921
347  TRUE 0.885740  0 0.279549
348  TRUE 0.935855  1 0.979469
349  TRUE 0.744080  1 0.682925
350  TRUE 0.838446  1 0.908006
351  TRUE 0.799357  1 0.669979
352  TRUE 0.893640  1 0.413065
353  TRUE 0.831137  0 0.931386
354  TRUE 0.370750  0 0.149159
355  TRUE 0.871980  0 0.017022
356  TRUE 0.800762  1 0.576501
357 FALSE 0.177285  0 0.508741
358  TRUE 0.163278  1 0.289367
359  TRUE 0.944489  0 0.276403
360  TRUE 0.444638  1 0.608338
361 FALSE 0.078393  0 0.390518
362  TRUE 0.985572  0 0.290984
363 FALSE 0.015838  0 0.385936
364  TRUE 0.494883  1 0.821543
365 FALSE 0.426626  0 0.232980
366  TRUE 0.380065  1 0.985718
367  TRUE 0.736944  0 0.615446
368  TRUE 0.279538  1 0.832476
369  TRUE 0.656284  0 0.236616
370  TRUE 0.779726  1 0.770901
371  TRUE 0.722053  0 0.058774
372  TRUE 0.982406  0 0.514900
373  TRUE 0.543323  1 0.861013
374  TRUE 0.659888  1 0.985402
375  TRUE 0.275039  1 0.396762
376  TRUE 0.396944  1 0.468284
377  TRUE 0.559185  0 0.420656
378  TRUE 0.980950  1 0.915635
379  TRUE 0.964967  1 0.482314
380  TRUE 0.218040  1 0.942408
381  TRUE 0.393171  1 0.124179
382  TRUE 0.734231  1 0.563708
383  TRUE 0.691589  1 0.731237
384 FALSE 0.336752  0 0.000571
385  TRUE 0.690482  1 0.628356
386 FALSE 0.153450  0 0.370726
387  TRUE 0.890399  0 0.085762
388  TRUE 0.888446  1 0.676197
389 FALSE 0.138003  0 0.609158
390  TRUE 0.035949  1 0.096099
391  TRUE 0.355017  1 0.398905
392 FALSE 0.378946  0 0.098322
393  TRUE 0.614777  1 0.794568
394  TRUE 0.506189  1 0.624536
395  TRUE 0.337955  0 0.405014
396  TRUE 0.329130  1 0.002587
397  TRUE 0.573297  1 0.608580
398  TRUE 0.050710  1 0.592337
399  TRUE 0.400963  1 0.910157
400 FALSE 0.260631  0 0.393951
401 FALSE 0.168700  0 0.964200
402  TRUE 0.059731  0 0.255094
403 FALSE 0.052582  0 0.140772
404  TRUE 0.972770  1 0.525254
405  TRUE 0.794608  0 0.454067
406  TRUE 0.031668  1 0.521722
407  TRUE 0.543285  0 0.085697
408  TRUE 0.017597  1 0.597549
409  TRUE 0.776670  0 0.683516
410  TRUE 0.757301  0 0.549356
411 FALSE 0.010548  0 0.620225
412  TRUE 0.817914  0 0.296236
413  TRUE 0.856346  1 0.284500
414 FALSE 0.422310  0 0.601983
415  TRUE 0.634296  0 0.167672
416  TRUE 0.418075  1 0.917387
417  TRUE 0.324664  1 0.990910
418  TRUE 0.765787  0 0.747668
419  TRUE 0.704656  0 0.492539
420  TRUE 0.919051  1 0.932810
421  TRUE 0.610137  1 0.617039
422  TRUE 0.055855  1 0.391704
423  TRUE 0.736152  1 0.196378
424  TRUE 0.903968  0 0.720079
425  TRUE 0.701815  1 0.934172
426  TRUE 0.577700  1 0.692644
427  TRUE 0.565839  0 0.888581
428  TRUE 0.367176  0 0.228666
429  TRUE 0.556922  0 0.546569
430  TRUE 0.897090  0 0.206999
431  TRUE 0.272231  0 0.537050
432  TRUE 0.826333  1 0.969278
433  TRUE 0.675996  1 0.803234
434  TRUE 0.899367  0 0.204047
435  TRUE 0.296660  1 0.400647
436  TRUE 0.385464  1 0.829125
437  TRUE 0.905350  0 0.441127
438  TRUE 0.781176  1 0.395053
439  TRUE 0.542551  0 0.030889
440  TRUE 0.826008  0 0.135866
441  TRUE 0.925736  1 0.677184
442  TRUE 0.302508  0 0.062488
443  TRUE 0.363235  1 0.997538
444  TRUE 0.960561  0 0.113849
445 FALSE 0.419576  0 0.625333
446  TRUE 0.564240  0 0.025587
447  TRUE 0.800476  0 0.108310
448  TRUE 0.478195  1 0.454083
449  TRUE 0.871664  1 0.800191
450  TRUE 0.701587  0 0.834824
451 FALSE 0.128367  0 0.724688
452  TRUE 0.651634  0 0.282822
453  TRUE 0.799508  1 0.642903
454 FALSE 0.240165  0 0.958786
455  TRUE 0.863995  1 0.537109
456  TRUE 0.478795  1 0.431453
457  TRUE 0.329742  1 0.724119
458  TRUE 0.995426  0 0.174124
459  TRUE 0.759542  1 0.320324
460  TRUE 0.471065  0 0.387978
461 FALSE 0.257584  0 0.054494
462  TRUE 0.383511  0 0.277925
463  TRUE 0.297954  0 0.715454
464  TRUE 0.768626  1 0.328546
465  TRUE 0.429740  1 0.601455
466  TRUE 0.655967  0 0.523921
467  TRUE 0.242657  1 0.860549
468  TRUE 0.295185  1 0.532769
469  TRUE 0.929919  0 0.111422
470 FALSE 0.139466  0 0.775893
471  TRUE 0.482361  1 0.062940
472  TRUE 0.801726  0 0.705285
473 FALSE 0.335298  0 0.049256
474  TRUE 0.547301  0 0.781317
475  TRUE 0.050614  0 0.784139
476  TRUE 0.685185  0 0.552576
477  TRUE 0.526017  1 0.855108
478  TRUE 0.385401  0 0.209872
479  TRUE 0.218078  0 0.230055
480 FALSE 0.049256  0 0.673410
481  TRUE 0.338604  1 0.444783
482  TRUE 0.527543  0 0.660065
483  TRUE 0.360100  1 0.077822
484  TRUE 0.991589  0 0.343248
485  TRUE 0.046358  1 0.807455
486  TRUE 0.071902  1 0.348975
487  TRUE 0.676367  0 0.052082
488  TRUE 0.162360  1 0.863283
489  TRUE 0.580374  0 0.556919
490 FALSE 0.090766  0 0.909955
491  TRUE 0.656099  0 0.761297
492  TRUE 0.357507  1 0.545542
493  TRUE 0.194491  1 0.477882
494  TRUE 0.681934  0 0.347431
495 FALSE 0.030555  0 0.568208
496  TRUE 0.439074  1 0.950769
497  TRUE 0.973690  0 0.261379
498  TRUE 0.412593  1 0.106805
499  TRUE 0.919770  1 0.253758
500  TRUE 0.098764  0 0.180904
> logLik( ss )
'log Lik.' -398 (df=5)
> 
> # estimation with BFGS method
> ssBFGS <- selection( ys ~ xs, yo ~ xo, data = simDat, maxMethod = "BFGS" )
Warning message:
In log(lik[i10]) : NaNs produced
> print( ssBFGS )

Call:
 selection(selection = ys ~ xs, outcome = yo ~ xo, data = simDat,      maxMethod = "BFGS") 

Coefficients:
S:(Intercept)           S:xs  O:(Intercept)           O:xo            rho  
       -0.122          3.329         -1.055          1.987          0.817  

> summary( ssBFGS )
--------------------------------------------
Tobit 2 model (sample selection model)
Maximum Likelihood estimation
BFGS maximization, 31 iterations
Return code 0: successful convergence 
Log-Likelihood: -398 
500 observations (74 censored and 426 observed)
5 free parameters (df = 495)
Probit selection equation:
            Estimate Std. error t value Pr(> t)    
(Intercept)   -0.122      0.132   -0.92    0.36    
xs             3.329      0.397    8.39  <2e-16 ***
Outcome equation:
            Estimate Std. error t value Pr(> t)    
(Intercept)   -1.055      0.122   -8.66  <2e-16 ***
xo             1.987      0.232    8.56  <2e-16 ***
   Error terms:
    Estimate Std. error t value Pr(> t)    
rho    0.817      0.145    5.64 1.7e-08 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
--------------------------------------------
> all.equal( coef( ssBFGS ), coef( ss ), tol = 1e-2 )
[1] TRUE
> all.equal( stdEr( ssBFGS ), stdEr( ss ), tol = 1e-1 )
[1] TRUE
> all.equal( vcov( ssBFGS ), vcov( ss ), tol = 1e-1 )
[1] TRUE
> nobs( ssBFGS )
[1] 500
> nObs( ssBFGS )
[1] 500
> all.equal( fitted( ss ), fitted( ssBFGS ), tol = 1e-2 )
[1] TRUE
> all.equal( fitted( ss, part = "selection" ),
+    fitted( ssBFGS, part = "selection" ), tol = 1e-2 )
[1] TRUE
> all.equal( fitted( ssBFGS ), fitted( ssBFGS, part = "outcome" ) )
[1] TRUE
> all.equal( residuals( ss ), residuals( ssBFGS ), tol = 1e-2 )
[1] TRUE
> all.equal( residuals( ss, part = "selection" ),
+    residuals( ssBFGS, part = "selection" ), tol = 1e-2 )
[1] TRUE
> all.equal( residuals( ssBFGS ), residuals( ssBFGS, part = "outcome" ) )
[1] TRUE
> all.equal( model.matrix( ss ), model.matrix( ssBFGS ) )
[1] TRUE
> all.equal( model.matrix( ss, part = "selection" ),
+    model.matrix( ssBFGS, part = "selection" ) )
[1] TRUE
> all.equal( model.matrix( ssBFGS ), model.matrix( ssBFGS, part = "outcome" ) )
[1] TRUE
> all.equal( logLik( ss ), logLik( ssBFGS ), tol = 1e-3 )
[1] TRUE
> 
> # BHHH estimation with equal weights
> simDat$we <- rep( 0.7, N )
> ssWe <- selection( ys ~ xs, yo ~ xo, weights = simDat$we, data = simDat,
+    steptol = 1e-12 )
> summary( ssWe )
--------------------------------------------
Tobit 2 model (sample selection model)
Maximum Likelihood estimation
BHHH maximisation, 11 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -279 
500 observations (74 censored and 426 observed)
5 free parameters (df = 495)
Probit selection equation:
            Estimate Std. error t value Pr(> t)    
(Intercept)   -0.122      0.185   -0.66    0.51    
xs             3.329      0.561    5.93   3e-09 ***
Outcome equation:
            Estimate Std. error t value Pr(> t)    
(Intercept)   -1.055      0.173   -6.10 1.1e-09 ***
xo             1.987      0.325    6.11 1.0e-09 ***
   Error terms:
    Estimate Std. error t value Pr(> t)    
rho    0.817      0.202    4.04 5.3e-05 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
--------------------------------------------
> all.equal( coef( ssWe ), coef( ss ), tol = 1e-2 )
[1] TRUE
> 
> # BHHH estimation with equal weights
> ssWeBFGS <- selection( ys ~ xs, yo ~ xo, weights = simDat$we,
+    data = simDat, maxMethod = "BFGS" )
> summary( ssWeBFGS )
--------------------------------------------
Tobit 2 model (sample selection model)
Maximum Likelihood estimation
BFGS maximization, 56 iterations
Return code 0: successful convergence 
Log-Likelihood: -279 
500 observations (74 censored and 426 observed)
5 free parameters (df = 495)
Probit selection equation:
            Estimate Std. error t value Pr(> t)    
(Intercept)   -0.122      0.158   -0.77    0.44    
xs             3.329      0.474    7.02 2.2e-12 ***
Outcome equation:
            Estimate Std. error t value Pr(> t)    
(Intercept)   -1.055      0.145   -7.25 4.2e-13 ***
xo             1.987      0.278    7.16 8.0e-13 ***
   Error terms:
    Estimate Std. error t value Pr(> t)    
rho    0.817      0.173    4.72 2.4e-06 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
--------------------------------------------
> all.equal( coef( ssWeBFGS ), coef( ssBFGS ), tol = 1e-2 )
[1] TRUE
> 
> # BHHH estimation with unequal weights
> simDat$wu <- 2 * runif( N )
> ssWu <- selection( ys ~ xs, yo ~ xo, weights = simDat$wu, data = simDat )
> summary( ssWu )
--------------------------------------------
Tobit 2 model (sample selection model)
Maximum Likelihood estimation
BHHH maximisation, 11 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -396 
500 observations (74 censored and 426 observed)
5 free parameters (df = 495)
Probit selection equation:
            Estimate Std. error t value Pr(> t)    
(Intercept)   -0.112      0.103   -1.09    0.27    
xs             3.360      0.275   12.21  <2e-16 ***
Outcome equation:
            Estimate Std. error t value Pr(> t)    
(Intercept)   -1.070      0.106   -10.1  <2e-16 ***
xo             1.994      0.185    10.8  <2e-16 ***
   Error terms:
    Estimate Std. error t value Pr(> t)    
rho   0.9535     0.0553    17.2  <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
--------------------------------------------
> 
> # BFGS estimation with unequal weights
> ssWuBFGS <- selection( ys ~ xs, yo ~ xo, weights = simDat$wu,
+    data = simDat, maxMethod = "BFGS" )
> summary( ssWuBFGS )
--------------------------------------------
Tobit 2 model (sample selection model)
Maximum Likelihood estimation
BFGS maximization, 43 iterations
Return code 0: successful convergence 
Log-Likelihood: -396 
500 observations (74 censored and 426 observed)
5 free parameters (df = 495)
Probit selection equation:
            Estimate Std. error t value Pr(> t)    
(Intercept)   -0.113      0.119   -0.94    0.35    
xs             3.361      0.369    9.12  <2e-16 ***
Outcome equation:
            Estimate Std. error t value Pr(> t)    
(Intercept)   -1.070      0.120   -8.92  <2e-16 ***
xo             1.995      0.216    9.23  <2e-16 ***
   Error terms:
    Estimate Std. error t value Pr(> t)    
rho   0.9535     0.0451    21.2  <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
--------------------------------------------
> all.equal( coef( ssWuBFGS ), coef( ssWu ), tol = 1e-2 )
[1] TRUE
> 
> # comparison of estimated coefficients, standard errors, and logLik values
> round( rbind( coef( ss ), coef( ssBFGS ), coef( ssWe ), coef( ssWeBFGS ),
+    coef( ssWu ), coef( ssWuBFGS ) ), 3 )
     (Intercept)   xs (Intercept)   xo   rho
[1,]      -0.122 3.33       -1.05 1.99 0.817
[2,]      -0.122 3.33       -1.05 1.99 0.817
[3,]      -0.122 3.33       -1.05 1.99 0.817
[4,]      -0.122 3.33       -1.05 1.99 0.817
[5,]      -0.112 3.36       -1.07 1.99 0.954
[6,]      -0.113 3.36       -1.07 2.00 0.953
> round( rbind( coef( summary( ss ) )[ , 2 ], coef( summary( ssBFGS ) )[ , 2 ],
+    coef( summary( ssWe ) )[ , 2 ], coef( summary( ssWeBFGS ) )[ , 2 ],
+    coef( summary( ssWu ) )[ , 2 ], coef( summary( ssWuBFGS ) )[ , 2 ] ), 3 )
     (Intercept)    xs (Intercept)    xo   rho
[1,]       0.130 0.393       0.121 0.228 0.141
[2,]       0.132 0.397       0.122 0.232 0.145
[3,]       0.185 0.561       0.173 0.325 0.202
[4,]       0.158 0.474       0.145 0.278 0.173
[5,]       0.103 0.275       0.106 0.185 0.055
[6,]       0.119 0.369       0.120 0.216 0.045
> print( rbind( logLik( ss ), logLik( ssBFGS ), logLik( ssWe ),
+    logLik( ssWeBFGS ), logLik( ssWu ), logLik( ssWuBFGS ) ), digits = 6 )
         [,1]
[1,] -398.191
[2,] -398.191
[3,] -278.734
[4,] -278.734
[5,] -395.657
[6,] -395.657
> 
> # binary outcome NA if unobserved
> simDat$yo[ !simDat$ys ] <- NA
> print(table(simDat$ys, simDat$yo, exclude=NULL))
       
          0   1 <NA>
  FALSE   0   0   74
  TRUE  202 224    0
  <NA>    0   0    0
> ssN <- selection( ys ~ xs, yo ~ xo, data = simDat, steptol = 1e-12 )
> print(summary(ssN))
--------------------------------------------
Tobit 2 model (sample selection model)
Maximum Likelihood estimation
BHHH maximisation, 6 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -398 
500 observations (74 censored and 426 observed)
5 free parameters (df = 495)
Probit selection equation:
            Estimate Std. error t value Pr(> t)    
(Intercept)   -0.122      0.130   -0.94    0.35    
xs             3.329      0.393    8.48  <2e-16 ***
Outcome equation:
            Estimate Std. error t value Pr(> t)    
(Intercept)   -1.055      0.121   -8.71  <2e-16 ***
xo             1.987      0.228    8.73  <2e-16 ***
   Error terms:
    Estimate Std. error t value Pr(> t)    
rho    0.817      0.141    5.77 7.8e-09 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
--------------------------------------------
> all.equal(ss,ssN)
[1] TRUE
> 
> # binary outcome logical
> simDat$yo <- simDat$yoX > 0 & simDat$ys
> print(table(simDat$ys, simDat$yo, exclude=NULL))
       
        FALSE TRUE <NA>
  FALSE    74    0    0
  TRUE    202  224    0
  <NA>      0    0    0
> ssL <- selection( ys ~ xs, yo ~ xo, data = simDat, steptol = 1e-12 )
> print(summary(ssL))
--------------------------------------------
Tobit 2 model (sample selection model)
Maximum Likelihood estimation
BHHH maximisation, 6 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -398 
500 observations (74 censored and 426 observed)
5 free parameters (df = 495)
Probit selection equation:
            Estimate Std. error t value Pr(> t)    
(Intercept)   -0.122      0.130   -0.94    0.35    
xs             3.329      0.393    8.48  <2e-16 ***
Outcome equation:
            Estimate Std. error t value Pr(> t)    
(Intercept)   -1.055      0.121   -8.71  <2e-16 ***
xo             1.987      0.228    8.73  <2e-16 ***
   Error terms:
    Estimate Std. error t value Pr(> t)    
rho    0.817      0.141    5.77 7.8e-09 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
--------------------------------------------
> all.equal(ss,ssL)
[1] "Component \"twoStep\": Component \"lm\": Component \"model\": Attributes: < Component \"row.names\": Modes: numeric, character >"              
[2] "Component \"twoStep\": Component \"lm\": Component \"model\": Attributes: < Component \"row.names\": target is numeric, current is character >"
[3] "Component \"twoStep\": Component \"lm\": Component \"model\": Component \"YO\": Modes: numeric, logical"                                       
[4] "Component \"twoStep\": Component \"lm\": Component \"model\": Component \"YO\": names for current but not for target"                          
[5] "Component \"twoStep\": Component \"lm\": Component \"model\": Component \"YO\": target is numeric, current is logical"                         
> 
> # binary outcome logical and NA if unobserved
> simDat$yo[ !simDat$ys ] <- NA
> print(table(simDat$ys, simDat$yo, exclude=NULL))
       
        FALSE TRUE <NA>
  FALSE     0    0   74
  TRUE    202  224    0
  <NA>      0    0    0
> ssLN <- selection( ys ~ xs, yo ~ xo, data = simDat, steptol = 1e-12 )
> print(summary(ssLN))
--------------------------------------------
Tobit 2 model (sample selection model)
Maximum Likelihood estimation
BHHH maximisation, 6 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -398 
500 observations (74 censored and 426 observed)
5 free parameters (df = 495)
Probit selection equation:
            Estimate Std. error t value Pr(> t)    
(Intercept)   -0.122      0.130   -0.94    0.35    
xs             3.329      0.393    8.48  <2e-16 ***
Outcome equation:
            Estimate Std. error t value Pr(> t)    
(Intercept)   -1.055      0.121   -8.71  <2e-16 ***
xo             1.987      0.228    8.73  <2e-16 ***
   Error terms:
    Estimate Std. error t value Pr(> t)    
rho    0.817      0.141    5.77 7.8e-09 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
--------------------------------------------
> all.equal(ssL,ssLN)
[1] TRUE
> 
> proc.time()
   user  system elapsed 
 28.952   0.172  29.134 
