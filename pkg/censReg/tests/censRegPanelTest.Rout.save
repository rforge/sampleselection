
R version 2.14.2 (2012-02-29)
Copyright (C) 2012 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> library( censReg )
Loading required package: maxLik
Loading required package: miscTools
> library( plm )
Loading required package: bdsmatrix

Attaching package: 'bdsmatrix'

The following object(s) are masked from 'package:base':

    backsolve

Loading required package: nlme
Loading required package: Formula
Loading required package: MASS
Loading required package: sandwich
Loading required package: zoo

Attaching package: 'zoo'

The following object(s) are masked from 'package:base':

    as.Date, as.Date.numeric

> 
> nId <- 15
> nTime <- 4
> 
> set.seed( 123 )
> pData <- data.frame(
+    id = rep( paste( "F", 1:nId, sep = "_" ), each = nTime ),
+    time = rep( 1980 + 1:nTime, nId ) )
> pData$ui <- rep( rnorm( nId ), each = nTime )
> pData$x1 <- rnorm( nId * nTime )
> pData$x2 <- runif( nId * nTime )
> pData$ys <- -1 + pData$ui + 2 * pData$x1 + 3 * pData$x2 + rnorm( nId * nTime )
> pData$y <- ifelse( pData$ys > 0, pData$ys, 0 )
> nData <- pData # save data set without information on panel structure
> pData <- pdata.frame( pData, c( "id", "time" ) )
> 
> 
> ## Newton-Raphson method
> randEff <- censReg( y ~ x1 + x2, data = pData )
> print( randEff )

Call:
censReg(formula = y ~ x1 + x2, data = pData)

Coefficients:
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
   -0.36562     1.68000     2.24054    -0.12955    -0.01241 

> print( randEff, logSigma = FALSE )

Call:
censReg(formula = y ~ x1 + x2, data = pData)

Coefficients:
(Intercept)          x1          x2     sigmaMu     sigmaNu 
    -0.3656      1.6800      2.2405      0.8785      0.9877 

> maxLik:::summary.maxLik( randEff )
--------------------------------------------
Maximum Likelihood estimation
Newton-Raphson maximisation, 5 iterations
Return code 1: gradient close to zero
Log-Likelihood: -73.19882 
5  free parameters
Estimates:
             Estimate Std. error t value   Pr(> t)    
(Intercept) -0.365623   0.474457 -0.7706 0.4409361    
x1           1.680004   0.209222  8.0298 9.767e-16 ***
x2           2.240544   0.673889  3.3248 0.0008848 ***
logSigmaMu  -0.129547   0.258070 -0.5020 0.6156793    
logSigmaNu  -0.012408   0.129690 -0.0957 0.9237786    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> summary( randEff )

Call:
censReg(formula = y ~ x1 + x2, data = pData)

Observations:
         Total  Left-censored     Uncensored Right-censored 
            60             20             40              0 

Coefficients:
            Estimate Std. error t value  Pr(> t)    
(Intercept) -0.36562    0.47446  -0.771 0.440936    
x1           1.68000    0.20922   8.030 9.77e-16 ***
x2           2.24054    0.67389   3.325 0.000885 ***
logSigmaMu  -0.12955    0.25807  -0.502 0.615679    
logSigmaNu  -0.01241    0.12969  -0.096 0.923779    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Newton-Raphson maximisation, 5 iterations
Return code 1: gradient close to zero
Log-likelihood: -73.19882 on 5 Df

> print( summary( randEff ), logSigma = FALSE )

Call:
censReg(formula = y ~ x1 + x2, data = pData)

Observations:
         Total  Left-censored     Uncensored Right-censored 
            60             20             40              0 

Coefficients:
            Estimate Std. error t value  Pr(> t)    
(Intercept)  -0.3656     0.4745  -0.771 0.440936    
x1            1.6800     0.2092   8.030 9.77e-16 ***
x2            2.2405     0.6739   3.325 0.000885 ***
sigmaMu       0.8785     0.2267   3.875 0.000107 ***
sigmaNu       0.9877     0.1281   7.711 1.25e-14 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Newton-Raphson maximisation, 5 iterations
Return code 1: gradient close to zero
Log-likelihood: -73.19882 on 5 Df

> coef( randEff )
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
-0.36562313  1.68000400  2.24054376 -0.12954703 -0.01240809 
> coef( randEff, logSigma = FALSE )
(Intercept)          x1          x2     sigmaMu     sigmaNu 
 -0.3656231   1.6800040   2.2405438   0.8784933   0.9876686 
> vcov( randEff )
             (Intercept)           x1           x2   logSigmaMu   logSigmaNu
(Intercept)  0.225109672 -0.020570168 -0.254602886 -0.023824162 -0.002973952
x1          -0.020570168  0.043773972  0.008562225  0.013404079  0.002969957
x2          -0.254602886  0.008562225  0.454125882  0.017179542  0.001505438
logSigmaMu  -0.023824162  0.013404079  0.017179542  0.066600320 -0.002638871
logSigmaNu  -0.002973952  0.002969957  0.001505438 -0.002638871  0.016819442
> vcov( randEff, logSigma = FALSE )
             (Intercept)           x1           x2      sigmaMu      sigmaNu
(Intercept)  0.225109672 -0.020570168 -0.254602886 -0.020929366 -0.002937279
x1          -0.020570168  0.043773972  0.008562225  0.011775393  0.002933333
x2          -0.254602886  0.008562225  0.454125882  0.015092113  0.001486874
sigmaMu     -0.020929366  0.011775393  0.015092113  0.051398826 -0.002289643
sigmaNu     -0.002937279  0.002933333  0.001486874 -0.002289643  0.016407184
> coef( summary( randEff ) )
               Estimate Std. error     t value      Pr(> t)
(Intercept) -0.36562313  0.4744572 -0.77061344 4.409361e-01
x1           1.68000400  0.2092223  8.02975581 9.766687e-16
x2           2.24054376  0.6738886  3.32479829 8.848252e-04
logSigmaMu  -0.12954703  0.2580704 -0.50198333 6.156793e-01
logSigmaNu  -0.01240809  0.1296898 -0.09567514 9.237786e-01
> coef( summary( randEff ), logSigma = FALSE )
              Estimate Std. error    t value      Pr(> t)
(Intercept) -0.3656231  0.4744572 -0.7706134 4.409361e-01
x1           1.6800040  0.2092223  8.0297558 9.766687e-16
x2           2.2405438  0.6738886  3.3247983 8.848252e-04
sigmaMu      0.8784933  0.2267131  3.8749120 1.066632e-04
sigmaNu      0.9876686  0.1280905  7.7107072 1.251225e-14
> logLik( randEff )
'log Lik.' -73.19882 (df=5)
> extractAIC( randEff )
[1] -40.0000 156.3976
> print.default( randEff )
$maximum
[1] -73.19882

$estimate
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
-0.36562313  1.68000400  2.24054376 -0.12954703 -0.01240809 

$gradient
 (Intercept)           x1           x2   logSigmaMu   logSigmaNu 
1.712347e-11 4.534091e-11 1.345653e-11 8.220286e-12 6.207043e-11 

$hessian
            (Intercept)         x1         x2  logSigmaMu  logSigmaNu
(Intercept)  -13.321985  -4.096607 -7.3075697  -2.1079024  -1.3088177
x1            -4.096607 -26.076787 -1.9905305   4.4849638   4.7620891
x2            -7.307570  -1.990530 -6.2362552  -0.6238251  -0.4803054
logSigmaMu    -2.107902   4.484964 -0.6238251 -16.6582041  -3.7223987
logSigmaNu    -1.308818   4.762089 -0.4803054  -3.7223987 -61.0683413

$code
[1] 1

$message
[1] "gradient close to zero"

$last.step
NULL

$fixed
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
      FALSE       FALSE       FALSE       FALSE       FALSE 

$iterations
[1] 5

$type
[1] "Newton-Raphson maximisation"

$gradientObs
      (Intercept)          x1          x2 logSigmaMu logSigmaNu
 [1,] -0.85308353  0.22558520 -0.07261010 -0.1440032 -0.9609402
 [2,] -1.70309357  0.04839424 -1.18987552  1.6807831 -1.0133141
 [3,]  1.75084247  0.33367482  1.72755770  1.8353812  1.8043727
 [4,]  0.15577733 -0.20240007 -0.43224660 -0.6891081 -1.4351382
 [5,]  0.12950026  0.98433620  0.68943625 -0.6770204 -0.5543803
 [6,]  0.33035909 -0.30928416  0.38471147 -0.4921375 -1.5793716
 [7,] -0.08212549 -3.18521871 -0.23724729 -0.6766315  6.0271932
 [8,] -0.26685300  0.37888544  0.05565473 -0.5385828 -1.1091111
 [9,]  1.14824183  0.59396387  0.30328556  0.1329802 -1.6172740
[10,] -0.43505392 -0.40640593 -0.15245982 -0.4687582 -1.9364984
[11,] -0.02839185  1.44795739 -0.64407731 -0.9172655  2.7349924
[12,]  1.21047881  0.53669833  0.61328528  0.2055542 -1.7351236
[13,]  0.53592707 -0.22523044  0.33117482 -0.3691166 -1.4082834
[14,] -1.81460674 -1.30608969 -0.91950989  1.9573174  2.5815580
[15,] -0.07791875  1.08513351 -0.45707928 -0.8393922  0.2013187

$call
censReg(formula = y ~ x1 + x2, data = pData)

$terms
y ~ x1 + x2
attr(,"variables")
list(y, x1, x2)
attr(,"factors")
   x1 x2
y   0  0
x1  1  0
x2  0  1
attr(,"term.labels")
[1] "x1" "x2"
attr(,"order")
[1] 1 1
attr(,"intercept")
[1] 1
attr(,"response")
[1] 1
attr(,".Environment")
<environment: R_GlobalEnv>
attr(,"predvars")
list(y, x1, x2)
attr(,"dataClasses")
        y        x1        x2 
"numeric" "numeric" "numeric" 

$nObs
         Total  Left-censored     Uncensored Right-censored 
            60             20             40              0 

$df.residual
[1] 55

$start
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
  0.4703506   1.0111600   1.6191826  -0.4962510  -0.0620962 

attr(,"class")
[1] "censReg" "maxLik"  "maxim"   "list"   
> 
> 
> ## BHHH method
> randEffBhhh <- censReg( y ~ x1 + x2, data = pData, method = "BHHH" )
> print( randEffBhhh )

Call:
censReg(formula = y ~ x1 + x2, data = pData, method = "BHHH")

Coefficients:
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
    -0.3656      1.6800      2.2406     -0.1296     -0.0124 

> maxLik:::summary.maxLik( randEffBhhh )
--------------------------------------------
Maximum Likelihood estimation
BHHH maximisation, 18 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -73.19882 
5  free parameters
Estimates:
             Estimate Std. error t value   Pr(> t)    
(Intercept) -0.365635   0.555054 -0.6587  0.510065    
x1           1.680016   0.293775  5.7187 1.073e-08 ***
x2           2.240556   0.729501  3.0714  0.002131 ** 
logSigmaMu  -0.129565   0.295017 -0.4392  0.660531    
logSigmaNu  -0.012402   0.140134 -0.0885  0.929481    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> summary( randEffBhhh )

Call:
censReg(formula = y ~ x1 + x2, data = pData, method = "BHHH")

Observations:
         Total  Left-censored     Uncensored Right-censored 
            60             20             40              0 

Coefficients:
            Estimate Std. error t value  Pr(> t)    
(Intercept)  -0.3656     0.5551  -0.659  0.51006    
x1            1.6800     0.2938   5.719 1.07e-08 ***
x2            2.2406     0.7295   3.071  0.00213 ** 
logSigmaMu   -0.1296     0.2950  -0.439  0.66053    
logSigmaNu   -0.0124     0.1401  -0.088  0.92948    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

BHHH maximisation, 18 iterations
Return code 2: successive function values within tolerance limit
Log-likelihood: -73.19882 on 5 Df

> print.default( randEffBhhh )
$maximum
[1] -73.19882

$estimate
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
-0.36563477  1.68001566  2.24055570 -0.12956535 -0.01240161 

$gradient
  (Intercept)            x1            x2    logSigmaMu    logSigmaNu 
 5.028294e-05 -3.315101e-04 -4.246354e-06  3.505038e-04 -2.626408e-04 

$hessian
            (Intercept)         x1         x2  logSigmaMu logSigmaNu
(Intercept)  -13.482494  -4.096061 -8.3241402   2.7373240   3.959016
x1            -4.096061 -17.395897 -2.1956247   2.0949384  19.029556
x2            -8.324140  -2.195625 -7.3456165  -0.2437129   3.421562
logSigmaMu     2.737324   2.094938 -0.2437129 -13.9308908  -3.639137
logSigmaNu     3.959016  19.029556  3.4215617  -3.6391374 -73.168704
attr(,"type")
[1] "BHHH"

$code
[1] 2

$message
[1] "successive function values within tolerance limit"

$last.step
NULL

$fixed
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
      FALSE       FALSE       FALSE       FALSE       FALSE 

$iterations
[1] 18

$type
[1] "BHHH maximisation"

$gradientObs
      (Intercept)          x1          x2 logSigmaMu logSigmaNu
 [1,] -0.85309912  0.22553991 -0.07262972 -0.1439976 -0.9609756
 [2,] -1.70314125  0.04834913 -1.18991475  1.6808211 -1.0132976
 [3,]  1.75089168  0.33368134  1.72757656  1.8353986  1.8044304
 [4,]  0.15581599 -0.20240761 -0.43221921 -0.6890852 -1.4351543
 [5,]  0.12951232  0.98431668  0.68943033 -0.6770023 -0.5544220
 [6,]  0.33038531 -0.30929737  0.38473066 -0.4921403 -1.5793732
 [7,] -0.08212211 -3.18519652 -0.23724499 -0.6766142  6.0271629
 [8,] -0.26685182  0.37888104  0.05565305 -0.5385702 -1.1091241
 [9,]  1.14826405  0.59392337  0.30329461  0.1330245 -1.6172865
[10,] -0.43507487 -0.40642217 -0.15246997 -0.4687544 -1.9364930
[11,] -0.02840097  1.44793082 -0.64407223 -0.9172307  2.7348842
[12,]  1.21050842  0.53669645  0.61330484  0.2056154 -1.7351598
[13,]  0.53595825 -0.22524780  0.33119153 -0.3691112 -1.4082671
[14,] -1.81465694 -1.30619017 -0.91955280  1.9573642  2.5815611
[15,] -0.07793866  1.08511138 -0.45708215 -0.8393671  0.2012520

$call
censReg(formula = y ~ x1 + x2, data = pData, method = "BHHH")

$terms
y ~ x1 + x2
attr(,"variables")
list(y, x1, x2)
attr(,"factors")
   x1 x2
y   0  0
x1  1  0
x2  0  1
attr(,"term.labels")
[1] "x1" "x2"
attr(,"order")
[1] 1 1
attr(,"intercept")
[1] 1
attr(,"response")
[1] 1
attr(,".Environment")
<environment: R_GlobalEnv>
attr(,"predvars")
list(y, x1, x2)
attr(,"dataClasses")
        y        x1        x2 
"numeric" "numeric" "numeric" 

$nObs
         Total  Left-censored     Uncensored Right-censored 
            60             20             40              0 

$df.residual
[1] 55

$start
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
  0.4703506   1.0111600   1.6191826  -0.4962510  -0.0620962 

attr(,"class")
[1] "censReg" "maxLik"  "maxim"   "list"   
> 
> 
> ## BFGS method (optim)
> randEffBfgs <- censReg( y ~ x1 + x2, data = pData, method = "BFGS" )
> print( randEffBfgs )

Call:
censReg(formula = y ~ x1 + x2, data = pData, method = "BFGS")

Coefficients:
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
   -0.36562     1.68000     2.24055    -0.12955    -0.01241 

> maxLik:::summary.maxLik( randEffBfgs )
--------------------------------------------
Maximum Likelihood estimation
BFGS maximisation, 25 iterations
Return code 0: successful convergence 
Log-Likelihood: -73.19882 
5  free parameters
Estimates:
             Estimate Std. error t value   Pr(> t)    
(Intercept) -0.365624   0.474456 -0.7706 0.4409343    
x1           1.680002   0.209222  8.0298 9.767e-16 ***
x2           2.240551   0.673888  3.3248 0.0008848 ***
logSigmaMu  -0.129549   0.258071 -0.5020 0.6156731    
logSigmaNu  -0.012408   0.129690 -0.0957 0.9237762    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> summary( randEffBfgs )

Call:
censReg(formula = y ~ x1 + x2, data = pData, method = "BFGS")

Observations:
         Total  Left-censored     Uncensored Right-censored 
            60             20             40              0 

Coefficients:
            Estimate Std. error t value  Pr(> t)    
(Intercept) -0.36562    0.47446  -0.771 0.440934    
x1           1.68000    0.20922   8.030 9.77e-16 ***
x2           2.24055    0.67389   3.325 0.000885 ***
logSigmaMu  -0.12955    0.25807  -0.502 0.615673    
logSigmaNu  -0.01241    0.12969  -0.096 0.923776    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

BFGS maximisation, 25 iterations
Return code 0: successful convergence 
Log-likelihood: -73.19882 on 5 Df

> print.default( randEffBfgs )
$maximum
[1] -73.19882

$estimate
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
-0.36562386  1.68000222  2.24055118 -0.12954945 -0.01240847 

$gradient
  (Intercept)            x1            x2    logSigmaMu    logSigmaNu 
-3.160077e-05  2.178336e-05 -3.570719e-05  3.081674e-05  2.108131e-05 

$hessian
            (Intercept)         x1         x2  logSigmaMu logSigmaNu
(Intercept)  -13.322030  -4.096615 -7.3075895  -2.1078505  -1.308810
x1            -4.096615 -26.076823 -1.9905334   4.4849768   4.762042
x2            -7.307589  -1.990533 -6.2362665  -0.6237935  -0.480264
logSigmaMu    -2.107850   4.484977 -0.6237936 -16.6581488  -3.722435
logSigmaNu    -1.308810   4.762042 -0.4802640  -3.7224350 -61.068402

$code
[1] 0

$message
[1] "successful convergence "

$last.step
NULL

$fixed
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
      FALSE       FALSE       FALSE       FALSE       FALSE 

$iterations
function 
      25 

$type
[1] "BFGS maximisation"

$constraints
NULL

$gradientObs
      (Intercept)          x1          x2 logSigmaMu logSigmaNu
 [1,] -0.85308743  0.22558129 -0.07261263 -0.1440013 -0.9609385
 [2,] -1.70310343  0.04839017 -1.18988370  1.6807981 -1.0133093
 [3,]  1.75084680  0.33368182  1.72755839  1.8353799  1.8043672
 [4,]  0.15577623 -0.20239996 -0.43224879 -0.6891122 -1.4351265
 [5,]  0.12949863  0.98433692  0.68943374 -0.6770205 -0.5543875
 [6,]  0.33035850 -0.30927350  0.38470918 -0.4921407 -1.5793728
 [7,] -0.08212636 -3.18521917 -0.23724752 -0.6766300  6.0271888
 [8,] -0.26685580  0.37888651  0.05565314 -0.5385807 -1.1091140
 [9,]  1.14824376  0.59396790  0.30328585  0.1329813 -1.6172723
[10,] -0.43505882 -0.40640593 -0.15246287 -0.4687554 -1.9365001
[11,] -0.02839283  1.44796138 -0.64407965 -0.9172624  2.7350038
[12,]  1.21048230  0.53670265  0.61328478  0.2055557 -1.7351212
[13,]  0.53592379 -0.22522781  0.33117257 -0.3691209 -1.4082845
[14,] -1.81461479 -1.30609804 -0.91951560  1.9573273  2.5815634
[15,] -0.07792214  1.08513754 -0.45708262 -0.8393873  0.2013247

$call
censReg(formula = y ~ x1 + x2, data = pData, method = "BFGS")

$terms
y ~ x1 + x2
attr(,"variables")
list(y, x1, x2)
attr(,"factors")
   x1 x2
y   0  0
x1  1  0
x2  0  1
attr(,"term.labels")
[1] "x1" "x2"
attr(,"order")
[1] 1 1
attr(,"intercept")
[1] 1
attr(,"response")
[1] 1
attr(,".Environment")
<environment: R_GlobalEnv>
attr(,"predvars")
list(y, x1, x2)
attr(,"dataClasses")
        y        x1        x2 
"numeric" "numeric" "numeric" 

$nObs
         Total  Left-censored     Uncensored Right-censored 
            60             20             40              0 

$df.residual
[1] 55

$start
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
  0.4703506   1.0111600   1.6191826  -0.4962510  -0.0620962 

attr(,"class")
[1] "censReg" "maxLik"  "maxim"  
> 
> 
> ## BFGS method (R)
> randEffBfgsr <- censReg( y ~ x1 + x2, data = pData, method = "BFGSR" )
> print( randEffBfgsr )

Call:
censReg(formula = y ~ x1 + x2, data = pData, method = "BFGSR")

Coefficients:
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
   -0.37018     1.68025     2.24734    -0.12908    -0.01241 

> maxLik:::summary.maxLik( randEffBfgsr )
--------------------------------------------
Maximum Likelihood estimation
BFGSR maximization, 75 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -73.19888 
5  free parameters
Estimates:
             Estimate Std. error t value   Pr(> t)    
(Intercept) -0.370182   0.474956 -0.7794 0.4357425    
x1           1.680252   0.209272  8.0291 9.823e-16 ***
x2           2.247340   0.674122  3.3337 0.0008569 ***
logSigmaMu  -0.129081   0.257976 -0.5004 0.6168223    
logSigmaNu  -0.012408   0.129698 -0.0957 0.9237856    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> summary( randEffBfgsr )

Call:
censReg(formula = y ~ x1 + x2, data = pData, method = "BFGSR")

Observations:
         Total  Left-censored     Uncensored Right-censored 
            60             20             40              0 

Coefficients:
            Estimate Std. error t value  Pr(> t)    
(Intercept) -0.37018    0.47496  -0.779 0.435742    
x1           1.68025    0.20927   8.029 9.82e-16 ***
x2           2.24734    0.67412   3.334 0.000857 ***
logSigmaMu  -0.12908    0.25798  -0.500 0.616822    
logSigmaNu  -0.01241    0.12970  -0.096 0.923786    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

BFGSR maximization, 75 iterations
Return code 2: successive function values within tolerance limit
Log-likelihood: -73.19888 on 5 Df

> print.default( randEffBfgsr )
$maximum
[1] -73.19888

$estimate
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
-0.37018234  1.68025208  2.24733953 -0.12908070 -0.01240769 

$gradient
  (Intercept)            x1            x2    logSigmaMu    logSigmaNu 
 0.0090559979  0.0007772901 -0.0098546834 -0.0012634716  0.0021938756 

$hessian
            (Intercept)         x1         x2  logSigmaMu  logSigmaNu
(Intercept)  -13.306859  -4.095250 -7.3017586  -2.1370146  -1.2903070
x1            -4.095250 -26.069883 -1.9886885   4.4811941   4.7602699
x2            -7.301759  -1.988688 -6.2335351  -0.6348343  -0.4476495
logSigmaMu    -2.137015   4.481194 -0.6348343 -16.6838057  -3.7182880
logSigmaNu    -1.290307   4.760270 -0.4476495  -3.7182880 -61.0575698

$code
[1] 2

$message
[1] "successive function values within tolerance limit"

$last.step
NULL

$fixed
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
      FALSE       FALSE       FALSE       FALSE       FALSE 

$iterations
[1] 75

$type
[1] "BFGSR maximization"

$gradientObs
      (Intercept)          x1          x2 logSigmaMu logSigmaNu
 [1,] -0.85194416  0.22398313 -0.07336700 -0.1446857 -0.9674842
 [2,] -1.70261218  0.04688186 -1.19048569  1.6816846 -1.0126363
 [3,]  1.74998381  0.33307242  1.72507486  1.8355560  1.7956705
 [4,]  0.15550261 -0.20324286 -0.43363481 -0.6889017 -1.4280903
 [5,]  0.12995633  0.98295180  0.68755458 -0.6768852 -0.5613391
 [6,]  0.33016582 -0.30602479  0.38388413 -0.4917571 -1.5820082
 [7,] -0.07978141 -3.18633952 -0.23680858 -0.6772826  6.0328767
 [8,] -0.26546774  0.37779930  0.05581157 -0.5391478 -1.1084078
 [9,]  1.14876457  0.59371435  0.30324528  0.1347629 -1.6152901
[10,] -0.43343717 -0.40489509 -0.15193229 -0.4699063 -1.9367751
[11,] -0.02767957  1.45037347 -0.64468930 -0.9185758  2.7425520
[12,]  1.20978159  0.53829574  0.61108739  0.2048048 -1.7332922
[13,]  0.53678347 -0.22547332  0.33130608 -0.3681078 -1.4083897
[14,] -1.81406240 -1.30743594 -0.91967746  1.9580933  2.5773071
[15,] -0.07689757  1.08711674 -0.45722343 -0.8409150  0.2075005

$call
censReg(formula = y ~ x1 + x2, data = pData, method = "BFGSR")

$terms
y ~ x1 + x2
attr(,"variables")
list(y, x1, x2)
attr(,"factors")
   x1 x2
y   0  0
x1  1  0
x2  0  1
attr(,"term.labels")
[1] "x1" "x2"
attr(,"order")
[1] 1 1
attr(,"intercept")
[1] 1
attr(,"response")
[1] 1
attr(,".Environment")
<environment: R_GlobalEnv>
attr(,"predvars")
list(y, x1, x2)
attr(,"dataClasses")
        y        x1        x2 
"numeric" "numeric" "numeric" 

$nObs
         Total  Left-censored     Uncensored Right-censored 
            60             20             40              0 

$df.residual
[1] 55

$start
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
  0.4703506   1.0111600   1.6191826  -0.4962510  -0.0620962 

attr(,"class")
[1] "censReg" "maxLik"  "maxim"   "list"   
> 
> 
> ## BHHH with starting values
> randEffBhhhStart <- censReg( y ~ x1 + x2, data = pData, method = "BHHH",
+    start = c( -0.4, 1.7, 2.2, -0.1, -0.01 ) )
> print( randEffBhhhStart )

Call:
censReg(formula = y ~ x1 + x2, data = pData, start = c(-0.4, 
    1.7, 2.2, -0.1, -0.01), method = "BHHH")

Coefficients:
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
    -0.3657      1.6800      2.2406     -0.1296     -0.0124 

> summary( randEffBhhhStart )

Call:
censReg(formula = y ~ x1 + x2, data = pData, start = c(-0.4, 
    1.7, 2.2, -0.1, -0.01), method = "BHHH")

Observations:
         Total  Left-censored     Uncensored Right-censored 
            60             20             40              0 

Coefficients:
            Estimate Std. error t value  Pr(> t)    
(Intercept)  -0.3657     0.5551  -0.659  0.51003    
x1            1.6800     0.2938   5.719 1.07e-08 ***
x2            2.2406     0.7295   3.071  0.00213 ** 
logSigmaMu   -0.1295     0.2950  -0.439  0.66056    
logSigmaNu   -0.0124     0.1401  -0.088  0.92948    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

BHHH maximisation, 10 iterations
Return code 2: successive function values within tolerance limit
Log-likelihood: -73.19882 on 5 Df

> 
> 
> ## left-censoring at 5
> pData$yAdd <- pData$y + 5
> randEffAdd <- censReg( yAdd ~ x1 + x2, data = pData, method = "BFGSR", left = 5 )
> print( randEffAdd )

Call:
censReg(formula = yAdd ~ x1 + x2, left = 5, data = pData, method = "BFGSR")

Coefficients:
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
    4.62963     1.68013     2.24807    -0.12910    -0.01241 

> maxLik:::summary.maxLik( randEffAdd )
--------------------------------------------
Maximum Likelihood estimation
BFGSR maximization, 85 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -73.19889 
5  free parameters
Estimates:
             Estimate Std. error t value   Pr(> t)    
(Intercept)  4.629631   0.474946  9.7477 < 2.2e-16 ***
x1           1.680126   0.209262  8.0288 9.842e-16 ***
x2           2.248069   0.674121  3.3348 0.0008536 ***
logSigmaMu  -0.129101   0.257966 -0.5005 0.6167536    
logSigmaNu  -0.012414   0.129693 -0.0957 0.9237465    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> summary( randEffAdd )

Call:
censReg(formula = yAdd ~ x1 + x2, left = 5, data = pData, method = "BFGSR")

Observations:
         Total  Left-censored     Uncensored Right-censored 
            60             20             40              0 

Coefficients:
            Estimate Std. error t value  Pr(> t)    
(Intercept)  4.62963    0.47495   9.748  < 2e-16 ***
x1           1.68013    0.20926   8.029 9.84e-16 ***
x2           2.24807    0.67412   3.335 0.000854 ***
logSigmaMu  -0.12910    0.25797  -0.500 0.616754    
logSigmaNu  -0.01241    0.12969  -0.096 0.923747    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

BFGSR maximization, 85 iterations
Return code 2: successive function values within tolerance limit
Log-likelihood: -73.19889 on 5 Df

> coef( randEffAdd )
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
 4.62963100  1.68012589  2.24806874 -0.12910058 -0.01241368 
> coef( randEffAdd, logSigma = FALSE )
(Intercept)          x1          x2     sigmaMu     sigmaNu 
  4.6296310   1.6801259   2.2480687   0.8788856   0.9876631 
> vcov( randEffAdd )
            (Intercept)           x1           x2   logSigmaMu   logSigmaNu
(Intercept)  0.22557410 -0.020675859 -0.254968984 -0.024050019 -0.003054810
x1          -0.02067586  0.043790620  0.008675764  0.013417482  0.002967324
x2          -0.25496898  0.008675764  0.454439229  0.017321622  0.001702283
logSigmaMu  -0.02405002  0.013417482  0.017321622  0.066546246 -0.002623451
logSigmaNu  -0.00305481  0.002967324  0.001702283 -0.002623451  0.016820401
> vcov( randEffAdd, logSigma = FALSE )
             (Intercept)           x1           x2      sigmaMu      sigmaNu
(Intercept)  0.225574100 -0.020675859 -0.254968984 -0.021137215 -0.003017123
x1          -0.020675859  0.043790620  0.008675764  0.011792431  0.002930716
x2          -0.254968984  0.008675764  0.454439229  0.015223723  0.001681282
sigmaMu     -0.021137215  0.011792431  0.015223723  0.051402971 -0.002277268
sigmaNu     -0.003017123  0.002930716  0.001681282 -0.002277268  0.016407936
> logLik( randEffAdd )
'log Lik.' -73.19889 (df=5)
> extractAIC( randEffAdd )
[1] -40.0000 156.3978
> print.default( randEffAdd )
$maximum
[1] -73.19889

$estimate
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
 4.62963100  1.68012589  2.24806874 -0.12910058 -0.01241368 

$gradient
 (Intercept)           x1           x2   logSigmaMu   logSigmaNu 
 0.006782428  0.003263930 -0.012771007 -0.001538611  0.001948740 

$hessian
            (Intercept)         x1         x2  logSigmaMu  logSigmaNu
(Intercept)  -13.305967  -4.094969 -7.3011610  -2.1334884  -1.2879936
x1            -4.094969 -26.070901 -1.9884535   4.4817185   4.7557681
x2            -7.301161  -1.988454 -6.2331853  -0.6327406  -0.4430688
logSigmaMu    -2.133488   4.481718 -0.6327406 -16.6836299  -3.7161834
logSigmaNu    -1.287994   4.755768 -0.4430688  -3.7161834 -61.0592738

$code
[1] 2

$message
[1] "successive function values within tolerance limit"

$last.step
NULL

$fixed
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
      FALSE       FALSE       FALSE       FALSE       FALSE 

$iterations
[1] 85

$type
[1] "BFGSR maximization"

$gradientObs
      (Intercept)          x1          x2 logSigmaMu logSigmaNu
 [1,] -0.85204596  0.22376293 -0.07350701 -0.1446165 -0.9676771
 [2,] -1.70294246  0.04672994 -1.19081058  1.6824868 -1.0123849
 [3,]  1.74977477  0.33339261  1.72473515  1.8350217  1.7943089
 [4,]  0.15523021 -0.20323651 -0.43392391 -0.6892885 -1.4270889
 [5,]  0.12978098  0.98296387  0.68726023 -0.6769826 -0.5620551
 [6,]  0.32992403 -0.30524299  0.38356786 -0.4920086 -1.5823027
 [7,] -0.07976139 -3.18624410 -0.23679850 -0.6772786  6.0324371
 [8,] -0.26560109  0.37783969  0.05571611 -0.5390821 -1.1085219
 [9,]  1.14874202  0.59405055  0.30320426  0.1346539 -1.6151240
[10,] -0.43359036 -0.40474225 -0.15206166 -0.4697787 -1.9369663
[11,] -0.02768523  1.45071862 -0.64483983 -0.9185599  2.7435900
[12,]  1.20980472  0.53859953  0.61086615  0.2045115 -1.7329863
[13,]  0.53641073 -0.22519646  0.33105795 -0.3683965 -1.4086293
[14,] -1.81425960 -1.30757319 -0.91984120  1.9585305  2.5771653
[15,] -0.07699894  1.08744169 -0.45739601 -0.8407509  0.2081839

$call
censReg(formula = yAdd ~ x1 + x2, left = 5, data = pData, method = "BFGSR")

$terms
yAdd ~ x1 + x2
attr(,"variables")
list(yAdd, x1, x2)
attr(,"factors")
     x1 x2
yAdd  0  0
x1    1  0
x2    0  1
attr(,"term.labels")
[1] "x1" "x2"
attr(,"order")
[1] 1 1
attr(,"intercept")
[1] 1
attr(,"response")
[1] 1
attr(,".Environment")
<environment: R_GlobalEnv>
attr(,"predvars")
list(yAdd, x1, x2)
attr(,"dataClasses")
     yAdd        x1        x2 
"numeric" "numeric" "numeric" 

$nObs
         Total  Left-censored     Uncensored Right-censored 
            60             20             40              0 

$df.residual
[1] 55

$start
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
  5.4703506   1.0111600   1.6191826  -0.4962510  -0.0620962 

attr(,"class")
[1] "censReg" "maxLik"  "maxim"   "list"   
> 
> 
> ## right-censoring
> pData$yNeg <- - pData$y
> randEffNeg <- censReg( yNeg ~ x1 + x2, data = pData, method = "BFGSR",
+    left = -Inf, right = 0 )
> print( randEffNeg )

Call:
censReg(formula = yNeg ~ x1 + x2, left = -Inf, right = 0, data = pData, 
    method = "BFGSR")

Coefficients:
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
    0.37018    -1.68025    -2.24734    -0.12908    -0.01241 

> maxLik:::summary.maxLik( randEffNeg )
--------------------------------------------
Maximum Likelihood estimation
BFGSR maximization, 75 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -73.19888 
5  free parameters
Estimates:
             Estimate Std. error t value   Pr(> t)    
(Intercept)  0.370182   0.474956  0.7794 0.4357425    
x1          -1.680252   0.209272 -8.0291 9.823e-16 ***
x2          -2.247340   0.674122 -3.3337 0.0008569 ***
logSigmaMu  -0.129081   0.257976 -0.5004 0.6168223    
logSigmaNu  -0.012408   0.129698 -0.0957 0.9237856    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> summary( randEffNeg )

Call:
censReg(formula = yNeg ~ x1 + x2, left = -Inf, right = 0, data = pData, 
    method = "BFGSR")

Observations:
         Total  Left-censored     Uncensored Right-censored 
            60              0             40             20 

Coefficients:
            Estimate Std. error t value  Pr(> t)    
(Intercept)  0.37018    0.47496   0.779 0.435742    
x1          -1.68025    0.20927  -8.029 9.82e-16 ***
x2          -2.24734    0.67412  -3.334 0.000857 ***
logSigmaMu  -0.12908    0.25798  -0.500 0.616822    
logSigmaNu  -0.01241    0.12970  -0.096 0.923786    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

BFGSR maximization, 75 iterations
Return code 2: successive function values within tolerance limit
Log-likelihood: -73.19888 on 5 Df

> coef( randEffNeg )
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
 0.37018234 -1.68025208 -2.24733953 -0.12908070 -0.01240769 
> coef( randEffNeg, logSigma = FALSE )
(Intercept)          x1          x2     sigmaMu     sigmaNu 
  0.3701823  -1.6802521  -2.2473395   0.8789030   0.9876690 
> vcov( randEffNeg )
             (Intercept)           x1           x2   logSigmaMu   logSigmaNu
(Intercept)  0.225583592 -0.020679234 -0.254974095  0.024068682  0.003044299
x1          -0.020679234  0.043794597  0.008671135 -0.013419823 -0.002970578
x2          -0.254974095  0.008671135  0.454439901 -0.017322697 -0.001677617
logSigmaMu   0.024068682 -0.013419823 -0.017322697  0.066551683 -0.002624979
logSigmaNu   0.003044299 -0.002970578 -0.001677617 -0.002624979  0.016821473
> vcov( randEffNeg, logSigma = FALSE )
            (Intercept)           x1           x2      sigmaMu      sigmaNu
(Intercept)  0.22558359 -0.020679234 -0.254974095  0.021154038  0.003006760
x1          -0.02067923  0.043794597  0.008671135 -0.011794723 -0.002933948
x2          -0.25497409  0.008671135  0.454439901 -0.015224971 -0.001656931
sigmaMu      0.02115404 -0.011794723 -0.015224971  0.051409215 -0.002278653
sigmaNu      0.00300676 -0.002933948 -0.001656931 -0.002278653  0.016409179
> logLik( randEffNeg )
'log Lik.' -73.19888 (df=5)
> extractAIC( randEffNeg )
[1] -40.0000 156.3978
> print.default( randEffNeg )
$maximum
[1] -73.19888

$estimate
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
 0.37018234 -1.68025208 -2.24733953 -0.12908070 -0.01240769 

$gradient
  (Intercept)            x1            x2    logSigmaMu    logSigmaNu 
-0.0090559979 -0.0007772901  0.0098546834 -0.0012634716  0.0021938756 

$hessian
            (Intercept)         x1         x2  logSigmaMu  logSigmaNu
(Intercept)  -13.306859  -4.095250 -7.3017586   2.1370146   1.2903070
x1            -4.095250 -26.069883 -1.9886885  -4.4811941  -4.7602699
x2            -7.301759  -1.988688 -6.2335351   0.6348343   0.4476495
logSigmaMu     2.137015  -4.481194  0.6348343 -16.6838057  -3.7182880
logSigmaNu     1.290307  -4.760270  0.4476495  -3.7182880 -61.0575698

$code
[1] 2

$message
[1] "successive function values within tolerance limit"

$last.step
NULL

$fixed
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
      FALSE       FALSE       FALSE       FALSE       FALSE 

$iterations
[1] 75

$type
[1] "BFGSR maximization"

$gradientObs
      (Intercept)          x1          x2 logSigmaMu logSigmaNu
 [1,]  0.85194416 -0.22398313  0.07336700 -0.1446857 -0.9674842
 [2,]  1.70261218 -0.04688186  1.19048569  1.6816846 -1.0126363
 [3,] -1.74998381 -0.33307242 -1.72507486  1.8355560  1.7956705
 [4,] -0.15550261  0.20324286  0.43363481 -0.6889017 -1.4280903
 [5,] -0.12995633 -0.98295180 -0.68755458 -0.6768852 -0.5613391
 [6,] -0.33016582  0.30602479 -0.38388413 -0.4917571 -1.5820082
 [7,]  0.07978141  3.18633952  0.23680858 -0.6772826  6.0328767
 [8,]  0.26546774 -0.37779930 -0.05581157 -0.5391478 -1.1084078
 [9,] -1.14876457 -0.59371435 -0.30324528  0.1347629 -1.6152901
[10,]  0.43343717  0.40489509  0.15193229 -0.4699063 -1.9367751
[11,]  0.02767957 -1.45037347  0.64468930 -0.9185758  2.7425520
[12,] -1.20978159 -0.53829574 -0.61108739  0.2048048 -1.7332922
[13,] -0.53678347  0.22547332 -0.33130608 -0.3681078 -1.4083897
[14,]  1.81406240  1.30743594  0.91967746  1.9580933  2.5773071
[15,]  0.07689757 -1.08711674  0.45722343 -0.8409150  0.2075005

$call
censReg(formula = yNeg ~ x1 + x2, left = -Inf, right = 0, data = pData, 
    method = "BFGSR")

$terms
yNeg ~ x1 + x2
attr(,"variables")
list(yNeg, x1, x2)
attr(,"factors")
     x1 x2
yNeg  0  0
x1    1  0
x2    0  1
attr(,"term.labels")
[1] "x1" "x2"
attr(,"order")
[1] 1 1
attr(,"intercept")
[1] 1
attr(,"response")
[1] 1
attr(,".Environment")
<environment: R_GlobalEnv>
attr(,"predvars")
list(yNeg, x1, x2)
attr(,"dataClasses")
     yNeg        x1        x2 
"numeric" "numeric" "numeric" 

$nObs
         Total  Left-censored     Uncensored Right-censored 
            60              0             40             20 

$df.residual
[1] 55

$start
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
 -0.4703506  -1.0111600  -1.6191826  -0.4962510  -0.0620962 

attr(,"class")
[1] "censReg" "maxLik"  "maxim"   "list"   
> 
> 
> ## right-censoring at -5
> pData$yAddNeg <- - pData$yAdd
> randEffAddNeg <- censReg( yAddNeg ~ x1 + x2, data = pData, method = "BFGSR",
+    left = -Inf, right = -5 )
> print( randEffAddNeg )

Call:
censReg(formula = yAddNeg ~ x1 + x2, left = -Inf, right = -5, 
    data = pData, method = "BFGSR")

Coefficients:
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
   -4.62963    -1.68013    -2.24807    -0.12910    -0.01241 

> maxLik:::summary.maxLik( randEffAddNeg )
--------------------------------------------
Maximum Likelihood estimation
BFGSR maximization, 85 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -73.19889 
5  free parameters
Estimates:
             Estimate Std. error t value   Pr(> t)    
(Intercept) -4.629631   0.474946 -9.7477 < 2.2e-16 ***
x1          -1.680126   0.209262 -8.0288 9.842e-16 ***
x2          -2.248069   0.674121 -3.3348 0.0008536 ***
logSigmaMu  -0.129100   0.257966 -0.5005 0.6167538    
logSigmaNu  -0.012414   0.129693 -0.0957 0.9237456    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> summary( randEffAddNeg )

Call:
censReg(formula = yAddNeg ~ x1 + x2, left = -Inf, right = -5, 
    data = pData, method = "BFGSR")

Observations:
         Total  Left-censored     Uncensored Right-censored 
            60              0             40             20 

Coefficients:
            Estimate Std. error t value  Pr(> t)    
(Intercept) -4.62963    0.47495  -9.748  < 2e-16 ***
x1          -1.68013    0.20926  -8.029 9.84e-16 ***
x2          -2.24807    0.67412  -3.335 0.000854 ***
logSigmaMu  -0.12910    0.25797  -0.500 0.616754    
logSigmaNu  -0.01241    0.12969  -0.096 0.923746    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

BFGSR maximization, 85 iterations
Return code 2: successive function values within tolerance limit
Log-likelihood: -73.19889 on 5 Df

> coef( randEffAddNeg )
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
-4.62963112 -1.68012569 -2.24806869 -0.12910048 -0.01241383 
> coef( randEffAddNeg, logSigma = FALSE )
(Intercept)          x1          x2     sigmaMu     sigmaNu 
 -4.6296311  -1.6801257  -2.2480687   0.8788857   0.9876629 
> vcov( randEffAddNeg )
             (Intercept)           x1           x2   logSigmaMu   logSigmaNu
(Intercept)  0.225574088 -0.020675852 -0.254968934  0.024050004  0.003054807
x1          -0.020675852  0.043790603  0.008675760 -0.013417474 -0.002967317
x2          -0.254968934  0.008675760  0.454439116 -0.017321604 -0.001702284
logSigmaMu   0.024050004 -0.013417474 -0.017321604  0.066546212 -0.002623446
logSigmaNu   0.003054807 -0.002967317 -0.001702284 -0.002623446  0.016820395
> vcov( randEffAddNeg, logSigma = FALSE )
            (Intercept)           x1           x2      sigmaMu      sigmaNu
(Intercept)  0.22557409 -0.020675852 -0.254968934  0.021137204  0.003017120
x1          -0.02067585  0.043790603  0.008675760 -0.011792425 -0.002930709
x2          -0.25496893  0.008675760  0.454439116 -0.015223709 -0.001681283
sigmaMu      0.02113720 -0.011792425 -0.015223709  0.051402955 -0.002277263
sigmaNu      0.00301712 -0.002930709 -0.001681283 -0.002277263  0.016407926
> logLik( randEffAddNeg )
'log Lik.' -73.19889 (df=5)
> extractAIC( randEffAddNeg )
[1] -40.0000 156.3978
> print.default( randEffAddNeg )
$maximum
[1] -73.19889

$estimate
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
-4.62963112 -1.68012569 -2.24806869 -0.12910048 -0.01241383 

$gradient
 (Intercept)           x1           x2   logSigmaMu   logSigmaNu 
-0.006782037 -0.003268441  0.012771145 -0.001540943  0.001956490 

$hessian
            (Intercept)         x1         x2  logSigmaMu  logSigmaNu
(Intercept)  -13.305966  -4.094969 -7.3011605   2.1334882   1.2879914
x1            -4.094969 -26.070909 -1.9884537  -4.4817187  -4.7557611
x2            -7.301161  -1.988454 -6.2331858   0.6327408   0.4430675
logSigmaMu     2.133488  -4.481719  0.6327408 -16.6836371  -3.7161781
logSigmaNu     1.287991  -4.755761  0.4430675  -3.7161781 -61.0592893

$code
[1] 2

$message
[1] "successive function values within tolerance limit"

$last.step
NULL

$fixed
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
      FALSE       FALSE       FALSE       FALSE       FALSE 

$iterations
[1] 85

$type
[1] "BFGSR maximization"

$gradientObs
      (Intercept)          x1          x2 logSigmaMu logSigmaNu
 [1,]  0.85204590 -0.22376353  0.07350679 -0.1446165 -0.9676764
 [2,]  1.70294220 -0.04673041  1.19081036  1.6824867 -1.0123850
 [3,] -1.74977466 -0.33339275 -1.72473527  1.8350221  1.7943089
 [4,] -0.15522980  0.20323643  0.43392429 -0.6892887 -1.4270883
 [5,] -0.12978089 -0.98296419 -0.68726038 -0.6769828 -0.5620545
 [6,] -0.32992386  0.30524255 -0.38356769 -0.4920085 -1.5823025
 [7,]  0.07976142  3.18624479  0.23679855 -0.6772788  6.0324382
 [8,]  0.26560113 -0.37783976 -0.05571611 -0.5390822 -1.1085218
 [9,] -1.14874192 -0.59405119 -0.30320419  0.1346536 -1.6151237
[10,]  0.43359021  0.40474211  0.15206160 -0.4697787 -1.9369663
[11,]  0.02768513 -1.45071918  0.64483999 -0.9185603  2.7435921
[12,] -1.20980451 -0.53859969 -0.61086594  0.2045109 -1.7329858
[13,] -0.53641044  0.22519630 -0.33105779 -0.3683966 -1.4086294
[14,]  1.81425930  1.30757225  0.91984085  1.9585302  2.5771659
[15,]  0.07699875 -1.08744217  0.45739609 -0.8407512  0.2081851

$call
censReg(formula = yAddNeg ~ x1 + x2, left = -Inf, right = -5, 
    data = pData, method = "BFGSR")

$terms
yAddNeg ~ x1 + x2
attr(,"variables")
list(yAddNeg, x1, x2)
attr(,"factors")
        x1 x2
yAddNeg  0  0
x1       1  0
x2       0  1
attr(,"term.labels")
[1] "x1" "x2"
attr(,"order")
[1] 1 1
attr(,"intercept")
[1] 1
attr(,"response")
[1] 1
attr(,".Environment")
<environment: R_GlobalEnv>
attr(,"predvars")
list(yAddNeg, x1, x2)
attr(,"dataClasses")
  yAddNeg        x1        x2 
"numeric" "numeric" "numeric" 

$nObs
         Total  Left-censored     Uncensored Right-censored 
            60              0             40             20 

$df.residual
[1] 55

$start
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
 -5.4703506  -1.0111600  -1.6191826  -0.4962510  -0.0620962 

attr(,"class")
[1] "censReg" "maxLik"  "maxim"   "list"   
> 
> 
> ## both right and left censoring
> pData$yBoth <- ifelse( pData$y < 3, pData$y, 3 )
> randEffBoth <- censReg( yBoth ~ x1 + x2, data = pData, method = "BFGSR",
+    left = 0, right = 3 )
> print( randEffBoth )

Call:
censReg(formula = yBoth ~ x1 + x2, left = 0, right = 3, data = pData, 
    method = "BFGSR")

Coefficients:
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
  -0.232110    1.892762    1.967098    0.001287    0.052617 

> maxLik:::summary.maxLik( randEffBoth )
--------------------------------------------
Maximum Likelihood estimation
BFGSR maximization, 92 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -64.31275 
5  free parameters
Estimates:
              Estimate Std. error t value   Pr(> t)    
(Intercept) -0.2321098  0.5480105 -0.4235   0.67189    
x1           1.8927621  0.3009583  6.2891 3.193e-10 ***
x2           1.9670981  0.8184026  2.4036   0.01624 *  
logSigmaMu   0.0012868  0.2778625  0.0046   0.99630    
logSigmaNu   0.0526171  0.1629769  0.3228   0.74681    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> summary( randEffBoth )

Call:
censReg(formula = yBoth ~ x1 + x2, left = 0, right = 3, data = pData, 
    method = "BFGSR")

Observations:
         Total  Left-censored     Uncensored Right-censored 
            60             20             28             12 

Coefficients:
             Estimate Std. error t value  Pr(> t)    
(Intercept) -0.232110   0.548011  -0.424   0.6719    
x1           1.892762   0.300958   6.289 3.19e-10 ***
x2           1.967098   0.818403   2.404   0.0162 *  
logSigmaMu   0.001287   0.277863   0.005   0.9963    
logSigmaNu   0.052617   0.162977   0.323   0.7468    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

BFGSR maximization, 92 iterations
Return code 2: successive function values within tolerance limit
Log-likelihood: -64.31275 on 5 Df

> print( summary( randEffBoth ), logSigma = FALSE )

Call:
censReg(formula = yBoth ~ x1 + x2, left = 0, right = 3, data = pData, 
    method = "BFGSR")

Observations:
         Total  Left-censored     Uncensored Right-censored 
            60             20             28             12 

Coefficients:
            Estimate Std. error t value  Pr(> t)    
(Intercept)  -0.2321     0.5480  -0.424  0.67189    
x1            1.8928     0.3010   6.289 3.19e-10 ***
x2            1.9671     0.8184   2.404  0.01624 *  
sigmaMu       1.0013     0.2782   3.599  0.00032 ***
sigmaNu       1.0540     0.1718   6.136 8.47e-10 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

BFGSR maximization, 92 iterations
Return code 2: successive function values within tolerance limit
Log-likelihood: -64.31275 on 5 Df

> coef( randEffBoth )
 (Intercept)           x1           x2   logSigmaMu   logSigmaNu 
-0.232109779  1.892762133  1.967098143  0.001286806  0.052617066 
> coef( randEffBoth, logSigma = FALSE )
(Intercept)          x1          x2     sigmaMu     sigmaNu 
 -0.2321098   1.8927621   1.9670981   1.0012876   1.0540259 
> vcov( randEffBoth )
            (Intercept)          x1          x2   logSigmaMu   logSigmaNu
(Intercept)  0.30031556 -0.03128535 -0.36363391 -0.015852457 -0.016319673
x1          -0.03128535  0.09057589  0.03165204  0.035162336  0.015900310
x2          -0.36363391  0.03165204  0.66978274  0.018525028  0.024387105
logSigmaMu  -0.01585246  0.03516234  0.01852503  0.077207586  0.004321898
logSigmaNu  -0.01631967  0.01590031  0.02438710  0.004321898  0.026561457
> vcov( randEffBoth, logSigma = FALSE )
            (Intercept)          x1          x2      sigmaMu      sigmaNu
(Intercept)  0.30031556 -0.03128535 -0.36363391 -0.015872870 -0.017201359
x1          -0.03128535  0.09057589  0.03165204  0.035207612  0.016759339
x2          -0.36363391  0.03165204  0.66978274  0.018548881  0.025704641
sigmaMu     -0.01587287  0.03520761  0.01854888  0.077406544  0.004561259
sigmaNu     -0.01720136  0.01675934  0.02570464  0.004561259  0.029509000
> coef( summary( randEffBoth ) )
                Estimate Std. error      t value      Pr(> t)
(Intercept) -0.232109779  0.5480105 -0.423549836 6.718941e-01
x1           1.892762133  0.3009583  6.289117905 3.192749e-10
x2           1.967098143  0.8184026  2.403582609 1.623530e-02
logSigmaMu   0.001286806  0.2778625  0.004631088 9.963049e-01
logSigmaNu   0.052617066  0.1629769  0.322849918 7.468089e-01
> coef( summary( randEffBoth ), logSigma = FALSE )
              Estimate Std. error    t value      Pr(> t)
(Intercept) -0.2321098  0.5480105 -0.4235498 6.718941e-01
x1           1.8927621  0.3009583  6.2891179 3.192749e-10
x2           1.9670981  0.8184026  2.4035826 1.623530e-02
sigmaMu      1.0012876  0.2782203  3.5989019 3.195636e-04
sigmaNu      1.0540259  0.1717818  6.1358404 8.471016e-10
> logLik( randEffBoth )
'log Lik.' -64.31275 (df=5)
> extractAIC( randEffBoth )
[1] -40.0000 138.6255
> print.default( randEffBoth )
$maximum
[1] -64.31275

$estimate
 (Intercept)           x1           x2   logSigmaMu   logSigmaNu 
-0.232109779  1.892762133  1.967098143  0.001286806  0.052617066 

$gradient
  (Intercept)            x1            x2    logSigmaMu    logSigmaNu 
-0.0053397985  0.0008211122  0.0047057159  0.0036527282  0.0014332574 

$hessian
            (Intercept)          x1         x2   logSigmaMu  logSigmaNu
(Intercept) -9.93690964  -1.4931040 -5.3106231  -0.06788227  -0.3246134
x1          -1.49310404 -15.1487281 -0.5466472   6.29670027   7.6283447
x2          -5.31062305  -0.5466472 -4.3937063   0.15269069   1.0735137
logSigmaMu  -0.06788227   6.2967003  0.1526907 -15.79301558  -1.3815199
logSigmaNu  -0.32461335   7.6283447  1.0735137  -1.38151990 -43.1753328

$code
[1] 2

$message
[1] "successive function values within tolerance limit"

$last.step
NULL

$fixed
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
      FALSE       FALSE       FALSE       FALSE       FALSE 

$iterations
[1] 92

$type
[1] "BFGSR maximization"

$gradientObs
      (Intercept)         x1          x2  logSigmaMu logSigmaNu
 [1,] -0.85455169 -0.1057668 -0.18131590 -0.02323934 -0.8360390
 [2,] -1.41700710 -0.0260301 -0.97173119  1.45616901 -1.1647476
 [3,]  1.29778887  1.0217991  0.92592440  1.09206787  0.1543625
 [4,]  0.07097108 -0.2516153 -0.39788580 -0.70164936 -1.8283297
 [5,]  0.08902305  0.8081334  0.64824509 -0.69074247 -0.2828186
 [6,]  0.55957220  0.4947325  0.42925652 -0.29131765 -0.3595702
 [7,] -0.12103287 -3.0615336 -0.23684757 -0.70594064  6.3413469
 [8,] -0.21013081  0.3359588  0.08321794 -0.59042342 -1.0297949
 [9,]  1.03430224  0.6608875  0.28835159  0.19642359 -1.2972792
[10,] -0.42866872 -0.5857419 -0.11747927 -0.39555575 -1.8007078
[11,] -0.04099703  1.0946561 -0.50823374 -0.86625671  2.0006943
[12,]  1.14077732  0.5050962  0.83289642  0.58577485 -0.7446512
[13,]  0.53439941 -0.2815291  0.34775868 -0.28706450 -1.4337307
[14,] -1.63841105 -1.3470395 -0.83801009  2.11946254  2.7651590
[15,] -0.02137469  0.7388138 -0.29944136 -0.89405530 -0.4824606

$call
censReg(formula = yBoth ~ x1 + x2, left = 0, right = 3, data = pData, 
    method = "BFGSR")

$terms
yBoth ~ x1 + x2
attr(,"variables")
list(yBoth, x1, x2)
attr(,"factors")
      x1 x2
yBoth  0  0
x1     1  0
x2     0  1
attr(,"term.labels")
[1] "x1" "x2"
attr(,"order")
[1] 1 1
attr(,"intercept")
[1] 1
attr(,"response")
[1] 1
attr(,".Environment")
<environment: R_GlobalEnv>
attr(,"predvars")
list(yBoth, x1, x2)
attr(,"dataClasses")
    yBoth        x1        x2 
"numeric" "numeric" "numeric" 

$nObs
         Total  Left-censored     Uncensored Right-censored 
            60             20             28             12 

$df.residual
[1] 55

$start
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
  0.6056357   0.8113032   1.0023997  -0.7545646  -0.2748137 

attr(,"class")
[1] "censReg" "maxLik"  "maxim"   "list"   
> 
> 
> ## re-order observations/individuals
> set.seed( 234 )
> perm <- sample( nId )
> nData2 <- nData
> nData2$id <- NA
> for( i in 1:nId ) {
+    nData2$id[ nData$id == paste( "F", i, sep = "_" ) ] <-
+       paste( "G", perm[ i ], sep = "_" )
+ }
> pData2 <- pdata.frame( nData2, c( "id", "time" ) )
> randEffBfgsr2 <- censReg( y ~ x1 + x2, data = pData2, method = "BFGSR" )
> all.equal( randEffBfgsr2[ -c(11,12) ], randEffBfgsr[ -c(11,12) ] )
[1] "Component 1: Mean relative difference: 3.392688e-07"
[2] "Component 2: Mean relative difference: 0.0006131182"
[3] "Component 3: Mean relative difference: 0.8783096"   
[4] "Component 4: Mean relative difference: 0.000747027" 
[5] "Component 9: Mean relative difference: 0.1176471"   
> all.equal( sort( randEffBfgsr2[[ 11 ]] ), sort( randEffBfgsr[[ 11 ]] ) )
[1] "Mean relative difference: 0.0006980243"
> 
> # check if the order of observations/individuals influences the likelihood values
> d1c1 <- censReg( y ~ x1 + x2, data = pData, method = "BFGSR", start = coef(randEffBfgsr),
+    iterlim = 0 )
> all.equal( d1c1[-c(5,6,9,12,16)], randEffBfgsr[-c(5,6,9,12,16)] )
[1] TRUE
> d1c1$maximum -  randEffBfgsr$maximum
[1] 0
> 
> d2c2 <- censReg( y ~ x1 + x2, data = pData2, method = "BFGSR", start = coef(randEffBfgsr2),
+    iterlim = 0 )
> all.equal( d2c2[-c(5,6,9,12,16)], randEffBfgsr2[-c(5,6,9,12,16)] )
[1] TRUE
> d2c2$maximum -  randEffBfgsr2$maximum
[1] 0
> 
> d1c2 <- censReg( y ~ x1 + x2, data = pData, method = "BFGSR", 
+    start = coef(randEffBfgsr2), iterlim = 0 )
> d2c2$maximum - d1c2$maximum
[1] 0
> d2c2$gradient - d1c2$gradient
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
          0           0           0           0           0 
> 
> d2c1 <- censReg( y ~ x1 + x2, data = pData2, method = "BFGSR", 
+    start = coef(randEffBfgsr), iterlim = 0 )
> d1c1$maximum - d2c1$maximum
[1] 0
> d1c1$gradient - d2c1$gradient
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
          0           0           0           0           0 
> 
> d2c2$maximum - d2c1$maximum
[1] -2.48341e-05
> d1c1$maximum - d1c2$maximum
[1] 2.48341e-05
> 
> d1cS <- censReg( y ~ x1 + x2, data = pData, method = "BFGSR", 
+    start = randEffBfgsr$start, iterlim = 0 )
> d2cS <- censReg( y ~ x1 + x2, data = pData2, method = "BFGSR", 
+    start = randEffBfgsr$start, iterlim = 0 )
> d1cS$maximum - d2cS$maximum
[1] 0
> d1cS$gradient - d2cS$gradient
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
          0           0           0           0           0 
> 
> 
> ## unbalanced panel data
> nDataUnb <- nData[ -c( 2, 5, 6, 8 ), ]
> pDataUnb <- pdata.frame( nDataUnb, c( "id", "time" ) )
> randEffBfgsrUnb <- censReg( y ~ x1 + x2, data = pDataUnb, method = "BFGSR" )
> print( randEffBfgsrUnb )

Call:
censReg(formula = y ~ x1 + x2, data = pDataUnb, method = "BFGSR")

Coefficients:
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
   -0.22150     1.64064     2.10609    -0.16724    -0.00113 

> maxLik:::summary.maxLik( randEffBfgsrUnb )
--------------------------------------------
Maximum Likelihood estimation
BFGSR maximization, 82 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -71.1926 
5  free parameters
Estimates:
              Estimate Std. error t value   Pr(> t)    
(Intercept) -0.2215015  0.4724742 -0.4688  0.639204    
x1           1.6406364  0.2110522  7.7736 7.628e-15 ***
x2           2.1060928  0.6848340  3.0753  0.002103 ** 
logSigmaMu  -0.1672372  0.2714962 -0.6160  0.537905    
logSigmaNu  -0.0011304  0.1322777 -0.0085  0.993182    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> summary( randEffBfgsrUnb )

Call:
censReg(formula = y ~ x1 + x2, data = pDataUnb, method = "BFGSR")

Observations:
         Total  Left-censored     Uncensored Right-censored 
            56             17             39              0 

Coefficients:
            Estimate Std. error t value  Pr(> t)    
(Intercept) -0.22150    0.47247  -0.469   0.6392    
x1           1.64064    0.21105   7.774 7.63e-15 ***
x2           2.10609    0.68483   3.075   0.0021 ** 
logSigmaMu  -0.16724    0.27150  -0.616   0.5379    
logSigmaNu  -0.00113    0.13228  -0.009   0.9932    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

BFGSR maximization, 82 iterations
Return code 2: successive function values within tolerance limit
Log-likelihood: -71.1926 on 5 Df

> logLik( randEffBfgsrUnb )
'log Lik.' -71.1926 (df=5)
> extractAIC( randEffBfgsrUnb )
[1] -36.0000 152.3852
> print.default( randEffBfgsrUnb )
$maximum
[1] -71.1926

$estimate
 (Intercept)           x1           x2   logSigmaMu   logSigmaNu 
-0.221501532  1.640636389  2.106092791 -0.167237237 -0.001130368 

$gradient
  (Intercept)            x1            x2    logSigmaMu    logSigmaNu 
-0.0046334514 -0.0044262892  0.0104276806 -0.0039640885 -0.0008670723 

$hessian
            (Intercept)         x1         x2  logSigmaMu logSigmaNu
(Intercept)  -13.789006  -4.345777 -7.5270718  -1.1044007  -1.944740
x1            -4.345777 -25.811532 -2.0575312   4.6517432   4.061606
x2            -7.527072  -2.057531 -6.2651172  -0.1419104  -1.070855
logSigmaMu    -1.104401   4.651743 -0.1419104 -14.9275865  -3.771336
logSigmaNu    -1.944740   4.061606 -1.0708553  -3.7713365 -58.832727

$code
[1] 2

$message
[1] "successive function values within tolerance limit"

$last.step
NULL

$fixed
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
      FALSE       FALSE       FALSE       FALSE       FALSE 

$iterations
[1] 82

$type
[1] "BFGSR maximization"

$gradientObs
      (Intercept)           x1         x2  logSigmaMu  logSigmaNu
 [1,] -0.50868085  0.089358052  0.1037872 -0.39411365 -0.52971556
 [2,] -1.81627024  0.067542860 -1.2464076  1.79733557 -0.96212548
 [3,]  1.78395505  0.483810997  1.7699334  1.73283462  1.89776788
 [4,]  0.15179018 -0.162590796 -0.3957634 -0.73690657 -1.58772419
 [5,]  0.08162853  1.039064882  0.6985891 -0.67823470 -0.44427587
 [6,]  0.33221112 -0.234452504  0.3740015 -0.53977553 -1.57280771
 [7,] -0.18101174 -3.029777028 -0.2486541 -0.62220718  5.48159018
 [8,]  0.01878867 -0.004095458  0.0107459 -0.41780303 -0.58159173
 [9,]  1.11548872  0.666124586  0.2956561  0.06294105 -1.68634596
[10,] -0.53787854 -0.420788481 -0.2041559 -0.40631587 -1.97396438
[11,] -0.08320030  1.377811297 -0.6473636 -0.82322729  2.49346870
[12,]  1.25870386  0.531059899  0.6699927  0.23041520 -1.79412224
[13,]  0.44664307 -0.163536826  0.2864696 -0.46814802 -1.45029731
[14,] -1.89223357 -1.286174624 -0.9616301  1.98298137  2.68233787
[15,] -0.17456741  1.042216855 -0.4947731 -0.72374005  0.02693874

$call
censReg(formula = y ~ x1 + x2, data = pDataUnb, method = "BFGSR")

$terms
y ~ x1 + x2
attr(,"variables")
list(y, x1, x2)
attr(,"factors")
   x1 x2
y   0  0
x1  1  0
x2  0  1
attr(,"term.labels")
[1] "x1" "x2"
attr(,"order")
[1] 1 1
attr(,"intercept")
[1] 1
attr(,"response")
[1] 1
attr(,".Environment")
<environment: R_GlobalEnv>
attr(,"predvars")
list(y, x1, x2)
attr(,"dataClasses")
        y        x1        x2 
"numeric" "numeric" "numeric" 

$nObs
         Total  Left-censored     Uncensored Right-censored 
            56             17             39              0 

$df.residual
[1] 51

$start
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
 0.48299720  1.03002625  1.63470549 -0.47772116 -0.04988945 

attr(,"class")
[1] "censReg" "maxLik"  "maxim"   "list"   
> 
> 
> ## NAs in data
> pDataNa <- pData
> obsNa <- which( ! rownames( pData ) %in% rownames( pDataUnb ) )
> pDataNa$y[ obsNa[ 1:2 ] ] <- NA
> pDataNa$x1[ obsNa[ 3 ] ] <- NA
> pDataNa$x2[ obsNa[ c( 1, 2, 4 ) ] ] <- NA
> randEffBfgsrNa <- censReg( y ~ x1 + x2, data = pDataNa, method = "BFGSR" )
> all.equal( randEffBfgsrNa[ -12 ], randEffBfgsrUnb[ -12 ] )
[1] TRUE
> 
> 
> # returning log-likelihood contributions only (no estimations)
> logLikRandEff <- censReg( y ~ x1 + x2, data = pData, start = coef( randEff ),
+    logLikOnly = TRUE )
> print( logLikRandEff )
 [1] -4.252049 -3.739068 -7.046358 -5.300447 -3.354337 -5.307797 -6.291576
 [8] -1.655650 -4.393946 -3.765898 -6.821870 -5.646158 -4.333350 -5.726405
[15] -5.563914
attr(,"gradient")
             [,1]        [,2]        [,3]       [,4]       [,5]
 [1,] -0.85308353  0.22558520 -0.07261010 -0.1440032 -0.9609402
 [2,] -1.70309357  0.04839424 -1.18987552  1.6807831 -1.0133141
 [3,]  1.75084247  0.33367482  1.72755770  1.8353812  1.8043727
 [4,]  0.15577733 -0.20240007 -0.43224660 -0.6891081 -1.4351382
 [5,]  0.12950026  0.98433620  0.68943625 -0.6770204 -0.5543803
 [6,]  0.33035909 -0.30928416  0.38471147 -0.4921375 -1.5793716
 [7,] -0.08212549 -3.18521871 -0.23724729 -0.6766315  6.0271932
 [8,] -0.26685300  0.37888544  0.05565473 -0.5385828 -1.1091111
 [9,]  1.14824183  0.59396387  0.30328556  0.1329802 -1.6172740
[10,] -0.43505392 -0.40640593 -0.15245982 -0.4687582 -1.9364984
[11,] -0.02839185  1.44795739 -0.64407731 -0.9172655  2.7349924
[12,]  1.21047881  0.53669833  0.61328528  0.2055542 -1.7351236
[13,]  0.53592707 -0.22523044  0.33117482 -0.3691166 -1.4082834
[14,] -1.81460674 -1.30608969 -0.91950989  1.9573174  2.5815580
[15,] -0.07791875  1.08513351 -0.45707928 -0.8393922  0.2013187
> all.equal( sum( logLikRandEff ), c( logLik( randEff ) ) )
[1] TRUE
> logLikStart <- censReg( y ~ x1 + x2, data = pData, 
+    start = c( -0.4, 1.7, 2.2, -0.1, -0.01 ), logLikOnly = TRUE )
> print( logLikStart )
 [1] -4.223693 -3.590625 -7.110342 -5.316228 -3.389378 -5.360380 -6.349353
 [8] -1.661668 -4.433769 -3.774324 -6.788058 -5.699416 -4.385225 -5.593147
[15] -5.548283
attr(,"gradient")
             [,1]        [,2]        [,3]       [,4]       [,5]
 [1,] -0.78780430  0.27899526 -0.03948865 -0.1781187 -1.0281108
 [2,] -1.58232641  0.09231159 -1.09619445  1.4850210 -1.0562683
 [3,]  1.72436737  0.26392132  1.72228285  1.9089216  1.8439353
 [4,]  0.18480626 -0.20993642 -0.40681657 -0.6139118 -1.5330720
 [5,]  0.16156500  0.97006006  0.71388764 -0.6642389 -0.5115526
 [6,]  0.36176010 -0.38785781  0.42046000 -0.4277169 -1.5829540
 [7,] -0.04900991 -3.19667670 -0.23065229 -0.6996566  6.1344398
 [8,] -0.21856969  0.35678338  0.07820116 -0.5684845 -1.0658263
 [9,]  1.13458709  0.55150636  0.30101863  0.1460472 -1.6130954
[10,] -0.35438475 -0.38788784 -0.10704963 -0.5248618 -1.9100687
[11,] -0.01373800  1.42364787 -0.62446618 -0.9654173  2.6815112
[12,]  1.16280483  0.49951850  0.60156788  0.2025718 -1.7537215
[13,]  0.59996890 -0.26781383  0.36925229 -0.2994739 -1.3806520
[14,] -1.71185020 -1.20078722 -0.84865925  1.8183688  2.4960866
[15,] -0.03387939  1.05747706 -0.42268903 -0.9163573  0.1985986
> 
> 
> 
> 
