
R version 3.0.1 (2013-05-16) -- "Good Sport"
Copyright (C) 2013 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> library( censReg )
Loading required package: maxLik
Loading required package: miscTools
> library( plm )
Loading required package: bdsmatrix

Attaching package: 'bdsmatrix'

The following object is masked from 'package:base':

    backsolve

Loading required package: nlme
Loading required package: Formula
Loading required package: MASS
Loading required package: sandwich
Loading required package: zoo

Attaching package: 'zoo'

The following object is masked from 'package:base':

    as.Date, as.Date.numeric

> 
> options( digits = 5 )
> 
> nId <- 15
> nTime <- 4
> 
> set.seed( 123 )
> pData <- data.frame(
+    id = rep( paste( "F", 1:nId, sep = "_" ), each = nTime ),
+    time = rep( 1980 + 1:nTime, nId ) )
> pData$ui <- rep( rnorm( nId ), each = nTime )
> pData$x1 <- rnorm( nId * nTime )
> pData$x2 <- runif( nId * nTime )
> pData$ys <- -1 + pData$ui + 2 * pData$x1 + 3 * pData$x2 + rnorm( nId * nTime )
> pData$y <- ifelse( pData$ys > 0, pData$ys, 0 )
> nData <- pData # save data set without information on panel structure
> pData <- pdata.frame( pData, c( "id", "time" ) )
> 
> 
> ## Newton-Raphson method
> randEff <- censReg( y ~ x1 + x2, data = pData )
> print( randEff )

Call:
censReg(formula = y ~ x1 + x2, data = pData)

Coefficients:
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
   -0.36562     1.68000     2.24054    -0.12955    -0.01241 

> print( randEff, logSigma = FALSE )

Call:
censReg(formula = y ~ x1 + x2, data = pData)

Coefficients:
(Intercept)          x1          x2     sigmaMu     sigmaNu 
    -0.3656      1.6800      2.2405      0.8785      0.9877 

> maxLik:::summary.maxLik( randEff )
--------------------------------------------
Maximum Likelihood estimation
Newton-Raphson maximisation, 5 iterations
Return code 1: gradient close to zero
Log-Likelihood: -73.199 
5  free parameters
Estimates:
            Estimate Std. error t value Pr(> t)    
(Intercept)  -0.3656     0.4745   -0.77 0.44094    
x1            1.6800     0.2092    8.03 9.8e-16 ***
x2            2.2405     0.6739    3.32 0.00088 ***
logSigmaMu   -0.1295     0.2581   -0.50 0.61568    
logSigmaNu   -0.0124     0.1297   -0.10 0.92378    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
--------------------------------------------
> summary( randEff )

Call:
censReg(formula = y ~ x1 + x2, data = pData)

Observations:
         Total  Left-censored     Uncensored Right-censored 
            60             20             40              0 

Coefficients:
            Estimate Std. error t value  Pr(> t)    
(Intercept) -0.36562    0.47446  -0.771 0.440936    
x1           1.68000    0.20922   8.030 9.77e-16 ***
x2           2.24054    0.67389   3.325 0.000885 ***
logSigmaMu  -0.12955    0.25807  -0.502 0.615679    
logSigmaNu  -0.01241    0.12969  -0.096 0.923779    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Newton-Raphson maximisation, 5 iterations
Return code 1: gradient close to zero
Log-likelihood: -73.199 on 5 Df

> print( summary( randEff ), logSigma = FALSE )

Call:
censReg(formula = y ~ x1 + x2, data = pData)

Observations:
         Total  Left-censored     Uncensored Right-censored 
            60             20             40              0 

Coefficients:
            Estimate Std. error t value  Pr(> t)    
(Intercept)  -0.3656     0.4745  -0.771 0.440936    
x1            1.6800     0.2092   8.030 9.77e-16 ***
x2            2.2405     0.6739   3.325 0.000885 ***
sigmaMu       0.8785     0.2267   3.875 0.000107 ***
sigmaNu       0.9877     0.1281   7.711 1.25e-14 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Newton-Raphson maximisation, 5 iterations
Return code 1: gradient close to zero
Log-likelihood: -73.199 on 5 Df

> coef( randEff )
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
  -0.365623    1.680004    2.240544   -0.129547   -0.012408 
> coef( randEff, logSigma = FALSE )
(Intercept)          x1          x2     sigmaMu     sigmaNu 
   -0.36562     1.68000     2.24054     0.87849     0.98767 
> vcov( randEff )
            (Intercept)         x1         x2 logSigmaMu logSigmaNu
(Intercept)    0.225110 -0.0205702 -0.2546029 -0.0238242 -0.0029740
x1            -0.020570  0.0437740  0.0085622  0.0134041  0.0029700
x2            -0.254603  0.0085622  0.4541259  0.0171795  0.0015054
logSigmaMu    -0.023824  0.0134041  0.0171795  0.0666003 -0.0026389
logSigmaNu    -0.002974  0.0029700  0.0015054 -0.0026389  0.0168194
> vcov( randEff, logSigma = FALSE )
            (Intercept)         x1         x2    sigmaMu    sigmaNu
(Intercept)   0.2251097 -0.0205702 -0.2546029 -0.0209294 -0.0029373
x1           -0.0205702  0.0437740  0.0085622  0.0117754  0.0029333
x2           -0.2546029  0.0085622  0.4541259  0.0150921  0.0014869
sigmaMu      -0.0209294  0.0117754  0.0150921  0.0513988 -0.0022896
sigmaNu      -0.0029373  0.0029333  0.0014869 -0.0022896  0.0164072
> coef( summary( randEff ) )
             Estimate Std. error   t value    Pr(> t)
(Intercept) -0.365623    0.47446 -0.770613 4.4094e-01
x1           1.680004    0.20922  8.029756 9.7667e-16
x2           2.240544    0.67389  3.324798 8.8483e-04
logSigmaMu  -0.129547    0.25807 -0.501983 6.1568e-01
logSigmaNu  -0.012408    0.12969 -0.095675 9.2378e-01
> coef( summary( randEff ), logSigma = FALSE )
            Estimate Std. error  t value    Pr(> t)
(Intercept) -0.36562    0.47446 -0.77061 4.4094e-01
x1           1.68000    0.20922  8.02976 9.7667e-16
x2           2.24054    0.67389  3.32480 8.8483e-04
sigmaMu      0.87849    0.22671  3.87491 1.0666e-04
sigmaNu      0.98767    0.12809  7.71071 1.2512e-14
> try( margEff( randEff ) )
Error in margEff.censReg(randEff) : 
  the margEff() method for objects of class 'censReg' can not yet be used for panel data models
> logLik( randEff )
'log Lik.' -73.199 (df=5)
> nobs( randEff )
[1] 60
> extractAIC( randEff )
[1] -40.0 156.4
> print.default( randEff )
$maximum
[1] -73.199

$estimate
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
  -0.365623    1.680004    2.240544   -0.129547   -0.012408 

$gradient
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
 1.7114e-11  4.5338e-11  1.3447e-11  8.2164e-12  6.2075e-11 

$hessian
            (Intercept)       x1       x2 logSigmaMu logSigmaNu
(Intercept)    -13.3220  -4.0966 -7.30757   -2.10790   -1.30882
x1              -4.0966 -26.0768 -1.99053    4.48496    4.76209
x2              -7.3076  -1.9905 -6.23626   -0.62383   -0.48031
logSigmaMu      -2.1079   4.4850 -0.62383  -16.65820   -3.72240
logSigmaNu      -1.3088   4.7621 -0.48031   -3.72240  -61.06834

$code
[1] 1

$message
[1] "gradient close to zero"

$last.step
NULL

$fixed
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
      FALSE       FALSE       FALSE       FALSE       FALSE 

$iterations
[1] 5

$type
[1] "Newton-Raphson maximisation"

$gradientObs
      (Intercept)        x1        x2 logSigmaMu logSigmaNu
 [1,]   -0.853084  0.225585 -0.072610   -0.14400   -0.96094
 [2,]   -1.703094  0.048394 -1.189876    1.68078   -1.01331
 [3,]    1.750842  0.333675  1.727558    1.83538    1.80437
 [4,]    0.155777 -0.202400 -0.432247   -0.68911   -1.43514
 [5,]    0.129500  0.984336  0.689436   -0.67702   -0.55438
 [6,]    0.330359 -0.309284  0.384711   -0.49214   -1.57937
 [7,]   -0.082125 -3.185219 -0.237247   -0.67663    6.02719
 [8,]   -0.266853  0.378885  0.055655   -0.53858   -1.10911
 [9,]    1.148242  0.593964  0.303286    0.13298   -1.61727
[10,]   -0.435054 -0.406406 -0.152460   -0.46876   -1.93650
[11,]   -0.028392  1.447957 -0.644077   -0.91727    2.73499
[12,]    1.210479  0.536698  0.613285    0.20555   -1.73512
[13,]    0.535927 -0.225230  0.331175   -0.36912   -1.40828
[14,]   -1.814607 -1.306090 -0.919510    1.95732    2.58156
[15,]   -0.077919  1.085134 -0.457079   -0.83939    0.20132

$xMean
(Intercept)          x1          x2 
  1.0000000  -0.0051594   0.5041407 

$call
censReg(formula = y ~ x1 + x2, data = pData)

$terms
y ~ x1 + x2
attr(,"variables")
list(y, x1, x2)
attr(,"factors")
   x1 x2
y   0  0
x1  1  0
x2  0  1
attr(,"term.labels")
[1] "x1" "x2"
attr(,"order")
[1] 1 1
attr(,"intercept")
[1] 1
attr(,"response")
[1] 1
attr(,".Environment")
<environment: R_GlobalEnv>
attr(,"predvars")
list(y, x1, x2)
attr(,"dataClasses")
        y        x1        x2 
"numeric" "numeric" "numeric" 

$nObs
         Total  Left-censored     Uncensored Right-censored 
            60             20             40              0 

$df.residual
[1] 55

$start
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
   0.470351    1.011160    1.619183   -0.496251   -0.062096 

$left
[1] 0

$right
[1] Inf

attr(,"class")
[1] "censReg" "maxLik"  "maxim"   "list"   
> 
> 
> ## BHHH method
> randEffBhhh <- censReg( y ~ x1 + x2, data = pData, method = "BHHH" )
> print( randEffBhhh )

Call:
censReg(formula = y ~ x1 + x2, data = pData, method = "BHHH")

Coefficients:
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
    -0.3656      1.6800      2.2406     -0.1296     -0.0124 

> maxLik:::summary.maxLik( randEffBhhh )
--------------------------------------------
Maximum Likelihood estimation
BHHH maximisation, 18 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -73.199 
5  free parameters
Estimates:
            Estimate Std. error t value Pr(> t)    
(Intercept)  -0.3656     0.5551   -0.66  0.5101    
x1            1.6800     0.2938    5.72 1.1e-08 ***
x2            2.2406     0.7295    3.07  0.0021 ** 
logSigmaMu   -0.1296     0.2950   -0.44  0.6605    
logSigmaNu   -0.0124     0.1401   -0.09  0.9295    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
--------------------------------------------
> summary( randEffBhhh )

Call:
censReg(formula = y ~ x1 + x2, data = pData, method = "BHHH")

Observations:
         Total  Left-censored     Uncensored Right-censored 
            60             20             40              0 

Coefficients:
            Estimate Std. error t value  Pr(> t)    
(Intercept)  -0.3656     0.5551  -0.659  0.51006    
x1            1.6800     0.2938   5.719 1.07e-08 ***
x2            2.2406     0.7295   3.071  0.00213 ** 
logSigmaMu   -0.1296     0.2950  -0.439  0.66053    
logSigmaNu   -0.0124     0.1401  -0.088  0.92948    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

BHHH maximisation, 18 iterations
Return code 2: successive function values within tolerance limit
Log-likelihood: -73.199 on 5 Df

> print.default( randEffBhhh )
$maximum
[1] -73.199

$estimate
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
  -0.365635    1.680016    2.240556   -0.129565   -0.012402 

$gradient
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
 5.0283e-05 -3.3151e-04 -4.2464e-06  3.5050e-04 -2.6264e-04 

$hessian
            (Intercept)       x1       x2 logSigmaMu logSigmaNu
(Intercept)    -13.4825  -4.0961 -8.32414    2.73732     3.9590
x1              -4.0961 -17.3959 -2.19562    2.09494    19.0296
x2              -8.3241  -2.1956 -7.34562   -0.24371     3.4216
logSigmaMu       2.7373   2.0949 -0.24371  -13.93089    -3.6391
logSigmaNu       3.9590  19.0296  3.42156   -3.63914   -73.1687
attr(,"type")
[1] "BHHH"

$code
[1] 2

$message
[1] "successive function values within tolerance limit"

$last.step
NULL

$fixed
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
      FALSE       FALSE       FALSE       FALSE       FALSE 

$iterations
[1] 18

$type
[1] "BHHH maximisation"

$gradientObs
      (Intercept)        x1        x2 logSigmaMu logSigmaNu
 [1,]   -0.853099  0.225540 -0.072630   -0.14400   -0.96098
 [2,]   -1.703141  0.048349 -1.189915    1.68082   -1.01330
 [3,]    1.750892  0.333681  1.727577    1.83540    1.80443
 [4,]    0.155816 -0.202408 -0.432219   -0.68909   -1.43515
 [5,]    0.129512  0.984317  0.689430   -0.67700   -0.55442
 [6,]    0.330385 -0.309297  0.384731   -0.49214   -1.57937
 [7,]   -0.082122 -3.185197 -0.237245   -0.67661    6.02716
 [8,]   -0.266852  0.378881  0.055653   -0.53857   -1.10912
 [9,]    1.148264  0.593923  0.303295    0.13302   -1.61729
[10,]   -0.435075 -0.406422 -0.152470   -0.46875   -1.93649
[11,]   -0.028401  1.447931 -0.644072   -0.91723    2.73488
[12,]    1.210508  0.536696  0.613305    0.20562   -1.73516
[13,]    0.535958 -0.225248  0.331192   -0.36911   -1.40827
[14,]   -1.814657 -1.306190 -0.919553    1.95736    2.58156
[15,]   -0.077939  1.085111 -0.457082   -0.83937    0.20125

$xMean
(Intercept)          x1          x2 
  1.0000000  -0.0051594   0.5041407 

$call
censReg(formula = y ~ x1 + x2, data = pData, method = "BHHH")

$terms
y ~ x1 + x2
attr(,"variables")
list(y, x1, x2)
attr(,"factors")
   x1 x2
y   0  0
x1  1  0
x2  0  1
attr(,"term.labels")
[1] "x1" "x2"
attr(,"order")
[1] 1 1
attr(,"intercept")
[1] 1
attr(,"response")
[1] 1
attr(,".Environment")
<environment: R_GlobalEnv>
attr(,"predvars")
list(y, x1, x2)
attr(,"dataClasses")
        y        x1        x2 
"numeric" "numeric" "numeric" 

$nObs
         Total  Left-censored     Uncensored Right-censored 
            60             20             40              0 

$df.residual
[1] 55

$start
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
   0.470351    1.011160    1.619183   -0.496251   -0.062096 

$left
[1] 0

$right
[1] Inf

attr(,"class")
[1] "censReg" "maxLik"  "maxim"   "list"   
> 
> 
> ## BFGS method (optim)
> randEffBfgs <- censReg( y ~ x1 + x2, data = pData, method = "BFGS" )
> print( randEffBfgs )

Call:
censReg(formula = y ~ x1 + x2, data = pData, method = "BFGS")

Coefficients:
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
   -0.36562     1.68000     2.24055    -0.12955    -0.01241 

> maxLik:::summary.maxLik( randEffBfgs )
--------------------------------------------
Maximum Likelihood estimation
BFGS maximisation, 25 iterations
Return code 0: successful convergence 
Log-Likelihood: -73.199 
5  free parameters
Estimates:
            Estimate Std. error t value Pr(> t)    
(Intercept)  -0.3656     0.4745   -0.77 0.44093    
x1            1.6800     0.2092    8.03 9.8e-16 ***
x2            2.2406     0.6739    3.32 0.00088 ***
logSigmaMu   -0.1295     0.2581   -0.50 0.61567    
logSigmaNu   -0.0124     0.1297   -0.10 0.92378    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
--------------------------------------------
> summary( randEffBfgs )

Call:
censReg(formula = y ~ x1 + x2, data = pData, method = "BFGS")

Observations:
         Total  Left-censored     Uncensored Right-censored 
            60             20             40              0 

Coefficients:
            Estimate Std. error t value  Pr(> t)    
(Intercept) -0.36562    0.47446  -0.771 0.440934    
x1           1.68000    0.20922   8.030 9.77e-16 ***
x2           2.24055    0.67389   3.325 0.000885 ***
logSigmaMu  -0.12955    0.25807  -0.502 0.615673    
logSigmaNu  -0.01241    0.12969  -0.096 0.923776    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

BFGS maximisation, 25 iterations
Return code 0: successful convergence 
Log-likelihood: -73.199 on 5 Df

> print.default( randEffBfgs )
$maximum
[1] -73.199

$estimate
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
  -0.365624    1.680002    2.240551   -0.129549   -0.012408 

$gradient
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
-3.1601e-05  2.1783e-05 -3.5707e-05  3.0817e-05  2.1081e-05 

$hessian
            (Intercept)       x1       x2 logSigmaMu logSigmaNu
(Intercept)    -13.3220  -4.0966 -7.30759   -2.10785   -1.30881
x1              -4.0966 -26.0768 -1.99053    4.48498    4.76204
x2              -7.3076  -1.9905 -6.23627   -0.62379   -0.48026
logSigmaMu      -2.1079   4.4850 -0.62379  -16.65815   -3.72243
logSigmaNu      -1.3088   4.7620 -0.48026   -3.72243  -61.06840

$code
[1] 0

$message
[1] "successful convergence "

$last.step
NULL

$fixed
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
      FALSE       FALSE       FALSE       FALSE       FALSE 

$iterations
function 
      25 

$type
[1] "BFGS maximisation"

$constraints
NULL

$gradientObs
      (Intercept)       x1        x2 logSigmaMu logSigmaNu
 [1,]   -0.853087  0.22558 -0.072613   -0.14400   -0.96094
 [2,]   -1.703103  0.04839 -1.189884    1.68080   -1.01331
 [3,]    1.750847  0.33368  1.727558    1.83538    1.80437
 [4,]    0.155776 -0.20240 -0.432249   -0.68911   -1.43513
 [5,]    0.129499  0.98434  0.689434   -0.67702   -0.55439
 [6,]    0.330358 -0.30927  0.384709   -0.49214   -1.57937
 [7,]   -0.082126 -3.18522 -0.237248   -0.67663    6.02719
 [8,]   -0.266856  0.37889  0.055653   -0.53858   -1.10911
 [9,]    1.148244  0.59397  0.303286    0.13298   -1.61727
[10,]   -0.435059 -0.40641 -0.152463   -0.46876   -1.93650
[11,]   -0.028393  1.44796 -0.644080   -0.91726    2.73500
[12,]    1.210482  0.53670  0.613285    0.20556   -1.73512
[13,]    0.535924 -0.22523  0.331173   -0.36912   -1.40828
[14,]   -1.814615 -1.30610 -0.919516    1.95733    2.58156
[15,]   -0.077922  1.08514 -0.457083   -0.83939    0.20132

$xMean
(Intercept)          x1          x2 
  1.0000000  -0.0051594   0.5041407 

$call
censReg(formula = y ~ x1 + x2, data = pData, method = "BFGS")

$terms
y ~ x1 + x2
attr(,"variables")
list(y, x1, x2)
attr(,"factors")
   x1 x2
y   0  0
x1  1  0
x2  0  1
attr(,"term.labels")
[1] "x1" "x2"
attr(,"order")
[1] 1 1
attr(,"intercept")
[1] 1
attr(,"response")
[1] 1
attr(,".Environment")
<environment: R_GlobalEnv>
attr(,"predvars")
list(y, x1, x2)
attr(,"dataClasses")
        y        x1        x2 
"numeric" "numeric" "numeric" 

$nObs
         Total  Left-censored     Uncensored Right-censored 
            60             20             40              0 

$df.residual
[1] 55

$start
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
   0.470351    1.011160    1.619183   -0.496251   -0.062096 

$left
[1] 0

$right
[1] Inf

attr(,"class")
[1] "censReg" "maxLik"  "maxim"  
> 
> 
> ## BFGS method (R)
> randEffBfgsr <- censReg( y ~ x1 + x2, data = pData, method = "BFGSR" )
> print( randEffBfgsr )

Call:
censReg(formula = y ~ x1 + x2, data = pData, method = "BFGSR")

Coefficients:
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
   -0.36750     1.67993     2.24379    -0.12947    -0.01241 

> maxLik:::summary.maxLik( randEffBfgsr )
--------------------------------------------
Maximum Likelihood estimation
BFGSR maximization, 78 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -73.199 
5  free parameters
Estimates:
            Estimate Std. error t value Pr(> t)    
(Intercept)  -0.3675     0.4746   -0.77 0.43874    
x1            1.6799     0.2092    8.03 9.8e-16 ***
x2            2.2438     0.6740    3.33 0.00087 ***
logSigmaMu   -0.1295     0.2580   -0.50 0.61585    
logSigmaNu   -0.0124     0.1297   -0.10 0.92377    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
--------------------------------------------
> summary( randEffBfgsr )

Call:
censReg(formula = y ~ x1 + x2, data = pData, method = "BFGSR")

Observations:
         Total  Left-censored     Uncensored Right-censored 
            60             20             40              0 

Coefficients:
            Estimate Std. error t value  Pr(> t)    
(Intercept) -0.36750    0.47461  -0.774 0.438743    
x1           1.67993    0.20923   8.029 9.82e-16 ***
x2           2.24379    0.67397   3.329 0.000871 ***
logSigmaMu  -0.12947    0.25805  -0.502 0.615848    
logSigmaNu  -0.01241    0.12969  -0.096 0.923774    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

BFGSR maximization, 78 iterations
Return code 2: successive function values within tolerance limit
Log-likelihood: -73.199 on 5 Df

> print.default( randEffBfgsr )
$maximum
[1] -73.199

$estimate
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
  -0.367502    1.679929    2.243794   -0.129473   -0.012409 

$gradient
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
 0.00142123  0.00349926 -0.00644195  0.00037830  0.00033413 

$hessian
            (Intercept)       x1       x2 logSigmaMu logSigmaNu
(Intercept)    -13.3175  -4.0961 -7.30580   -2.11557   -1.30086
x1              -4.0961 -26.0756 -1.98981    4.48403    4.75541
x2              -7.3058  -1.9898 -6.23540   -0.62592   -0.46423
logSigmaMu      -2.1156   4.4840 -0.62592  -16.66520   -3.72118
logSigmaNu      -1.3009   4.7554 -0.46423   -3.72118  -61.06509

$code
[1] 2

$message
[1] "successive function values within tolerance limit"

$last.step
NULL

$fixed
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
      FALSE       FALSE       FALSE       FALSE       FALSE 

$iterations
[1] 78

$type
[1] "BFGSR maximization"

$gradientObs
      (Intercept)        x1        x2 logSigmaMu logSigmaNu
 [1,]   -0.852781  0.224785 -0.073030   -0.14421   -0.96349
 [2,]   -1.703424  0.047642 -1.190553    1.68202   -1.01273
 [3,]    1.750600  0.334038  1.726456    1.83516    1.80002
 [4,]    0.155523 -0.202689 -0.432967   -0.68936   -1.43158
 [5,]    0.129532  0.983868  0.688466   -0.67701   -0.55770
 [6,]    0.330210 -0.307031  0.384159   -0.49219   -1.58068
 [7,]   -0.081244 -3.185437 -0.237069   -0.67681    6.02845
 [8,]   -0.266508  0.378544  0.055603   -0.53867   -1.10903
 [9,]    1.148498  0.594261  0.303258    0.13365   -1.61634
[10,]   -0.434665 -0.405671 -0.152429   -0.46906   -1.93682
[11,]   -0.028154  1.449207 -0.644470   -0.91763    2.73877
[12,]    1.210365  0.537647  0.612312    0.20523   -1.73421
[13,]    0.535922 -0.225052  0.331001   -0.36906   -1.40853
[14,]   -1.814739 -1.306821 -0.919828    1.95803    2.57995
[15,]   -0.077714  1.086208 -0.457350   -0.83970    0.20426

$xMean
(Intercept)          x1          x2 
  1.0000000  -0.0051594   0.5041407 

$call
censReg(formula = y ~ x1 + x2, data = pData, method = "BFGSR")

$terms
y ~ x1 + x2
attr(,"variables")
list(y, x1, x2)
attr(,"factors")
   x1 x2
y   0  0
x1  1  0
x2  0  1
attr(,"term.labels")
[1] "x1" "x2"
attr(,"order")
[1] 1 1
attr(,"intercept")
[1] 1
attr(,"response")
[1] 1
attr(,".Environment")
<environment: R_GlobalEnv>
attr(,"predvars")
list(y, x1, x2)
attr(,"dataClasses")
        y        x1        x2 
"numeric" "numeric" "numeric" 

$nObs
         Total  Left-censored     Uncensored Right-censored 
            60             20             40              0 

$df.residual
[1] 55

$start
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
   0.470351    1.011160    1.619183   -0.496251   -0.062096 

$left
[1] 0

$right
[1] Inf

attr(,"class")
[1] "censReg" "maxLik"  "maxim"   "list"   
> 
> 
> ## BHHH with starting values
> randEffBhhhStart <- censReg( y ~ x1 + x2, data = pData, method = "BHHH",
+    start = c( -0.4, 1.7, 2.2, -0.1, -0.01 ) )
> print( randEffBhhhStart )

Call:
censReg(formula = y ~ x1 + x2, data = pData, start = c(-0.4, 
    1.7, 2.2, -0.1, -0.01), method = "BHHH")

Coefficients:
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
    -0.3657      1.6800      2.2406     -0.1296     -0.0124 

> summary( randEffBhhhStart )

Call:
censReg(formula = y ~ x1 + x2, data = pData, start = c(-0.4, 
    1.7, 2.2, -0.1, -0.01), method = "BHHH")

Observations:
         Total  Left-censored     Uncensored Right-censored 
            60             20             40              0 

Coefficients:
            Estimate Std. error t value  Pr(> t)    
(Intercept)  -0.3657     0.5551  -0.659  0.51003    
x1            1.6800     0.2938   5.719 1.07e-08 ***
x2            2.2406     0.7295   3.071  0.00213 ** 
logSigmaMu   -0.1295     0.2950  -0.439  0.66056    
logSigmaNu   -0.0124     0.1401  -0.088  0.92948    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

BHHH maximisation, 10 iterations
Return code 2: successive function values within tolerance limit
Log-likelihood: -73.199 on 5 Df

> nobs( randEffBhhhStart )
[1] 60
> 
> 
> ## left-censoring at 5
> pData$yAdd <- pData$y + 5
> randEffAdd <- censReg( yAdd ~ x1 + x2, data = pData, method = "BFGSR", left = 5 )
> print( randEffAdd )

Call:
censReg(formula = yAdd ~ x1 + x2, left = 5, data = pData, method = "BFGSR")

Coefficients:
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
    4.62970     1.67974     2.24826    -0.12967    -0.01247 

> maxLik:::summary.maxLik( randEffAdd )
--------------------------------------------
Maximum Likelihood estimation
BFGSR maximization, 75 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -73.199 
5  free parameters
Estimates:
            Estimate Std. error t value Pr(> t)    
(Intercept)   4.6297     0.4748    9.75 < 2e-16 ***
x1            1.6797     0.2092    8.03 9.9e-16 ***
x2            2.2483     0.6740    3.34 0.00085 ***
logSigmaMu   -0.1297     0.2581   -0.50 0.61537    
logSigmaNu   -0.0125     0.1297   -0.10 0.92343    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
--------------------------------------------
> summary( randEffAdd )

Call:
censReg(formula = yAdd ~ x1 + x2, left = 5, data = pData, method = "BFGSR")

Observations:
         Total  Left-censored     Uncensored Right-censored 
            60             20             40              0 

Coefficients:
            Estimate Std. error t value  Pr(> t)    
(Intercept)  4.62970    0.47478   9.751  < 2e-16 ***
x1           1.67974    0.20923   8.028 9.88e-16 ***
x2           2.24826    0.67403   3.336 0.000851 ***
logSigmaMu  -0.12967    0.25810  -0.502 0.615373    
logSigmaNu  -0.01247    0.12969  -0.096 0.923426    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

BFGSR maximization, 75 iterations
Return code 2: successive function values within tolerance limit
Log-likelihood: -73.199 on 5 Df

> coef( randEffAdd )
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
   4.629702    1.679738    2.248262   -0.129673   -0.012466 
> coef( randEffAdd, logSigma = FALSE )
(Intercept)          x1          x2     sigmaMu     sigmaNu 
    4.62970     1.67974     2.24826     0.87838     0.98761 
> vcov( randEffAdd )
            (Intercept)         x1         x2 logSigmaMu logSigmaNu
(Intercept)   0.2254132 -0.0206605 -0.2548721 -0.0240587 -0.0030554
x1           -0.0206605  0.0437754  0.0086703  0.0134249  0.0029544
x2           -0.2548721  0.0086703  0.4543202  0.0173446  0.0017049
logSigmaMu   -0.0240587  0.0134249  0.0173446  0.0666141 -0.0026442
logSigmaNu   -0.0030554  0.0029544  0.0017049 -0.0026442  0.0168198
> vcov( randEffAdd, logSigma = FALSE )
            (Intercept)         x1         x2    sigmaMu    sigmaNu
(Intercept)   0.2254132 -0.0206605 -0.2548721 -0.0211328 -0.0030175
x1           -0.0206605  0.0437754  0.0086703  0.0117922  0.0029178
x2           -0.2548721  0.0086703  0.4543202  0.0152352  0.0016838
sigmaMu      -0.0211328  0.0117922  0.0152352  0.0513966 -0.0022939
sigmaNu      -0.0030175  0.0029178  0.0016838 -0.0022939  0.0164057
> logLik( randEffAdd )
'log Lik.' -73.199 (df=5)
> nobs( randEffAdd )
[1] 60
> extractAIC( randEffAdd )
[1] -40.0 156.4
> print.default( randEffAdd )
$maximum
[1] -73.199

$estimate
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
   4.629702    1.679738    2.248262   -0.129673   -0.012466 

$gradient
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
  0.0073079   0.0098838  -0.0133344   0.0061864   0.0052413 

$hessian
            (Intercept)       x1       x2 logSigmaMu logSigmaNu
(Intercept)    -13.3205  -4.0976 -7.30822    -2.1336   -1.29460
x1              -4.0976 -26.0783 -1.98997     4.4821    4.74266
x2              -7.3082  -1.9900 -6.23720    -0.6321   -0.44517
logSigmaMu      -2.1336   4.4821 -0.63210   -16.6692   -3.73134
logSigmaNu      -1.2946   4.7427 -0.44517    -3.7313  -61.06329

$code
[1] 2

$message
[1] "successive function values within tolerance limit"

$last.step
NULL

$fixed
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
      FALSE       FALSE       FALSE       FALSE       FALSE 

$iterations
[1] 75

$type
[1] "BFGSR maximization"

$gradientObs
      (Intercept)        x1        x2 logSigmaMu logSigmaNu
 [1,]   -0.852345  0.223913 -0.073522   -0.14465   -0.96679
 [2,]   -1.704407  0.046484 -1.191874    1.68369   -1.01169
 [3,]    1.751747  0.335352  1.725875    1.83675    1.79582
 [4,]    0.155791 -0.203096 -0.433626   -0.68919   -1.42680
 [5,]    0.129920  0.983335  0.687393   -0.67671   -0.56210
 [6,]    0.330860 -0.303114  0.383878   -0.49176   -1.58239
 [7,]   -0.079891 -3.185973 -0.236810   -0.67690    6.03029
 [8,]   -0.265965  0.378046  0.055562   -0.53871   -1.10899
 [9,]    1.149325  0.594764  0.303379    0.13529   -1.61479
[10,]   -0.434134 -0.404613 -0.152394   -0.46967   -1.93720
[11,]   -0.027830  1.451117 -0.645093   -0.91789    2.74440
[12,]    1.210655  0.539142  0.611207    0.20595   -1.73310
[13,]    0.536502 -0.225103  0.331083   -0.36877   -1.40847
[14,]   -1.815387 -1.308229 -0.920548    1.95881    2.57843
[15,]   -0.077533  1.087860 -0.457843   -0.84005    0.20862

$xMean
(Intercept)          x1          x2 
  1.0000000  -0.0051594   0.5041407 

$call
censReg(formula = yAdd ~ x1 + x2, left = 5, data = pData, method = "BFGSR")

$terms
yAdd ~ x1 + x2
attr(,"variables")
list(yAdd, x1, x2)
attr(,"factors")
     x1 x2
yAdd  0  0
x1    1  0
x2    0  1
attr(,"term.labels")
[1] "x1" "x2"
attr(,"order")
[1] 1 1
attr(,"intercept")
[1] 1
attr(,"response")
[1] 1
attr(,".Environment")
<environment: R_GlobalEnv>
attr(,"predvars")
list(yAdd, x1, x2)
attr(,"dataClasses")
     yAdd        x1        x2 
"numeric" "numeric" "numeric" 

$nObs
         Total  Left-censored     Uncensored Right-censored 
            60             20             40              0 

$df.residual
[1] 55

$start
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
   5.470351    1.011160    1.619183   -0.496251   -0.062096 

$left
[1] 5

$right
[1] Inf

attr(,"class")
[1] "censReg" "maxLik"  "maxim"   "list"   
> 
> 
> ## right-censoring
> pData$yNeg <- - pData$y
> randEffNeg <- censReg( yNeg ~ x1 + x2, data = pData, method = "BFGSR",
+    left = -Inf, right = 0 )
> print( randEffNeg )

Call:
censReg(formula = yNeg ~ x1 + x2, left = -Inf, right = 0, data = pData, 
    method = "BFGSR")

Coefficients:
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
    0.36750    -1.67993    -2.24379    -0.12947    -0.01241 

> maxLik:::summary.maxLik( randEffNeg )
--------------------------------------------
Maximum Likelihood estimation
BFGSR maximization, 78 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -73.199 
5  free parameters
Estimates:
            Estimate Std. error t value Pr(> t)    
(Intercept)   0.3675     0.4746    0.77 0.43874    
x1           -1.6799     0.2092   -8.03 9.8e-16 ***
x2           -2.2438     0.6740   -3.33 0.00087 ***
logSigmaMu   -0.1295     0.2580   -0.50 0.61585    
logSigmaNu   -0.0124     0.1297   -0.10 0.92377    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
--------------------------------------------
> summary( randEffNeg )

Call:
censReg(formula = yNeg ~ x1 + x2, left = -Inf, right = 0, data = pData, 
    method = "BFGSR")

Observations:
         Total  Left-censored     Uncensored Right-censored 
            60              0             40             20 

Coefficients:
            Estimate Std. error t value  Pr(> t)    
(Intercept)  0.36750    0.47461   0.774 0.438743    
x1          -1.67993    0.20923  -8.029 9.82e-16 ***
x2          -2.24379    0.67397  -3.329 0.000871 ***
logSigmaMu  -0.12947    0.25805  -0.502 0.615848    
logSigmaNu  -0.01241    0.12969  -0.096 0.923774    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

BFGSR maximization, 78 iterations
Return code 2: successive function values within tolerance limit
Log-likelihood: -73.199 on 5 Df

> coef( randEffNeg )
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
   0.367502   -1.679929   -2.243794   -0.129473   -0.012409 
> coef( randEffNeg, logSigma = FALSE )
(Intercept)          x1          x2     sigmaMu     sigmaNu 
    0.36750    -1.67993    -2.24379     0.87856     0.98767 
> vcov( randEffNeg )
            (Intercept)         x1         x2 logSigmaMu logSigmaNu
(Intercept)   0.2252576 -0.0206060 -0.2547275  0.0239005  0.0030104
x1           -0.0206060  0.0437769  0.0086067 -0.0134093 -0.0029655
x2           -0.2547275  0.0086067  0.4542345 -0.0172363 -0.0015931
logSigmaMu    0.0239005 -0.0134093 -0.0172363  0.0665884 -0.0026354
logSigmaNu    0.0030104 -0.0029655 -0.0015931 -0.0026354  0.0168195
> vcov( randEffNeg, logSigma = FALSE )
            (Intercept)         x1         x2    sigmaMu    sigmaNu
(Intercept)   0.2252576 -0.0206060 -0.2547275  0.0209980  0.0029732
x1           -0.0206060  0.0437769  0.0086067 -0.0117808 -0.0029289
x2           -0.2547275  0.0086067  0.4542345 -0.0151431 -0.0015735
sigmaMu       0.0209980 -0.0117808 -0.0151431  0.0513972 -0.0022868
sigmaNu       0.0029732 -0.0029289 -0.0015735 -0.0022868  0.0164072
> logLik( randEffNeg )
'log Lik.' -73.199 (df=5)
> extractAIC( randEffNeg )
[1] -40.0 156.4
> print.default( randEffNeg )
$maximum
[1] -73.199

$estimate
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
   0.367502   -1.679929   -2.243794   -0.129473   -0.012409 

$gradient
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
-0.00142123 -0.00349926  0.00644195  0.00037830  0.00033413 

$hessian
            (Intercept)       x1       x2 logSigmaMu logSigmaNu
(Intercept)    -13.3175  -4.0961 -7.30580    2.11557    1.30086
x1              -4.0961 -26.0756 -1.98981   -4.48403   -4.75541
x2              -7.3058  -1.9898 -6.23540    0.62592    0.46423
logSigmaMu       2.1156  -4.4840  0.62592  -16.66520   -3.72118
logSigmaNu       1.3009  -4.7554  0.46423   -3.72118  -61.06509

$code
[1] 2

$message
[1] "successive function values within tolerance limit"

$last.step
NULL

$fixed
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
      FALSE       FALSE       FALSE       FALSE       FALSE 

$iterations
[1] 78

$type
[1] "BFGSR maximization"

$gradientObs
      (Intercept)        x1        x2 logSigmaMu logSigmaNu
 [1,]    0.852781 -0.224785  0.073030   -0.14421   -0.96349
 [2,]    1.703424 -0.047642  1.190553    1.68202   -1.01273
 [3,]   -1.750600 -0.334038 -1.726456    1.83516    1.80002
 [4,]   -0.155523  0.202689  0.432967   -0.68936   -1.43158
 [5,]   -0.129532 -0.983868 -0.688466   -0.67701   -0.55770
 [6,]   -0.330210  0.307031 -0.384159   -0.49219   -1.58068
 [7,]    0.081244  3.185437  0.237069   -0.67681    6.02845
 [8,]    0.266508 -0.378544 -0.055603   -0.53867   -1.10903
 [9,]   -1.148498 -0.594261 -0.303258    0.13365   -1.61634
[10,]    0.434665  0.405671  0.152429   -0.46906   -1.93682
[11,]    0.028154 -1.449207  0.644470   -0.91763    2.73877
[12,]   -1.210365 -0.537647 -0.612312    0.20523   -1.73421
[13,]   -0.535922  0.225052 -0.331001   -0.36906   -1.40853
[14,]    1.814739  1.306821  0.919828    1.95803    2.57995
[15,]    0.077714 -1.086208  0.457350   -0.83970    0.20426

$xMean
(Intercept)          x1          x2 
  1.0000000  -0.0051594   0.5041407 

$call
censReg(formula = yNeg ~ x1 + x2, left = -Inf, right = 0, data = pData, 
    method = "BFGSR")

$terms
yNeg ~ x1 + x2
attr(,"variables")
list(yNeg, x1, x2)
attr(,"factors")
     x1 x2
yNeg  0  0
x1    1  0
x2    0  1
attr(,"term.labels")
[1] "x1" "x2"
attr(,"order")
[1] 1 1
attr(,"intercept")
[1] 1
attr(,"response")
[1] 1
attr(,".Environment")
<environment: R_GlobalEnv>
attr(,"predvars")
list(yNeg, x1, x2)
attr(,"dataClasses")
     yNeg        x1        x2 
"numeric" "numeric" "numeric" 

$nObs
         Total  Left-censored     Uncensored Right-censored 
            60              0             40             20 

$df.residual
[1] 55

$start
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
  -0.470351   -1.011160   -1.619183   -0.496251   -0.062096 

$left
[1] -Inf

$right
[1] 0

attr(,"class")
[1] "censReg" "maxLik"  "maxim"   "list"   
> 
> 
> ## right-censoring at -5
> pData$yAddNeg <- - pData$yAdd
> randEffAddNeg <- censReg( yAddNeg ~ x1 + x2, data = pData, method = "BFGSR",
+    left = -Inf, right = -5 )
> print( randEffAddNeg )

Call:
censReg(formula = yAddNeg ~ x1 + x2, left = -Inf, right = -5, 
    data = pData, method = "BFGSR")

Coefficients:
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
   -4.63391    -1.68002    -2.24127    -0.12953    -0.01241 

> maxLik:::summary.maxLik( randEffAddNeg )
--------------------------------------------
Maximum Likelihood estimation
BFGSR maximization, 73 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -73.199 
5  free parameters
Estimates:
            Estimate Std. error t value Pr(> t)    
(Intercept)  -4.6339     0.4745   -9.77 < 2e-16 ***
x1           -1.6800     0.2092   -8.03 9.8e-16 ***
x2           -2.2413     0.6739   -3.33 0.00088 ***
logSigmaMu   -0.1295     0.2581   -0.50 0.61573    
logSigmaNu   -0.0124     0.1297   -0.10 0.92376    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
--------------------------------------------
> summary( randEffAddNeg )

Call:
censReg(formula = yAddNeg ~ x1 + x2, left = -Inf, right = -5, 
    data = pData, method = "BFGSR")

Observations:
         Total  Left-censored     Uncensored Right-censored 
            60              0             40             20 

Coefficients:
            Estimate Std. error t value  Pr(> t)    
(Intercept) -4.63391    0.47450  -9.766  < 2e-16 ***
x1          -1.68002    0.20923  -8.030 9.77e-16 ***
x2          -2.24127    0.67391  -3.326 0.000882 ***
logSigmaMu  -0.12953    0.25807  -0.502 0.615730    
logSigmaNu  -0.01241    0.12969  -0.096 0.923758    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

BFGSR maximization, 73 iterations
Return code 2: successive function values within tolerance limit
Log-likelihood: -73.199 on 5 Df

> coef( randEffAddNeg )
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
  -4.633912   -1.680022   -2.241274   -0.129526   -0.012412 
> coef( randEffAddNeg, logSigma = FALSE )
(Intercept)          x1          x2     sigmaMu     sigmaNu 
   -4.63391    -1.68002    -2.24127     0.87851     0.98767 
> vcov( randEffAddNeg )
            (Intercept)         x1         x2 logSigmaMu logSigmaNu
(Intercept)   0.2251498 -0.0205806 -0.2546356  0.0238478  0.0029816
x1           -0.0205806  0.0437756  0.0085735 -0.0134059 -0.0029698
x2           -0.2546356  0.0085735  0.4541520 -0.0171948 -0.0015242
logSigmaMu    0.0238478 -0.0134059 -0.0171948  0.0665978 -0.0026382
logSigmaNu    0.0029816 -0.0029698 -0.0015242 -0.0026382  0.0168196
> vcov( randEffAddNeg, logSigma = FALSE )
            (Intercept)         x1         x2    sigmaMu    sigmaNu
(Intercept)   0.2251498 -0.0205806 -0.2546356  0.0209505  0.0029449
x1           -0.0205806  0.0437756  0.0085735 -0.0117773 -0.0029332
x2           -0.2546356  0.0085735  0.4541520 -0.0151059 -0.0015054
sigmaMu       0.0209505 -0.0117773 -0.0151059  0.0513990 -0.0022891
sigmaNu       0.0029449 -0.0029332 -0.0015054 -0.0022891  0.0164072
> logLik( randEffAddNeg )
'log Lik.' -73.199 (df=5)
> extractAIC( randEffAddNeg )
[1] -40.0 156.4
> print.default( randEffAddNeg )
$maximum
[1] -73.199

$estimate
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
  -4.633912   -1.680022   -2.241274   -0.129526   -0.012412 

$gradient
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
-7.4254e-04 -5.2373e-05  1.2054e-03  2.6670e-04  4.7633e-04 

$hessian
            (Intercept)       x1       x2 logSigmaMu logSigmaNu
(Intercept)    -13.3210  -4.0966 -7.30724    2.11057    1.30700
x1              -4.0966 -26.0764 -1.99039   -4.48469   -4.76185
x2              -7.3072  -1.9904 -6.23613    0.62475    0.47681
logSigmaMu       2.1106  -4.4847  0.62475  -16.66020   -3.72258
logSigmaNu       1.3070  -4.7618  0.47681   -3.72258  -61.06777

$code
[1] 2

$message
[1] "successive function values within tolerance limit"

$last.step
NULL

$fixed
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
      FALSE       FALSE       FALSE       FALSE       FALSE 

$iterations
[1] 73

$type
[1] "BFGSR maximization"

$gradientObs
      (Intercept)        x1       x2 logSigmaMu logSigmaNu
 [1,]    0.853006 -0.225384  0.07271   -0.14406   -0.96159
 [2,]    1.703134 -0.048197  1.19001    1.68099   -1.01321
 [3,]   -1.750819 -0.333659 -1.72734    1.83542    1.80352
 [4,]   -0.155759  0.202488  0.43239   -0.68910   -1.43436
 [5,]   -0.129543 -0.984197 -0.68924   -0.67700   -0.55513
 [6,]   -0.330349  0.308899 -0.38463   -0.49212   -1.57963
 [7,]    0.081895  3.185350  0.23721   -0.67668    6.02778
 [8,]    0.266731 -0.378781 -0.05566   -0.53862   -1.10906
 [9,]   -1.148321 -0.593950 -0.30329    0.13319   -1.61707
[10,]    0.434934  0.406266  0.15243   -0.46885   -1.93653
[11,]    0.028329 -1.448222  0.64415   -0.91737    2.73581
[12,]   -1.210446 -0.536887 -0.61307    0.20552   -1.73494
[13,]   -0.536010  0.225250 -0.33118   -0.36904   -1.40829
[14,]    1.814632  1.306329  0.91958    1.95749    2.58119
[15,]    0.077845 -1.085356  0.45712   -0.83951    0.20196

$xMean
(Intercept)          x1          x2 
  1.0000000  -0.0051594   0.5041407 

$call
censReg(formula = yAddNeg ~ x1 + x2, left = -Inf, right = -5, 
    data = pData, method = "BFGSR")

$terms
yAddNeg ~ x1 + x2
attr(,"variables")
list(yAddNeg, x1, x2)
attr(,"factors")
        x1 x2
yAddNeg  0  0
x1       1  0
x2       0  1
attr(,"term.labels")
[1] "x1" "x2"
attr(,"order")
[1] 1 1
attr(,"intercept")
[1] 1
attr(,"response")
[1] 1
attr(,".Environment")
<environment: R_GlobalEnv>
attr(,"predvars")
list(yAddNeg, x1, x2)
attr(,"dataClasses")
  yAddNeg        x1        x2 
"numeric" "numeric" "numeric" 

$nObs
         Total  Left-censored     Uncensored Right-censored 
            60              0             40             20 

$df.residual
[1] 55

$start
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
  -5.470351   -1.011160   -1.619183   -0.496251   -0.062096 

$left
[1] -Inf

$right
[1] -5

attr(,"class")
[1] "censReg" "maxLik"  "maxim"   "list"   
> 
> 
> ## both right and left censoring
> pData$yBoth <- ifelse( pData$y < 3, pData$y, 3 )
> randEffBoth <- censReg( yBoth ~ x1 + x2, data = pData, method = "BFGSR",
+    left = 0, right = 3 )
> print( randEffBoth )

Call:
censReg(formula = yBoth ~ x1 + x2, left = 0, right = 3, data = pData, 
    method = "BFGSR")

Coefficients:
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
  -0.233782    1.893280    1.969602    0.001543    0.052867 

> maxLik:::summary.maxLik( randEffBoth )
--------------------------------------------
Maximum Likelihood estimation
BFGSR maximization, 96 iterations
Return code 3: Last step could not find a value above the current.
Boundary of parameter space?  
Consider switching to a more robust optimisation method temporarily.
Log-Likelihood: -64.313 
5  free parameters
Estimates:
            Estimate Std. error t value Pr(> t)    
(Intercept) -0.23378    0.54833   -0.43   0.670    
x1           1.89328    0.30112    6.29 3.2e-10 ***
x2           1.96960    0.81883    2.41   0.016 *  
logSigmaMu   0.00154    0.27788    0.01   0.996    
logSigmaNu   0.05287    0.16302    0.32   0.746    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
--------------------------------------------
> summary( randEffBoth )

Call:
censReg(formula = yBoth ~ x1 + x2, left = 0, right = 3, data = pData, 
    method = "BFGSR")

Observations:
         Total  Left-censored     Uncensored Right-censored 
            60             20             28             12 

Coefficients:
             Estimate Std. error t value  Pr(> t)    
(Intercept) -0.233782   0.548329  -0.426   0.6698    
x1           1.893280   0.301117   6.288 3.23e-10 ***
x2           1.969602   0.818834   2.405   0.0162 *  
logSigmaMu   0.001543   0.277876   0.006   0.9956    
logSigmaNu   0.052867   0.163016   0.324   0.7457    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

BFGSR maximization, 96 iterations
Return code 3: Last step could not find a value above the current.
Boundary of parameter space?  
Consider switching to a more robust optimisation method temporarily.
Log-likelihood: -64.313 on 5 Df

> print( summary( randEffBoth ), logSigma = FALSE )

Call:
censReg(formula = yBoth ~ x1 + x2, left = 0, right = 3, data = pData, 
    method = "BFGSR")

Observations:
         Total  Left-censored     Uncensored Right-censored 
            60             20             28             12 

Coefficients:
            Estimate Std. error t value  Pr(> t)    
(Intercept)  -0.2338     0.5483  -0.426  0.66985    
x1            1.8933     0.3011   6.288 3.23e-10 ***
x2            1.9696     0.8188   2.405  0.01616 *  
sigmaMu       1.0015     0.2783   3.599  0.00032 ***
sigmaNu       1.0543     0.1719   6.134 8.55e-10 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

BFGSR maximization, 96 iterations
Return code 3: Last step could not find a value above the current.
Boundary of parameter space?  
Consider switching to a more robust optimisation method temporarily.
Log-likelihood: -64.313 on 5 Df

> coef( randEffBoth )
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
 -0.2337822   1.8932801   1.9696025   0.0015433   0.0528675 
> coef( randEffBoth, logSigma = FALSE )
(Intercept)          x1          x2     sigmaMu     sigmaNu 
   -0.23378     1.89328     1.96960     1.00154     1.05429 
> vcov( randEffBoth )
            (Intercept)        x1        x2 logSigmaMu logSigmaNu
(Intercept)    0.300665 -0.031409 -0.364069 -0.0159745 -0.0163840
x1            -0.031409  0.090672  0.031823  0.0351950  0.0159307
x2            -0.364069  0.031823  0.670489  0.0186522  0.0245039
logSigmaMu    -0.015975  0.035195  0.018652  0.0772150  0.0043375
logSigmaNu    -0.016384  0.015931  0.024504  0.0043375  0.0265741
> vcov( randEffBoth, logSigma = FALSE )
            (Intercept)        x1        x2   sigmaMu   sigmaNu
(Intercept)    0.300665 -0.031409 -0.364069 -0.015999 -0.017274
x1            -0.031409  0.090672  0.031823  0.035249  0.016796
x2            -0.364069  0.031823  0.670489  0.018681  0.025834
sigmaMu       -0.015999  0.035249  0.018681  0.077454  0.004580
sigmaNu       -0.017274  0.016796  0.025834  0.004580  0.029538
> coef( summary( randEffBoth ) )
              Estimate Std. error    t value    Pr(> t)
(Intercept) -0.2337822    0.54833 -0.4263539 6.6985e-01
x1           1.8932801    0.30112  6.2875177 3.2258e-10
x2           1.9696025    0.81883  2.4053742 1.6156e-02
logSigmaMu   0.0015433    0.27788  0.0055538 9.9557e-01
logSigmaNu   0.0528675    0.16302  0.3243089 7.4570e-01
> coef( summary( randEffBoth ), logSigma = FALSE )
            Estimate Std. error  t value    Pr(> t)
(Intercept) -0.23378    0.54833 -0.42635 6.6985e-01
x1           1.89328    0.30112  6.28752 3.2258e-10
x2           1.96960    0.81883  2.40537 1.6156e-02
sigmaMu      1.00154    0.27831  3.59873 3.1978e-04
sigmaNu      1.05429    0.17187  6.13437 8.5495e-10
> logLik( randEffBoth )
'log Lik.' -64.313 (df=5)
> nobs( randEffBoth )
[1] 60
> extractAIC( randEffBoth )
[1] -40.00 138.63
> print.default( randEffBoth )
$maximum
[1] -64.313

$estimate
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
 -0.2337822   1.8932801   1.9696025   0.0015433   0.0528675 

$gradient
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
 -0.0028949  -0.0023697   0.0026100   0.0030165  -0.0025434 

$hessian
            (Intercept)       x1       x2 logSigmaMu logSigmaNu
(Intercept)   -9.929212  -1.4916 -5.30683  -0.074303   -0.32206
x1            -1.491578 -15.1381 -0.54540   6.294522    7.63088
x2            -5.306826  -0.5454 -4.39075   0.150718    1.07917
logSigmaMu    -0.074303   6.2945  0.15072 -15.794173   -1.38029
logSigmaNu    -0.322059   7.6309  1.07917  -1.380290  -43.17348

$code
[1] 3

$message
[1] "Last step could not find a value above the current.\nBoundary of parameter space?  \nConsider switching to a more robust optimisation method temporarily."

$last.step
$last.step$theta0
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
 -0.2338051   1.8933106   1.9696410   0.0015514   0.0526757 

$last.step$f0
[1] -64.313
attr(,"gradient")
           [,1]      [,2]      [,3]      [,4]     [,5]
 [1,] -0.854175 -0.106093 -0.181468 -0.023549 -0.83697
 [2,] -1.416801 -0.027024 -0.971968  1.456755 -1.16460
 [3,]  1.297460  1.020885  0.925447  1.092090  0.15407
 [4,]  0.070756 -0.252077 -0.398410 -0.701597 -1.82610
 [5,]  0.089224  0.807459  0.647698 -0.690663 -0.28477
 [6,]  0.559238  0.494686  0.428980 -0.291444 -0.36035
 [7,] -0.120348 -3.062192 -0.236741 -0.706385  6.34551
 [8,] -0.209615  0.335508  0.083265 -0.590648 -1.02953
 [9,]  1.034365  0.660218  0.288327  0.197179 -1.29701
[10,] -0.428290 -0.585647 -0.117333 -0.395715 -1.80064
[11,] -0.040642  1.095092 -0.508215 -0.866882  2.00180
[12,]  1.140340  0.505339  0.832219  0.585284 -0.74502
[13,]  0.534863 -0.281815  0.347915 -0.286503 -1.43365
[14,] -1.638192 -1.347620 -0.838036  2.120125  2.76469
[15,] -0.021040  0.739050 -0.299339 -0.894696 -0.48140

$last.step$climb
[1]  -394657   523582   662476   140569 -3294770


$fixed
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
      FALSE       FALSE       FALSE       FALSE       FALSE 

$iterations
[1] 96

$type
[1] "BFGSR maximization"

$gradientObs
      (Intercept)        x1        x2 logSigmaMu logSigmaNu
 [1,]   -0.853993 -0.106021 -0.181408  -0.023647   -0.83714
 [2,]   -1.416808 -0.027009 -0.971939   1.456647   -1.16454
 [3,]    1.297380  1.020959  0.925393   1.091903    0.15398
 [4,]    0.071006 -0.251979 -0.398077  -0.701548   -1.82666
 [5,]    0.089227  0.807457  0.647567  -0.690559   -0.28504
 [6,]    0.559254  0.494805  0.428923  -0.291477   -0.36086
 [7,]   -0.120395 -3.060891 -0.236663  -0.706229    6.34207
 [8,]   -0.209695  0.335552  0.083221  -0.590509   -1.02971
 [9,]    1.034289  0.660161  0.288315   0.197210   -1.29713
[10,]   -0.428286 -0.585385 -0.117364  -0.395826   -1.80092
[11,]   -0.040816  1.094720 -0.508164  -0.866678    2.00068
[12,]    1.140456  0.505283  0.832269   0.585502   -0.74528
[13,]    0.534702 -0.281626  0.347809  -0.286742   -1.43397
[14,]   -1.637957 -1.347176 -0.837916   2.119401    2.76413
[15,]   -0.021259  0.738779 -0.299356  -0.894432   -0.48216

$xMean
(Intercept)          x1          x2 
  1.0000000  -0.0051594   0.5041407 

$call
censReg(formula = yBoth ~ x1 + x2, left = 0, right = 3, data = pData, 
    method = "BFGSR")

$terms
yBoth ~ x1 + x2
attr(,"variables")
list(yBoth, x1, x2)
attr(,"factors")
      x1 x2
yBoth  0  0
x1     1  0
x2     0  1
attr(,"term.labels")
[1] "x1" "x2"
attr(,"order")
[1] 1 1
attr(,"intercept")
[1] 1
attr(,"response")
[1] 1
attr(,".Environment")
<environment: R_GlobalEnv>
attr(,"predvars")
list(yBoth, x1, x2)
attr(,"dataClasses")
    yBoth        x1        x2 
"numeric" "numeric" "numeric" 

$nObs
         Total  Left-censored     Uncensored Right-censored 
            60             20             28             12 

$df.residual
[1] 55

$start
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
    0.60564     0.81130     1.00240    -0.75456    -0.27481 

$left
[1] 0

$right
[1] 3

attr(,"class")
[1] "censReg" "maxLik"  "maxim"   "list"   
> 
> 
> ## re-order observations/individuals
> set.seed( 234 )
> perm <- sample( nId )
> nData2 <- nData
> nData2$id <- NA
> for( i in 1:nId ) {
+    nData2$id[ nData$id == paste( "F", i, sep = "_" ) ] <-
+       paste( "G", perm[ i ], sep = "_" )
+ }
> pData2 <- pdata.frame( nData2, c( "id", "time" ) )
> randEffBfgsr2 <- censReg( y ~ x1 + x2, data = pData2, method = "BFGSR" )
> all.equal( randEffBfgsr2[ -c(11,13) ], randEffBfgsr[ -c(11,13) ] )
[1] "Component 1: Mean relative difference: 1.5859e-07"
[2] "Component 2: Mean relative difference: 0.00099426"
[3] "Component 3: Mean relative difference: 5.2676"    
[4] "Component 4: Mean relative difference: 0.00045365"
[5] "Component 9: Mean relative difference: 0.23529"   
> all.equal( sort( randEffBfgsr2[[ 11 ]] ), sort( randEffBfgsr[[ 11 ]] ) )
[1] "Mean relative difference: 0.00066929"
> 
> # check if the order of observations/individuals influences the likelihood values
> d1c1 <- censReg( y ~ x1 + x2, data = pData, method = "BFGSR", start = coef(randEffBfgsr),
+    iterlim = 0 )
> all.equal( d1c1[-c(5,6,9,13,17)], randEffBfgsr[-c(5,6,9,13,17)] )
[1] TRUE
> d1c1$maximum -  randEffBfgsr$maximum
[1] 0
> 
> d2c2 <- censReg( y ~ x1 + x2, data = pData2, method = "BFGSR", start = coef(randEffBfgsr2),
+    iterlim = 0 )
> all.equal( d2c2[-c(5,6,9,13,17)], randEffBfgsr2[-c(5,6,9,13,17)] )
[1] TRUE
> d2c2$maximum -  randEffBfgsr2$maximum
[1] 0
> 
> d1c2 <- censReg( y ~ x1 + x2, data = pData, method = "BFGSR", 
+    start = coef(randEffBfgsr2), iterlim = 0 )
> d2c2$maximum - d1c2$maximum
[1] 0
> d2c2$gradient - d1c2$gradient
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
          0           0           0           0           0 
> 
> d2c1 <- censReg( y ~ x1 + x2, data = pData2, method = "BFGSR", 
+    start = coef(randEffBfgsr), iterlim = 0 )
> d1c1$maximum - d2c1$maximum
[1] 0
> d1c1$gradient - d2c1$gradient
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
          0           0           0           0           0 
> 
> d2c2$maximum - d2c1$maximum
[1] 1.1609e-05
> d1c1$maximum - d1c2$maximum
[1] -1.1609e-05
> 
> d1cS <- censReg( y ~ x1 + x2, data = pData, method = "BFGSR", 
+    start = randEffBfgsr$start, iterlim = 0 )
> d2cS <- censReg( y ~ x1 + x2, data = pData2, method = "BFGSR", 
+    start = randEffBfgsr$start, iterlim = 0 )
> d1cS$maximum - d2cS$maximum
[1] 0
> d1cS$gradient - d2cS$gradient
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
          0           0           0           0           0 
> 
> 
> ## unbalanced panel data
> nDataUnb <- nData[ -c( 2, 5, 6, 8 ), ]
> pDataUnb <- pdata.frame( nDataUnb, c( "id", "time" ) )
> randEffBfgsrUnb <- censReg( y ~ x1 + x2, data = pDataUnb, method = "BFGSR" )
> print( randEffBfgsrUnb )

Call:
censReg(formula = y ~ x1 + x2, data = pDataUnb, method = "BFGSR")

Coefficients:
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
  -0.223438    1.640494    2.109440   -0.167351   -0.001139 

> maxLik:::summary.maxLik( randEffBfgsrUnb )
--------------------------------------------
Maximum Likelihood estimation
BFGSR maximization, 91 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -71.193 
5  free parameters
Estimates:
            Estimate Std. error t value Pr(> t)    
(Intercept) -0.22344    0.47257   -0.47  0.6363    
x1           1.64049    0.21105    7.77 7.7e-15 ***
x2           2.10944    0.68488    3.08  0.0021 ** 
logSigmaMu  -0.16735    0.27149   -0.62  0.5376    
logSigmaNu  -0.00114    0.13227   -0.01  0.9931    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
--------------------------------------------
> summary( randEffBfgsrUnb )

Call:
censReg(formula = y ~ x1 + x2, data = pDataUnb, method = "BFGSR")

Observations:
         Total  Left-censored     Uncensored Right-censored 
            56             17             39              0 

Coefficients:
             Estimate Std. error t value  Pr(> t)    
(Intercept) -0.223438   0.472575  -0.473  0.63635    
x1           1.640494   0.211052   7.773 7.67e-15 ***
x2           2.109440   0.684875   3.080  0.00207 ** 
logSigmaMu  -0.167351   0.271491  -0.616  0.53762    
logSigmaNu  -0.001139   0.132273  -0.009  0.99313    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

BFGSR maximization, 91 iterations
Return code 2: successive function values within tolerance limit
Log-likelihood: -71.193 on 5 Df

> logLik( randEffBfgsrUnb )
'log Lik.' -71.193 (df=5)
> extractAIC( randEffBfgsrUnb )
[1] -36.00 152.39
> print.default( randEffBfgsrUnb )
$maximum
[1] -71.193

$estimate
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
 -0.2234379   1.6404941   2.1094395  -0.1673511  -0.0011386 

$gradient
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
-0.00236460  0.00021347  0.00435254 -0.00122748 -0.00033109 

$hessian
            (Intercept)       x1       x2 logSigmaMu logSigmaNu
(Intercept)    -13.7884  -4.3459 -7.52732   -1.11085    -1.9419
x1              -4.3459 -25.8115 -2.05717    4.65031     4.0525
x2              -7.5273  -2.0572 -6.26548   -0.14354    -1.0571
logSigmaMu      -1.1109   4.6503 -0.14354  -14.93040    -3.7725
logSigmaNu      -1.9419   4.0525 -1.05707   -3.77250   -58.8326

$code
[1] 2

$message
[1] "successive function values within tolerance limit"

$last.step
NULL

$fixed
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
      FALSE       FALSE       FALSE       FALSE       FALSE 

$iterations
[1] 91

$type
[1] "BFGSR maximization"

$gradientObs
      (Intercept)         x1        x2 logSigmaMu logSigmaNu
 [1,]   -0.508515  0.0885491  0.103324  -0.394241  -0.532153
 [2,]   -1.817053  0.0666301 -1.247445   1.798802  -0.961309
 [3,]    1.784382  0.4846226  1.769219   1.733241   1.893871
 [4,]    0.151787 -0.1628638 -0.396333  -0.736972  -1.584420
 [5,]    0.081745  1.0386199  0.697662  -0.678102  -0.447899
 [6,]    0.332387 -0.2317414  0.373603  -0.539709  -1.574060
 [7,]   -0.180057 -3.0299399 -0.248457  -0.622479   5.482390
 [8,]    0.018786 -0.0040948  0.010744  -0.417751  -0.581644
 [9,]    1.116136  0.6664585  0.295761   0.063791  -1.685063
[10,]   -0.537614 -0.4200665 -0.204198  -0.406602  -1.974363
[11,]   -0.082801  1.3792369 -0.647723  -0.823563   2.497355
[12,]    1.258856  0.5321222  0.669155   0.230588  -1.793473
[13,]    0.446787 -0.1634132  0.286374  -0.468100  -1.450498
[14,]   -1.892749 -1.2872627 -0.962224   1.983782   2.681070
[15,]   -0.174441  1.0433564 -0.495111  -0.723913   0.029865

$xMean
(Intercept)          x1          x2 
   1.000000    0.031414    0.518445 

$call
censReg(formula = y ~ x1 + x2, data = pDataUnb, method = "BFGSR")

$terms
y ~ x1 + x2
attr(,"variables")
list(y, x1, x2)
attr(,"factors")
   x1 x2
y   0  0
x1  1  0
x2  0  1
attr(,"term.labels")
[1] "x1" "x2"
attr(,"order")
[1] 1 1
attr(,"intercept")
[1] 1
attr(,"response")
[1] 1
attr(,".Environment")
<environment: R_GlobalEnv>
attr(,"predvars")
list(y, x1, x2)
attr(,"dataClasses")
        y        x1        x2 
"numeric" "numeric" "numeric" 

$nObs
         Total  Left-censored     Uncensored Right-censored 
            56             17             39              0 

$df.residual
[1] 51

$start
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
   0.482997    1.030026    1.634705   -0.477721   -0.049889 

$left
[1] 0

$right
[1] Inf

attr(,"class")
[1] "censReg" "maxLik"  "maxim"   "list"   
> 
> 
> ## NAs in data
> pDataNa <- pData
> obsNa <- which( ! rownames( pData ) %in% rownames( pDataUnb ) )
> pDataNa$y[ obsNa[ 1:2 ] ] <- NA
> pDataNa$x1[ obsNa[ 3 ] ] <- NA
> pDataNa$x2[ obsNa[ c( 1, 2, 4 ) ] ] <- NA
> randEffBfgsrNa <- censReg( y ~ x1 + x2, data = pDataNa, method = "BFGSR" )
> all.equal( randEffBfgsrNa[ -13 ], randEffBfgsrUnb[ -13 ] )
[1] TRUE
> 
> 
> # returning log-likelihood contributions only (no estimations)
> logLikRandEff <- censReg( y ~ x1 + x2, data = pData, start = coef( randEff ),
+    logLikOnly = TRUE )
> print( logLikRandEff )
 [1] -4.2520 -3.7391 -7.0464 -5.3004 -3.3543 -5.3078 -6.2916 -1.6557 -4.3939
[10] -3.7659 -6.8219 -5.6462 -4.3333 -5.7264 -5.5639
attr(,"gradient")
           [,1]      [,2]      [,3]     [,4]     [,5]
 [1,] -0.853084  0.225585 -0.072610 -0.14400 -0.96094
 [2,] -1.703094  0.048394 -1.189876  1.68078 -1.01331
 [3,]  1.750842  0.333675  1.727558  1.83538  1.80437
 [4,]  0.155777 -0.202400 -0.432247 -0.68911 -1.43514
 [5,]  0.129500  0.984336  0.689436 -0.67702 -0.55438
 [6,]  0.330359 -0.309284  0.384711 -0.49214 -1.57937
 [7,] -0.082125 -3.185219 -0.237247 -0.67663  6.02719
 [8,] -0.266853  0.378885  0.055655 -0.53858 -1.10911
 [9,]  1.148242  0.593964  0.303286  0.13298 -1.61727
[10,] -0.435054 -0.406406 -0.152460 -0.46876 -1.93650
[11,] -0.028392  1.447957 -0.644077 -0.91727  2.73499
[12,]  1.210479  0.536698  0.613285  0.20555 -1.73512
[13,]  0.535927 -0.225230  0.331175 -0.36912 -1.40828
[14,] -1.814607 -1.306090 -0.919510  1.95732  2.58156
[15,] -0.077919  1.085134 -0.457079 -0.83939  0.20132
> all.equal( sum( logLikRandEff ), c( logLik( randEff ) ) )
[1] TRUE
> logLikStart <- censReg( y ~ x1 + x2, data = pData, 
+    start = c( -0.4, 1.7, 2.2, -0.1, -0.01 ), logLikOnly = TRUE )
> print( logLikStart )
 [1] -4.2237 -3.5906 -7.1103 -5.3162 -3.3894 -5.3604 -6.3494 -1.6617 -4.4338
[10] -3.7743 -6.7881 -5.6994 -4.3852 -5.5931 -5.5483
attr(,"gradient")
           [,1]      [,2]      [,3]     [,4]     [,5]
 [1,] -0.787804  0.278995 -0.039489 -0.17812 -1.02811
 [2,] -1.582326  0.092312 -1.096194  1.48502 -1.05627
 [3,]  1.724367  0.263921  1.722283  1.90892  1.84394
 [4,]  0.184806 -0.209936 -0.406817 -0.61391 -1.53307
 [5,]  0.161565  0.970060  0.713888 -0.66424 -0.51155
 [6,]  0.361760 -0.387858  0.420460 -0.42772 -1.58295
 [7,] -0.049010 -3.196677 -0.230652 -0.69966  6.13444
 [8,] -0.218570  0.356783  0.078201 -0.56848 -1.06583
 [9,]  1.134587  0.551506  0.301019  0.14605 -1.61310
[10,] -0.354385 -0.387888 -0.107050 -0.52486 -1.91007
[11,] -0.013738  1.423648 -0.624466 -0.96542  2.68151
[12,]  1.162805  0.499519  0.601568  0.20257 -1.75372
[13,]  0.599969 -0.267814  0.369252 -0.29947 -1.38065
[14,] -1.711850 -1.200787 -0.848659  1.81837  2.49609
[15,] -0.033879  1.057477 -0.422689 -0.91636  0.19860
> 
> 
> 
> 
> proc.time()
   user  system elapsed 
 40.932   0.040  41.102 
