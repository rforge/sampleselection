
R version 2.14.2 (2012-02-29)
Copyright (C) 2012 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> library( censReg )
Loading required package: maxLik
Loading required package: miscTools
> library( plm )
Loading required package: bdsmatrix

Attaching package: 'bdsmatrix'

The following object(s) are masked from 'package:base':

    backsolve

Loading required package: nlme
Loading required package: Formula
Loading required package: MASS
Loading required package: sandwich
Loading required package: zoo

Attaching package: 'zoo'

The following object(s) are masked from 'package:base':

    as.Date, as.Date.numeric

> 
> nId <- 15
> nTime <- 4
> 
> set.seed( 123 )
> pData <- data.frame(
+    id = rep( paste( "F", 1:nId, sep = "_" ), each = nTime ),
+    time = rep( 1980 + 1:nTime, nId ) )
> pData$ui <- rep( rnorm( nId ), each = nTime )
> pData$x1 <- rnorm( nId * nTime )
> pData$x2 <- runif( nId * nTime )
> pData$ys <- -1 + pData$ui + 2 * pData$x1 + 3 * pData$x2 + rnorm( nId * nTime )
> pData$y <- ifelse( pData$ys > 0, pData$ys, 0 )
> nData <- pData # save data set without information on panel structure
> pData <- pdata.frame( pData, c( "id", "time" ) )
> 
> 
> ## Newton-Raphson method
> randEff <- censReg( y ~ x1 + x2, data = pData )
> print( randEff )

Call:
censReg(formula = y ~ x1 + x2, data = pData)

Coefficients:
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
   -0.36562     1.68000     2.24054    -0.12955    -0.01241 

> print( randEff, logSigma = FALSE )

Call:
censReg(formula = y ~ x1 + x2, data = pData)

Coefficients:
(Intercept)          x1          x2     sigmaMu     sigmaNu 
    -0.3656      1.6800      2.2405      0.8785      0.9877 

> maxLik:::summary.maxLik( randEff )
--------------------------------------------
Maximum Likelihood estimation
Newton-Raphson maximisation, 5 iterations
Return code 1: gradient close to zero
Log-Likelihood: -73.19882 
5  free parameters
Estimates:
             Estimate Std. error t value   Pr(> t)    
(Intercept) -0.365623   0.474457 -0.7706 0.4409361    
x1           1.680004   0.209222  8.0298 9.767e-16 ***
x2           2.240544   0.673889  3.3248 0.0008848 ***
logSigmaMu  -0.129547   0.258070 -0.5020 0.6156793    
logSigmaNu  -0.012408   0.129690 -0.0957 0.9237786    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> summary( randEff )

Call:
censReg(formula = y ~ x1 + x2, data = pData)

Observations:
         Total  Left-censored     Uncensored Right-censored 
            60             20             40              0 

Coefficients:
            Estimate Std. error t value  Pr(> t)    
(Intercept) -0.36562    0.47446  -0.771 0.440936    
x1           1.68000    0.20922   8.030 9.77e-16 ***
x2           2.24054    0.67389   3.325 0.000885 ***
logSigmaMu  -0.12955    0.25807  -0.502 0.615679    
logSigmaNu  -0.01241    0.12969  -0.096 0.923779    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Newton-Raphson maximisation, 5 iterations
Return code 1: gradient close to zero
Log-likelihood: -73.19882 on 5 Df

> print( summary( randEff ), logSigma = FALSE )

Call:
censReg(formula = y ~ x1 + x2, data = pData)

Observations:
         Total  Left-censored     Uncensored Right-censored 
            60             20             40              0 

Coefficients:
            Estimate Std. error t value  Pr(> t)    
(Intercept)  -0.3656     0.4745  -0.771 0.440936    
x1            1.6800     0.2092   8.030 9.77e-16 ***
x2            2.2405     0.6739   3.325 0.000885 ***
sigmaMu       0.8785     0.2267   3.875 0.000107 ***
sigmaNu       0.9877     0.1281   7.711 1.25e-14 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Newton-Raphson maximisation, 5 iterations
Return code 1: gradient close to zero
Log-likelihood: -73.19882 on 5 Df

> coef( randEff )
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
-0.36562313  1.68000400  2.24054376 -0.12954703 -0.01240809 
> coef( randEff, logSigma = FALSE )
(Intercept)          x1          x2     sigmaMu     sigmaNu 
 -0.3656231   1.6800040   2.2405438   0.8784933   0.9876686 
> vcov( randEff )
             (Intercept)           x1           x2   logSigmaMu   logSigmaNu
(Intercept)  0.225109672 -0.020570168 -0.254602886 -0.023824162 -0.002973952
x1          -0.020570168  0.043773972  0.008562225  0.013404079  0.002969957
x2          -0.254602886  0.008562225  0.454125882  0.017179542  0.001505438
logSigmaMu  -0.023824162  0.013404079  0.017179542  0.066600320 -0.002638871
logSigmaNu  -0.002973952  0.002969957  0.001505438 -0.002638871  0.016819442
> vcov( randEff, logSigma = FALSE )
             (Intercept)           x1           x2      sigmaMu      sigmaNu
(Intercept)  0.225109672 -0.020570168 -0.254602886 -0.020929366 -0.002937279
x1          -0.020570168  0.043773972  0.008562225  0.011775394  0.002933333
x2          -0.254602886  0.008562225  0.454125882  0.015092113  0.001486874
sigmaMu     -0.020929366  0.011775394  0.015092113  0.051398826 -0.002289643
sigmaNu     -0.002937279  0.002933333  0.001486874 -0.002289643  0.016407184
> coef( summary( randEff ) )
               Estimate Std. error     t value      Pr(> t)
(Intercept) -0.36562313  0.4744572 -0.77061344 4.409361e-01
x1           1.68000400  0.2092223  8.02975581 9.766687e-16
x2           2.24054376  0.6738886  3.32479829 8.848252e-04
logSigmaMu  -0.12954703  0.2580704 -0.50198333 6.156793e-01
logSigmaNu  -0.01240809  0.1296898 -0.09567514 9.237786e-01
> coef( summary( randEff ), logSigma = FALSE )
              Estimate Std. error    t value      Pr(> t)
(Intercept) -0.3656231  0.4744572 -0.7706134 4.409361e-01
x1           1.6800040  0.2092223  8.0297558 9.766687e-16
x2           2.2405438  0.6738886  3.3247983 8.848252e-04
sigmaMu      0.8784933  0.2267131  3.8749120 1.066632e-04
sigmaNu      0.9876686  0.1280905  7.7107072 1.251225e-14
> logLik( randEff )
'log Lik.' -73.19882 (df=5)
> extractAIC( randEff )
[1] -40.0000 156.3976
> print.default( randEff )
$maximum
[1] -73.19882

$estimate
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
-0.36562313  1.68000400  2.24054376 -0.12954703 -0.01240809 

$gradient
 (Intercept)           x1           x2   logSigmaMu   logSigmaNu 
1.712707e-11 4.535116e-11 1.345738e-11 8.213902e-12 6.206907e-11 

$hessian
            (Intercept)         x1         x2  logSigmaMu  logSigmaNu
(Intercept)  -13.321985  -4.096607 -7.3075697  -2.1079024  -1.3088177
x1            -4.096607 -26.076787 -1.9905305   4.4849638   4.7620891
x2            -7.307570  -1.990530 -6.2362552  -0.6238251  -0.4803054
logSigmaMu    -2.107902   4.484964 -0.6238251 -16.6582041  -3.7223987
logSigmaNu    -1.308818   4.762089 -0.4803054  -3.7223987 -61.0683413

$code
[1] 1

$message
[1] "gradient close to zero"

$last.step
NULL

$fixed
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
      FALSE       FALSE       FALSE       FALSE       FALSE 

$iterations
[1] 5

$type
[1] "Newton-Raphson maximisation"

$gradientObs
      (Intercept)          x1          x2 logSigmaMu logSigmaNu
 [1,] -0.85308353  0.22558520 -0.07261010 -0.1440032 -0.9609402
 [2,] -1.70309357  0.04839424 -1.18987552  1.6807831 -1.0133141
 [3,]  1.75084247  0.33367482  1.72755770  1.8353812  1.8043727
 [4,]  0.15577733 -0.20240007 -0.43224660 -0.6891081 -1.4351382
 [5,]  0.12950026  0.98433620  0.68943625 -0.6770204 -0.5543803
 [6,]  0.33035909 -0.30928416  0.38471147 -0.4921375 -1.5793716
 [7,] -0.08212549 -3.18521871 -0.23724729 -0.6766315  6.0271932
 [8,] -0.26685300  0.37888544  0.05565473 -0.5385828 -1.1091111
 [9,]  1.14824183  0.59396387  0.30328556  0.1329802 -1.6172740
[10,] -0.43505392 -0.40640593 -0.15245982 -0.4687582 -1.9364984
[11,] -0.02839185  1.44795739 -0.64407731 -0.9172655  2.7349924
[12,]  1.21047881  0.53669833  0.61328528  0.2055542 -1.7351236
[13,]  0.53592707 -0.22523044  0.33117482 -0.3691166 -1.4082834
[14,] -1.81460674 -1.30608969 -0.91950989  1.9573174  2.5815580
[15,] -0.07791875  1.08513351 -0.45707928 -0.8393922  0.2013187

$call
censReg(formula = y ~ x1 + x2, data = pData)

$terms
y ~ x1 + x2
attr(,"variables")
list(y, x1, x2)
attr(,"factors")
   x1 x2
y   0  0
x1  1  0
x2  0  1
attr(,"term.labels")
[1] "x1" "x2"
attr(,"order")
[1] 1 1
attr(,"intercept")
[1] 1
attr(,"response")
[1] 1
attr(,".Environment")
<environment: R_GlobalEnv>
attr(,"predvars")
list(y, x1, x2)
attr(,"dataClasses")
        y        x1        x2 
"numeric" "numeric" "numeric" 

$nObs
         Total  Left-censored     Uncensored Right-censored 
            60             20             40              0 

$df.residual
[1] 55

$start
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
  0.4703506   1.0111600   1.6191826  -0.4962510  -0.0620962 

attr(,"class")
[1] "censReg" "maxLik"  "maxim"   "list"   
> 
> 
> ## BHHH method
> randEffBhhh <- censReg( y ~ x1 + x2, data = pData, method = "BHHH" )
> print( randEffBhhh )

Call:
censReg(formula = y ~ x1 + x2, data = pData, method = "BHHH")

Coefficients:
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
    -0.3656      1.6800      2.2406     -0.1296     -0.0124 

> maxLik:::summary.maxLik( randEffBhhh )
--------------------------------------------
Maximum Likelihood estimation
BHHH maximisation, 18 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -73.19882 
5  free parameters
Estimates:
             Estimate Std. error t value   Pr(> t)    
(Intercept) -0.365635   0.555054 -0.6587  0.510065    
x1           1.680016   0.293775  5.7187 1.073e-08 ***
x2           2.240556   0.729501  3.0714  0.002131 ** 
logSigmaMu  -0.129565   0.295017 -0.4392  0.660531    
logSigmaNu  -0.012402   0.140134 -0.0885  0.929481    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> summary( randEffBhhh )

Call:
censReg(formula = y ~ x1 + x2, data = pData, method = "BHHH")

Observations:
         Total  Left-censored     Uncensored Right-censored 
            60             20             40              0 

Coefficients:
            Estimate Std. error t value  Pr(> t)    
(Intercept)  -0.3656     0.5551  -0.659  0.51006    
x1            1.6800     0.2938   5.719 1.07e-08 ***
x2            2.2406     0.7295   3.071  0.00213 ** 
logSigmaMu   -0.1296     0.2950  -0.439  0.66053    
logSigmaNu   -0.0124     0.1401  -0.088  0.92948    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

BHHH maximisation, 18 iterations
Return code 2: successive function values within tolerance limit
Log-likelihood: -73.19882 on 5 Df

> print.default( randEffBhhh )
$maximum
[1] -73.19882

$estimate
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
-0.36563477  1.68001566  2.24055570 -0.12956535 -0.01240161 

$gradient
  (Intercept)            x1            x2    logSigmaMu    logSigmaNu 
 5.028294e-05 -3.315101e-04 -4.246354e-06  3.505038e-04 -2.626408e-04 

$hessian
            (Intercept)         x1         x2  logSigmaMu logSigmaNu
(Intercept)  -13.482494  -4.096061 -8.3241402   2.7373240   3.959016
x1            -4.096061 -17.395897 -2.1956247   2.0949384  19.029556
x2            -8.324140  -2.195625 -7.3456165  -0.2437129   3.421562
logSigmaMu     2.737324   2.094938 -0.2437129 -13.9308908  -3.639137
logSigmaNu     3.959016  19.029556  3.4215617  -3.6391374 -73.168704
attr(,"type")
[1] "BHHH"

$code
[1] 2

$message
[1] "successive function values within tolerance limit"

$last.step
NULL

$fixed
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
      FALSE       FALSE       FALSE       FALSE       FALSE 

$iterations
[1] 18

$type
[1] "BHHH maximisation"

$gradientObs
      (Intercept)          x1          x2 logSigmaMu logSigmaNu
 [1,] -0.85309912  0.22553991 -0.07262972 -0.1439976 -0.9609756
 [2,] -1.70314125  0.04834913 -1.18991475  1.6808211 -1.0132976
 [3,]  1.75089168  0.33368134  1.72757656  1.8353986  1.8044304
 [4,]  0.15581599 -0.20240761 -0.43221921 -0.6890852 -1.4351543
 [5,]  0.12951232  0.98431668  0.68943033 -0.6770023 -0.5544220
 [6,]  0.33038531 -0.30929737  0.38473066 -0.4921403 -1.5793732
 [7,] -0.08212211 -3.18519652 -0.23724499 -0.6766142  6.0271629
 [8,] -0.26685182  0.37888104  0.05565305 -0.5385702 -1.1091241
 [9,]  1.14826405  0.59392337  0.30329461  0.1330245 -1.6172865
[10,] -0.43507487 -0.40642217 -0.15246997 -0.4687544 -1.9364930
[11,] -0.02840097  1.44793082 -0.64407223 -0.9172307  2.7348842
[12,]  1.21050842  0.53669645  0.61330484  0.2056154 -1.7351598
[13,]  0.53595825 -0.22524780  0.33119153 -0.3691112 -1.4082671
[14,] -1.81465694 -1.30619017 -0.91955280  1.9573642  2.5815611
[15,] -0.07793866  1.08511138 -0.45708215 -0.8393671  0.2012520

$call
censReg(formula = y ~ x1 + x2, data = pData, method = "BHHH")

$terms
y ~ x1 + x2
attr(,"variables")
list(y, x1, x2)
attr(,"factors")
   x1 x2
y   0  0
x1  1  0
x2  0  1
attr(,"term.labels")
[1] "x1" "x2"
attr(,"order")
[1] 1 1
attr(,"intercept")
[1] 1
attr(,"response")
[1] 1
attr(,".Environment")
<environment: R_GlobalEnv>
attr(,"predvars")
list(y, x1, x2)
attr(,"dataClasses")
        y        x1        x2 
"numeric" "numeric" "numeric" 

$nObs
         Total  Left-censored     Uncensored Right-censored 
            60             20             40              0 

$df.residual
[1] 55

$start
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
  0.4703506   1.0111600   1.6191826  -0.4962510  -0.0620962 

attr(,"class")
[1] "censReg" "maxLik"  "maxim"   "list"   
> 
> 
> ## BFGS method (optim)
> randEffBfgs <- censReg( y ~ x1 + x2, data = pData, method = "BFGS" )
> print( randEffBfgs )

Call:
censReg(formula = y ~ x1 + x2, data = pData, method = "BFGS")

Coefficients:
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
   -0.36562     1.68000     2.24055    -0.12955    -0.01241 

> maxLik:::summary.maxLik( randEffBfgs )
--------------------------------------------
Maximum Likelihood estimation
BFGS maximisation, 25 iterations
Return code 0: successful convergence 
Log-Likelihood: -73.19882 
5  free parameters
Estimates:
             Estimate Std. error t value   Pr(> t)    
(Intercept) -0.365624   0.474456 -0.7706 0.4409343    
x1           1.680002   0.209222  8.0298 9.767e-16 ***
x2           2.240551   0.673888  3.3248 0.0008848 ***
logSigmaMu  -0.129549   0.258071 -0.5020 0.6156731    
logSigmaNu  -0.012408   0.129690 -0.0957 0.9237762    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> summary( randEffBfgs )

Call:
censReg(formula = y ~ x1 + x2, data = pData, method = "BFGS")

Observations:
         Total  Left-censored     Uncensored Right-censored 
            60             20             40              0 

Coefficients:
            Estimate Std. error t value  Pr(> t)    
(Intercept) -0.36562    0.47446  -0.771 0.440934    
x1           1.68000    0.20922   8.030 9.77e-16 ***
x2           2.24055    0.67389   3.325 0.000885 ***
logSigmaMu  -0.12955    0.25807  -0.502 0.615673    
logSigmaNu  -0.01241    0.12969  -0.096 0.923776    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

BFGS maximisation, 25 iterations
Return code 0: successful convergence 
Log-likelihood: -73.19882 on 5 Df

> print.default( randEffBfgs )
$maximum
[1] -73.19882

$estimate
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
-0.36562386  1.68000222  2.24055118 -0.12954945 -0.01240847 

$gradient
  (Intercept)            x1            x2    logSigmaMu    logSigmaNu 
-3.160077e-05  2.178336e-05 -3.570719e-05  3.081674e-05  2.108131e-05 

$hessian
            (Intercept)         x1         x2  logSigmaMu logSigmaNu
(Intercept)  -13.322030  -4.096615 -7.3075895  -2.1078505  -1.308810
x1            -4.096615 -26.076823 -1.9905334   4.4849768   4.762042
x2            -7.307589  -1.990533 -6.2362665  -0.6237935  -0.480264
logSigmaMu    -2.107850   4.484977 -0.6237936 -16.6581488  -3.722435
logSigmaNu    -1.308810   4.762042 -0.4802640  -3.7224350 -61.068402

$code
[1] 0

$message
[1] "successful convergence "

$last.step
NULL

$fixed
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
      FALSE       FALSE       FALSE       FALSE       FALSE 

$iterations
function 
      25 

$type
[1] "BFGS maximisation"

$constraints
NULL

$gradientObs
      (Intercept)          x1          x2 logSigmaMu logSigmaNu
 [1,] -0.85308743  0.22558129 -0.07261263 -0.1440013 -0.9609385
 [2,] -1.70310343  0.04839017 -1.18988370  1.6807981 -1.0133093
 [3,]  1.75084680  0.33368182  1.72755839  1.8353799  1.8043672
 [4,]  0.15577623 -0.20239996 -0.43224879 -0.6891122 -1.4351265
 [5,]  0.12949863  0.98433692  0.68943374 -0.6770205 -0.5543875
 [6,]  0.33035850 -0.30927350  0.38470918 -0.4921407 -1.5793728
 [7,] -0.08212636 -3.18521917 -0.23724752 -0.6766300  6.0271888
 [8,] -0.26685580  0.37888651  0.05565314 -0.5385807 -1.1091140
 [9,]  1.14824376  0.59396790  0.30328585  0.1329813 -1.6172723
[10,] -0.43505882 -0.40640593 -0.15246287 -0.4687554 -1.9365001
[11,] -0.02839283  1.44796138 -0.64407965 -0.9172624  2.7350038
[12,]  1.21048230  0.53670265  0.61328478  0.2055557 -1.7351212
[13,]  0.53592379 -0.22522781  0.33117257 -0.3691209 -1.4082845
[14,] -1.81461479 -1.30609804 -0.91951560  1.9573273  2.5815634
[15,] -0.07792214  1.08513754 -0.45708262 -0.8393873  0.2013247

$call
censReg(formula = y ~ x1 + x2, data = pData, method = "BFGS")

$terms
y ~ x1 + x2
attr(,"variables")
list(y, x1, x2)
attr(,"factors")
   x1 x2
y   0  0
x1  1  0
x2  0  1
attr(,"term.labels")
[1] "x1" "x2"
attr(,"order")
[1] 1 1
attr(,"intercept")
[1] 1
attr(,"response")
[1] 1
attr(,".Environment")
<environment: R_GlobalEnv>
attr(,"predvars")
list(y, x1, x2)
attr(,"dataClasses")
        y        x1        x2 
"numeric" "numeric" "numeric" 

$nObs
         Total  Left-censored     Uncensored Right-censored 
            60             20             40              0 

$df.residual
[1] 55

$start
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
  0.4703506   1.0111600   1.6191826  -0.4962510  -0.0620962 

attr(,"class")
[1] "censReg" "maxLik"  "maxim"  
> 
> 
> ## BFGS method (R)
> randEffBfgsr <- censReg( y ~ x1 + x2, data = pData, method = "BFGSR" )
> print( randEffBfgsr )

Call:
censReg(formula = y ~ x1 + x2, data = pData, method = "BFGSR")

Coefficients:
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
   -0.36587     1.68002     2.24093    -0.12952    -0.01243 

> maxLik:::summary.maxLik( randEffBfgsr )
--------------------------------------------
Maximum Likelihood estimation
BFGSR maximization, 96 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -73.19882 
5  free parameters
Estimates:
             Estimate Std. error t value   Pr(> t)    
(Intercept) -0.365871   0.474479 -0.7711  0.440648    
x1           1.680023   0.209221  8.0299 9.756e-16 ***
x2           2.240926   0.673887  3.3254  0.000883 ***
logSigmaMu  -0.129525   0.258059 -0.5019  0.615725    
logSigmaNu  -0.012433   0.129687 -0.0959  0.923623    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> summary( randEffBfgsr )

Call:
censReg(formula = y ~ x1 + x2, data = pData, method = "BFGSR")

Observations:
         Total  Left-censored     Uncensored Right-censored 
            60             20             40              0 

Coefficients:
            Estimate Std. error t value  Pr(> t)    
(Intercept) -0.36587    0.47448  -0.771 0.440648    
x1           1.68002    0.20922   8.030 9.76e-16 ***
x2           2.24093    0.67389   3.325 0.000883 ***
logSigmaMu  -0.12952    0.25806  -0.502 0.615725    
logSigmaNu  -0.01243    0.12969  -0.096 0.923623    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

BFGSR maximization, 96 iterations
Return code 2: successive function values within tolerance limit
Log-likelihood: -73.19882 on 5 Df

> print.default( randEffBfgsr )
$maximum
[1] -73.19882

$estimate
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
-0.36587093  1.68002290  2.24092589 -0.12952474 -0.01243325 

$gradient
  (Intercept)            x1            x2    logSigmaMu    logSigmaNu 
 4.172135e-04 -2.582919e-04 -6.117348e-04  9.123233e-05  1.684705e-03 

$hessian
            (Intercept)         x1         x2  logSigmaMu  logSigmaNu
(Intercept)  -13.321357  -4.096703 -7.3074148  -2.1095873  -1.3074327
x1            -4.096703 -26.077471 -1.9904989   4.4849156   4.7625127
x2            -7.307415  -1.990499 -6.2363187  -0.6244758  -0.4782726
logSigmaMu    -2.109587   4.484916 -0.6244758 -16.6603352  -3.7222176
logSigmaNu    -1.307433   4.762513 -0.4782726  -3.7222176 -61.0705915

$code
[1] 2

$message
[1] "successive function values within tolerance limit"

$last.step
NULL

$fixed
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
      FALSE       FALSE       FALSE       FALSE       FALSE 

$iterations
[1] 96

$type
[1] "BFGSR maximization"

$gradientObs
      (Intercept)          x1          x2 logSigmaMu logSigmaNu
 [1,] -0.85306086  0.22550058 -0.07265739 -0.1440168 -0.9612354
 [2,] -1.70309243  0.04830011 -1.18993443  1.6808915 -1.0132824
 [3,]  1.75083174  0.33358127  1.72747051  1.8354726  1.8040265
 [4,]  0.15573445 -0.20245828 -0.43236874 -0.6891126 -1.4346426
 [5,]  0.12952593  0.98426973  0.68935599 -0.6770224 -0.5547150
 [6,]  0.33032397 -0.30916111  0.38466295 -0.4921217 -1.5794347
 [7,] -0.08199634 -3.18546328 -0.23723547 -0.6766821  6.0279485
 [8,] -0.26677064  0.37882062  0.05566615 -0.5386269 -1.1090550
 [9,]  1.14828876  0.59396113  0.30328677  0.1330783 -1.6171431
[10,] -0.43497713 -0.40635992 -0.15243456 -0.4688055 -1.9364760
[11,] -0.02834696  1.44814799 -0.64413332 -0.9173662  2.7356590
[12,]  1.21043846  0.53679812  0.61315634  0.2054857 -1.7349647
[13,]  0.53598614 -0.22526256  0.33118989 -0.3690449 -1.4082472
[14,] -1.81461951 -1.30622614 -0.91953779  1.9574566  2.5814708
[15,] -0.07784838  1.08529344 -0.45709863 -0.8394945  0.2017760

$call
censReg(formula = y ~ x1 + x2, data = pData, method = "BFGSR")

$terms
y ~ x1 + x2
attr(,"variables")
list(y, x1, x2)
attr(,"factors")
   x1 x2
y   0  0
x1  1  0
x2  0  1
attr(,"term.labels")
[1] "x1" "x2"
attr(,"order")
[1] 1 1
attr(,"intercept")
[1] 1
attr(,"response")
[1] 1
attr(,".Environment")
<environment: R_GlobalEnv>
attr(,"predvars")
list(y, x1, x2)
attr(,"dataClasses")
        y        x1        x2 
"numeric" "numeric" "numeric" 

$nObs
         Total  Left-censored     Uncensored Right-censored 
            60             20             40              0 

$df.residual
[1] 55

$start
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
  0.4703506   1.0111600   1.6191826  -0.4962510  -0.0620962 

attr(,"class")
[1] "censReg" "maxLik"  "maxim"   "list"   
> 
> 
> ## BHHH with starting values
> randEffBhhhStart <- censReg( y ~ x1 + x2, data = pData, method = "BHHH",
+    start = c( -0.4, 1.7, 2.2, -0.1, -0.01 ) )
> print( randEffBhhhStart )

Call:
censReg(formula = y ~ x1 + x2, data = pData, start = c(-0.4, 
    1.7, 2.2, -0.1, -0.01), method = "BHHH")

Coefficients:
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
    -0.3657      1.6800      2.2406     -0.1296     -0.0124 

> summary( randEffBhhhStart )

Call:
censReg(formula = y ~ x1 + x2, data = pData, start = c(-0.4, 
    1.7, 2.2, -0.1, -0.01), method = "BHHH")

Observations:
         Total  Left-censored     Uncensored Right-censored 
            60             20             40              0 

Coefficients:
            Estimate Std. error t value  Pr(> t)    
(Intercept)  -0.3657     0.5551  -0.659  0.51003    
x1            1.6800     0.2938   5.719 1.07e-08 ***
x2            2.2406     0.7295   3.071  0.00213 ** 
logSigmaMu   -0.1295     0.2950  -0.439  0.66056    
logSigmaNu   -0.0124     0.1401  -0.088  0.92948    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

BHHH maximisation, 10 iterations
Return code 2: successive function values within tolerance limit
Log-likelihood: -73.19882 on 5 Df

> 
> 
> ## left-censoring at 5
> pData$yAdd <- pData$y + 5
> randEffAdd <- censReg( yAdd ~ x1 + x2, data = pData, method = "BFGSR", left = 5 )
> print( randEffAdd )

Call:
censReg(formula = yAdd ~ x1 + x2, left = 5, data = pData, method = "BFGSR")

Coefficients:
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
    4.63351     1.68002     2.24187    -0.12945    -0.01235 

> maxLik:::summary.maxLik( randEffAdd )
--------------------------------------------
Maximum Likelihood estimation
BFGSR maximization, 105 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -73.19883 
5  free parameters
Estimates:
             Estimate Std. error t value   Pr(> t)    
(Intercept)  4.633508   0.474561  9.7638 < 2.2e-16 ***
x1           1.680019   0.209240  8.0292 9.815e-16 ***
x2           2.241869   0.673967  3.3264 0.0008798 ***
logSigmaMu  -0.129451   0.258064 -0.5016 0.6159326    
logSigmaNu  -0.012346   0.129698 -0.0952 0.9241622    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> summary( randEffAdd )

Call:
censReg(formula = yAdd ~ x1 + x2, left = 5, data = pData, method = "BFGSR")

Observations:
         Total  Left-censored     Uncensored Right-censored 
            60             20             40              0 

Coefficients:
            Estimate Std. error t value  Pr(> t)    
(Intercept)  4.63351    0.47456   9.764  < 2e-16 ***
x1           1.68002    0.20924   8.029 9.81e-16 ***
x2           2.24187    0.67397   3.326  0.00088 ***
logSigmaMu  -0.12945    0.25806  -0.502  0.61593    
logSigmaNu  -0.01235    0.12970  -0.095  0.92416    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

BFGSR maximization, 105 iterations
Return code 2: successive function values within tolerance limit
Log-likelihood: -73.19883 on 5 Df

> coef( randEffAdd )
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
 4.63350813  1.68001875  2.24186922 -0.12945104 -0.01234624 
> coef( randEffAdd, logSigma = FALSE )
(Intercept)          x1          x2     sigmaMu     sigmaNu 
  4.6335081   1.6800188   2.2418692   0.8785776   0.9877297 
> vcov( randEffAdd )
             (Intercept)           x1           x2   logSigmaMu   logSigmaNu
(Intercept)  0.225208367 -0.020590012 -0.254692051 -0.023867634 -0.002989242
x1          -0.020590012  0.043781322  0.008582277  0.013407927  0.002969541
x2          -0.254692051  0.008582277  0.454230962  0.017207694  0.001539845
logSigmaMu  -0.023867634  0.013407927  0.017207694  0.066597184 -0.002636491
logSigmaNu  -0.002989242  0.002969541  0.001539845 -0.002636491  0.016821594
> vcov( randEffAdd, logSigma = FALSE )
             (Intercept)           x1           x2      sigmaMu      sigmaNu
(Intercept)  0.225208367 -0.020590012 -0.254692051 -0.020969569 -0.002952563
x1          -0.020590012  0.043781322  0.008582277  0.011779905  0.002933104
x2          -0.254692051  0.008582277  0.454230962  0.015118294  0.001520950
sigmaMu     -0.020969569  0.011779905  0.015118294  0.051406273 -0.002287939
sigmaNu     -0.002952563  0.002933104  0.001520950 -0.002287939  0.016411313
> logLik( randEffAdd )
'log Lik.' -73.19883 (df=5)
> extractAIC( randEffAdd )
[1] -40.0000 156.3977
> print.default( randEffAdd )
$maximum
[1] -73.19883

$estimate
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
 4.63350813  1.68001875  2.24186922 -0.12945104 -0.01234624 

$gradient
  (Intercept)            x1            x2    logSigmaMu    logSigmaNu 
 0.0015432006  0.0012607203 -0.0020363065 -0.0007577694 -0.0035603921 

$hessian
            (Intercept)         x1         x2  logSigmaMu  logSigmaNu
(Intercept)  -13.318448  -4.095873 -7.3059493  -2.1125121  -1.3059874
x1            -4.095873 -26.072999 -1.9899750   4.4839455   4.7598002
x2            -7.305949  -1.989975 -6.2351455  -0.6254346  -0.4742555
logSigmaMu    -2.112512   4.483946 -0.6254346 -16.6612050  -3.7210572
logSigmaNu    -1.305987   4.759800 -0.4742555  -3.7210572 -61.0595283

$code
[1] 2

$message
[1] "successive function values within tolerance limit"

$last.step
NULL

$fixed
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
      FALSE       FALSE       FALSE       FALSE       FALSE 

$iterations
[1] 105

$type
[1] "BFGSR maximization"

$gradientObs
      (Intercept)          x1          x2 logSigmaMu logSigmaNu
 [1,] -0.85278513  0.22525689 -0.07275174 -0.1441796 -0.9623322
 [2,] -1.70297534  0.04812965 -1.18995985  1.6809023 -1.0131469
 [3,]  1.75054956  0.33375150  1.72692354  1.8351240  1.8022354
 [4,]  0.15575128 -0.20252363 -0.43243148 -0.6890881 -1.4339778
 [5,]  0.12955595  0.98406028  0.68899172 -0.6769890 -0.5558761
 [6,]  0.33034397 -0.30844290  0.38451924 -0.4920909 -1.5801027
 [7,] -0.08169246 -3.18495570 -0.23713459 -0.6767194  6.0270759
 [8,] -0.26663125  0.37870402  0.05566403 -0.5386485 -1.1090384
 [9,]  1.14828498  0.59393944  0.30326240  0.1332828 -1.6169395
[10,] -0.43474321 -0.40601283 -0.15236897 -0.4689916 -1.9366709
[11,] -0.02827275  1.44830684 -0.64415338 -0.9174409  2.7359051
[12,]  1.21035171  0.53700189  0.61286736  0.2054303 -1.7348895
[13,]  0.53599740 -0.22518722  0.33114213 -0.3690121 -1.4084457
[14,] -1.81441592 -1.30618386 -0.91950820  1.9572710  2.5803840
[15,] -0.07777559  1.08541635 -0.45709852 -0.8396081  0.2022589

$call
censReg(formula = yAdd ~ x1 + x2, left = 5, data = pData, method = "BFGSR")

$terms
yAdd ~ x1 + x2
attr(,"variables")
list(yAdd, x1, x2)
attr(,"factors")
     x1 x2
yAdd  0  0
x1    1  0
x2    0  1
attr(,"term.labels")
[1] "x1" "x2"
attr(,"order")
[1] 1 1
attr(,"intercept")
[1] 1
attr(,"response")
[1] 1
attr(,".Environment")
<environment: R_GlobalEnv>
attr(,"predvars")
list(yAdd, x1, x2)
attr(,"dataClasses")
     yAdd        x1        x2 
"numeric" "numeric" "numeric" 

$nObs
         Total  Left-censored     Uncensored Right-censored 
            60             20             40              0 

$df.residual
[1] 55

$start
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
  5.4703506   1.0111600   1.6191826  -0.4962510  -0.0620962 

attr(,"class")
[1] "censReg" "maxLik"  "maxim"   "list"   
> 
> 
> ## right-censoring
> pData$yNeg <- - pData$y
> randEffNeg <- censReg( yNeg ~ x1 + x2, data = pData, method = "BFGSR",
+    left = -Inf, right = 0 )
> print( randEffNeg )

Call:
censReg(formula = yNeg ~ x1 + x2, left = -Inf, right = 0, data = pData, 
    method = "BFGSR")

Coefficients:
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
    0.36710    -1.68010    -2.24284    -0.12943    -0.01239 

> maxLik:::summary.maxLik( randEffNeg )
--------------------------------------------
Maximum Likelihood estimation
BFGSR maximization, 87 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -73.19883 
5  free parameters
Estimates:
             Estimate Std. error t value   Pr(> t)    
(Intercept)  0.367102   0.474610  0.7735 0.4392381    
x1          -1.680101   0.209242 -8.0295 9.791e-16 ***
x2          -2.242841   0.673971 -3.3278 0.0008754 ***
logSigmaMu  -0.129426   0.258048 -0.5016 0.6159785    
logSigmaNu  -0.012391   0.129694 -0.0955 0.9238878    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> summary( randEffNeg )

Call:
censReg(formula = yNeg ~ x1 + x2, left = -Inf, right = 0, data = pData, 
    method = "BFGSR")

Observations:
         Total  Left-censored     Uncensored Right-censored 
            60              0             40             20 

Coefficients:
            Estimate Std. error t value  Pr(> t)    
(Intercept)  0.36710    0.47461   0.773 0.439238    
x1          -1.68010    0.20924  -8.029 9.79e-16 ***
x2          -2.24284    0.67397  -3.328 0.000875 ***
logSigmaMu  -0.12943    0.25805  -0.502 0.615979    
logSigmaNu  -0.01239    0.12969  -0.096 0.923888    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

BFGSR maximization, 87 iterations
Return code 2: successive function values within tolerance limit
Log-likelihood: -73.19883 on 5 Df

> coef( randEffNeg )
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
 0.36710188 -1.68010130 -2.24284076 -0.12942589 -0.01239068 
> coef( randEffNeg, logSigma = FALSE )
(Intercept)          x1          x2     sigmaMu     sigmaNu 
  0.3671019  -1.6801013  -2.2428408   0.8785997   0.9876858 
> vcov( randEffNeg )
             (Intercept)           x1           x2   logSigmaMu   logSigmaNu
(Intercept)  0.225255066 -0.020604503 -0.254722852  0.023897411  0.002998828
x1          -0.020604503  0.043782312  0.008598236 -0.013409724 -0.002970897
x2          -0.254722852  0.008598236  0.454237364 -0.017226447 -0.001564741
logSigmaMu   0.023897411 -0.013409724 -0.017226447  0.066588642 -0.002634974
logSigmaNu   0.002998828 -0.002970897 -0.001564741 -0.002634974  0.016820586
> vcov( randEffNeg, logSigma = FALSE )
            (Intercept)           x1           x2      sigmaMu      sigmaNu
(Intercept)  0.22525507 -0.020604503 -0.254722852  0.020996258  0.002961900
x1          -0.02060450  0.043782312  0.008598236 -0.011781779 -0.002934313
x2          -0.25472285  0.008598236  0.454237364 -0.015135151 -0.001545473
sigmaMu      0.02099626 -0.011781779 -0.015135151  0.051402266 -0.002286579
sigmaNu      0.00296190 -0.002934313 -0.001545473 -0.002286579  0.016408872
> logLik( randEffNeg )
'log Lik.' -73.19883 (df=5)
> extractAIC( randEffNeg )
[1] -40.0000 156.3977
> print.default( randEffNeg )
$maximum
[1] -73.19883

$estimate
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
 0.36710188 -1.68010130 -2.24284076 -0.12942589 -0.01239068 

$gradient
  (Intercept)            x1            x2    logSigmaMu    logSigmaNu 
-2.236047e-03  4.250578e-04  3.796463e-03  4.011092e-05 -2.104214e-04 

$hessian
            (Intercept)         x1         x2  logSigmaMu  logSigmaNu
(Intercept)  -13.317368  -4.096080 -7.3057150   2.1160411   1.3026668
x1            -4.096080 -26.073684 -1.9898689  -4.4839860  -4.7624742
x2            -7.305715  -1.989869 -6.2352728   0.6266641   0.4691597
logSigmaMu     2.116041  -4.483986  0.6266641 -16.6651230  -3.7215527
logSigmaNu     1.302667  -4.762474  0.4691597  -3.7215527 -61.0637081

$code
[1] 2

$message
[1] "successive function values within tolerance limit"

$last.step
NULL

$fixed
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
      FALSE       FALSE       FALSE       FALSE       FALSE 

$iterations
[1] 87

$type
[1] "BFGSR maximization"

$gradientObs
      (Intercept)          x1          x2 logSigmaMu logSigmaNu
 [1,]  0.85279233 -0.22490131  0.07293363 -0.1441731 -0.9631385
 [2,]  1.70308174 -0.04778014  1.19019682  1.6813160 -1.0130360
 [3,] -1.75054001 -0.33347145 -1.72669219  1.8352350  1.8014149
 [4,] -0.15568789  0.20268590  0.43269686 -0.6890969 -1.4327657
 [5,] -0.12961571 -0.98384096 -0.68875808 -0.6769737 -0.5568133
 [6,] -0.33024565  0.30824598 -0.38440508 -0.4921152 -1.5802502
 [7,]  0.08138685  3.18550538  0.23710453 -0.6768074  6.0288921
 [8,]  0.26644086 -0.37853975 -0.05568124 -0.5387265 -1.1089340
 [9,] -1.14842321 -0.59382564 -0.30327684  0.1335771 -1.6166751
[10,]  0.43462859  0.40595883  0.15234263 -0.4690676 -1.9366042
[11,]  0.02819032 -1.44869800  0.64427731 -0.9176095  2.7372584
[12,] -1.21030155 -0.53723214 -0.61258576  0.2053225 -1.7345715
[13,] -0.53616642  0.22528306 -0.33119126 -0.3688498 -1.4083441
[14,]  1.81456812  1.30678138  0.91968304  1.9577959  2.5801652
[15,]  0.07765558 -1.08574608  0.45715208 -0.8397867  0.2031916

$call
censReg(formula = yNeg ~ x1 + x2, left = -Inf, right = 0, data = pData, 
    method = "BFGSR")

$terms
yNeg ~ x1 + x2
attr(,"variables")
list(yNeg, x1, x2)
attr(,"factors")
     x1 x2
yNeg  0  0
x1    1  0
x2    0  1
attr(,"term.labels")
[1] "x1" "x2"
attr(,"order")
[1] 1 1
attr(,"intercept")
[1] 1
attr(,"response")
[1] 1
attr(,".Environment")
<environment: R_GlobalEnv>
attr(,"predvars")
list(yNeg, x1, x2)
attr(,"dataClasses")
     yNeg        x1        x2 
"numeric" "numeric" "numeric" 

$nObs
         Total  Left-censored     Uncensored Right-censored 
            60              0             40             20 

$df.residual
[1] 55

$start
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
 -0.4703506  -1.0111600  -1.6191826  -0.4962510  -0.0620962 

attr(,"class")
[1] "censReg" "maxLik"  "maxim"   "list"   
> 
> 
> ## right-censoring at -5
> pData$yAddNeg <- - pData$yAdd
> randEffAddNeg <- censReg( yAddNeg ~ x1 + x2, data = pData, method = "BFGSR",
+    left = -Inf, right = -5 )
> print( randEffAddNeg )

Call:
censReg(formula = yAddNeg ~ x1 + x2, left = -Inf, right = -5, 
    data = pData, method = "BFGSR")

Coefficients:
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
   -4.63251    -1.68006    -2.24332    -0.12935    -0.01241 

> maxLik:::summary.maxLik( randEffAddNeg )
--------------------------------------------
Maximum Likelihood estimation
BFGSR maximization, 88 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -73.19883 
5  free parameters
Estimates:
             Estimate Std. error t value   Pr(> t)    
(Intercept) -4.632515   0.474662 -9.7596 < 2.2e-16 ***
x1          -1.680061   0.209239 -8.0294 9.797e-16 ***
x2          -2.243320   0.673983 -3.3285 0.0008733 ***
logSigmaMu  -0.129348   0.258030 -0.5013 0.6161664    
logSigmaNu  -0.012407   0.129693 -0.0957 0.9237841    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> summary( randEffAddNeg )

Call:
censReg(formula = yAddNeg ~ x1 + x2, left = -Inf, right = -5, 
    data = pData, method = "BFGSR")

Observations:
         Total  Left-censored     Uncensored Right-censored 
            60              0             40             20 

Coefficients:
            Estimate Std. error t value  Pr(> t)    
(Intercept) -4.63251    0.47466  -9.760  < 2e-16 ***
x1          -1.68006    0.20924  -8.029  9.8e-16 ***
x2          -2.24332    0.67398  -3.328 0.000873 ***
logSigmaMu  -0.12935    0.25803  -0.501 0.616166    
logSigmaNu  -0.01241    0.12969  -0.096 0.923784    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

BFGSR maximization, 88 iterations
Return code 2: successive function values within tolerance limit
Log-likelihood: -73.19883 on 5 Df

> coef( randEffAddNeg )
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
-4.63251451 -1.68006056 -2.24332044 -0.12934815 -0.01240745 
> coef( randEffAddNeg, logSigma = FALSE )
(Intercept)          x1          x2     sigmaMu     sigmaNu 
 -4.6325145  -1.6800606  -2.2433204   0.8786680   0.9876692 
> vcov( randEffAddNeg )
             (Intercept)           x1           x2   logSigmaMu   logSigmaNu
(Intercept)  0.225304403 -0.020613946 -0.254754490  0.023924149  0.003002657
x1          -0.020613946  0.043781109  0.008605934 -0.013410045 -0.002968880
x2          -0.254754490  0.008605934  0.454253283 -0.017237261 -0.001575930
logSigmaMu   0.023924149 -0.013410045 -0.017237261  0.066579540 -0.002633035
logSigmaNu   0.003002657 -0.002968880 -0.001575930 -0.002633035  0.016820158
> vcov( randEffAddNeg, logSigma = FALSE )
             (Intercept)           x1           x2      sigmaMu      sigmaNu
(Intercept)  0.225304403 -0.020613946 -0.254754490  0.021021385  0.002965632
x1          -0.020613946  0.043781109  0.008605934 -0.011782977 -0.002932272
x2          -0.254754490  0.008605934  0.454253283 -0.015145829 -0.001556498
sigmaMu      0.021021385 -0.011782977 -0.015145829  0.051403230 -0.002285036
sigmaNu      0.002965632 -0.002932272 -0.001556498 -0.002285036  0.016407904
> logLik( randEffAddNeg )
'log Lik.' -73.19883 (df=5)
> extractAIC( randEffAddNeg )
[1] -40.0000 156.3977
> print.default( randEffAddNeg )
$maximum
[1] -73.19883

$estimate
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
-4.63251451 -1.68006056 -2.24332044 -0.12934815 -0.01240745 

$gradient
  (Intercept)            x1            x2    logSigmaMu    logSigmaNu 
-0.0038641116 -0.0015227501  0.0039448399 -0.0008643679  0.0006054536 

$hessian
            (Intercept)         x1         x2 logSigmaMu  logSigmaNu
(Intercept)  -13.315655  -4.096021 -7.3051314   2.119935   1.3014880
x1            -4.096021 -26.074303 -1.9897832  -4.483265  -4.7593425
x2            -7.305131  -1.989783 -6.2351183   0.628412   0.4670523
logSigmaMu     2.119935  -4.483265  0.6284120 -16.668812  -3.7202354
logSigmaNu     1.301488  -4.759342  0.4670523  -3.720235 -61.0634754

$code
[1] 2

$message
[1] "successive function values within tolerance limit"

$last.step
NULL

$fixed
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
      FALSE       FALSE       FALSE       FALSE       FALSE 

$iterations
[1] 88

$type
[1] "BFGSR maximization"

$gradientObs
      (Intercept)         x1          x2 logSigmaMu logSigmaNu
 [1,]  0.85256423 -0.2250299  0.07287496 -0.1443204 -0.9635716
 [2,]  1.70285484 -0.0478571  1.19008366  1.6810785 -1.0130313
 [3,] -1.75049387 -0.3335613 -1.72654026  1.8354982  1.8006971
 [4,] -0.15564988  0.2027185  0.43281792 -0.6890347 -1.4322741
 [5,] -0.12968180 -0.9838168 -0.68867177 -0.6769737 -0.5571956
 [6,] -0.33031169  0.3077624 -0.38436370 -0.4919421 -1.5805142
 [7,]  0.08116571  3.1855950  0.23706224 -0.6769069  6.0292065
 [8,]  0.26629967 -0.3784570 -0.05571625 -0.5388154 -1.1088282
 [9,] -1.14844038 -0.5939664 -0.30326112  0.1336744 -1.6164212
[10,]  0.43435658  0.4057172  0.15223172 -0.4692537 -1.9366570
[11,]  0.02808782 -1.4489896  0.64433615 -0.9178240  2.7381985
[12,] -1.21018170 -0.5373796 -0.61236726  0.2052389 -1.7343499
[13,] -0.53623362  0.2252896 -0.33120251 -0.3687294 -1.4083694
[14,]  1.81430963  1.3064348  0.91951534  1.9574747  2.5797698
[15,]  0.07749036 -1.0859824  0.45714570 -0.8400287  0.2039461

$call
censReg(formula = yAddNeg ~ x1 + x2, left = -Inf, right = -5, 
    data = pData, method = "BFGSR")

$terms
yAddNeg ~ x1 + x2
attr(,"variables")
list(yAddNeg, x1, x2)
attr(,"factors")
        x1 x2
yAddNeg  0  0
x1       1  0
x2       0  1
attr(,"term.labels")
[1] "x1" "x2"
attr(,"order")
[1] 1 1
attr(,"intercept")
[1] 1
attr(,"response")
[1] 1
attr(,".Environment")
<environment: R_GlobalEnv>
attr(,"predvars")
list(yAddNeg, x1, x2)
attr(,"dataClasses")
  yAddNeg        x1        x2 
"numeric" "numeric" "numeric" 

$nObs
         Total  Left-censored     Uncensored Right-censored 
            60              0             40             20 

$df.residual
[1] 55

$start
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
 -5.4703506  -1.0111600  -1.6191826  -0.4962510  -0.0620962 

attr(,"class")
[1] "censReg" "maxLik"  "maxim"   "list"   
> 
> 
> ## both right and left censoring
> pData$yBoth <- ifelse( pData$y < 3, pData$y, 3 )
> randEffBoth <- censReg( yBoth ~ x1 + x2, data = pData, method = "BFGSR",
+    left = 0, right = 3 )
> print( randEffBoth )

Call:
censReg(formula = yBoth ~ x1 + x2, left = 0, right = 3, data = pData, 
    method = "BFGSR")

Coefficients:
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
  -0.232534    1.893042    1.967582    0.001479    0.052592 

> maxLik:::summary.maxLik( randEffBoth )
--------------------------------------------
Maximum Likelihood estimation
BFGSR maximization, 95 iterations
Return code 3: Last step could not find a value above the current.
Boundary of parameter space?  
Consider switching to a more robust optimisation method temporarily.
Log-Likelihood: -64.31274 
5  free parameters
Estimates:
              Estimate Std. error t value   Pr(> t)    
(Intercept) -0.2325343  0.5481180 -0.4242   0.67139    
x1           1.8930415  0.3010145  6.2889 3.198e-10 ***
x2           1.9675822  0.8184749  2.4040   0.01622 *  
logSigmaMu   0.0014788  0.2778205  0.0053   0.99575    
logSigmaNu   0.0525918  0.1629764  0.3227   0.74693    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> summary( randEffBoth )

Call:
censReg(formula = yBoth ~ x1 + x2, left = 0, right = 3, data = pData, 
    method = "BFGSR")

Observations:
         Total  Left-censored     Uncensored Right-censored 
            60             20             28             12 

Coefficients:
             Estimate Std. error t value Pr(> t)    
(Intercept) -0.232534   0.548118  -0.424  0.6714    
x1           1.893042   0.301015   6.289 3.2e-10 ***
x2           1.967582   0.818475   2.404  0.0162 *  
logSigmaMu   0.001479   0.277821   0.005  0.9958    
logSigmaNu   0.052592   0.162976   0.323  0.7469    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

BFGSR maximization, 95 iterations
Return code 3: Last step could not find a value above the current.
Boundary of parameter space?  
Consider switching to a more robust optimisation method temporarily.
Log-likelihood: -64.31274 on 5 Df

> print( summary( randEffBoth ), logSigma = FALSE )

Call:
censReg(formula = yBoth ~ x1 + x2, left = 0, right = 3, data = pData, 
    method = "BFGSR")

Observations:
         Total  Left-censored     Uncensored Right-censored 
            60             20             28             12 

Coefficients:
            Estimate Std. error t value  Pr(> t)    
(Intercept)  -0.2325     0.5481  -0.424 0.671390    
x1            1.8930     0.3010   6.289 3.20e-10 ***
x2            1.9676     0.8185   2.404 0.016218 *  
sigmaMu       1.0015     0.2782   3.599 0.000319 ***
sigmaNu       1.0540     0.1718   6.136 8.47e-10 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

BFGSR maximization, 95 iterations
Return code 3: Last step could not find a value above the current.
Boundary of parameter space?  
Consider switching to a more robust optimisation method temporarily.
Log-likelihood: -64.31274 on 5 Df

> coef( randEffBoth )
 (Intercept)           x1           x2   logSigmaMu   logSigmaNu 
-0.232534256  1.893041511  1.967582188  0.001478768  0.052591838 
> coef( randEffBoth, logSigma = FALSE )
(Intercept)          x1          x2     sigmaMu     sigmaNu 
 -0.2325343   1.8930415   1.9675822   1.0014799   1.0539994 
> vcov( randEffBoth )
            (Intercept)          x1          x2  logSigmaMu  logSigmaNu
(Intercept)  0.30043337 -0.03132054 -0.36373552 -0.01588086 -0.01633593
x1          -0.03132054  0.09060975  0.03169947  0.03517351  0.01591406
x2          -0.36373552  0.03169947  0.66990114  0.01855280  0.02441036
logSigmaMu  -0.01588086  0.03517351  0.01855280  0.07718424  0.00433417
logSigmaNu  -0.01633593  0.01591406  0.02441036  0.00433417  0.02656132
> vcov( randEffBoth, logSigma = FALSE )
            (Intercept)          x1          x2      sigmaMu      sigmaNu
(Intercept)  0.30043337 -0.03132054 -0.36373552 -0.015904363 -0.017218060
x1          -0.03132054  0.09060975  0.03169947  0.035225564  0.016773407
x2          -0.36373552  0.03169947  0.66990114  0.018580253  0.025728507
sigmaMu     -0.01590436  0.03522556  0.01858025  0.077412856  0.004574973
sigmaNu     -0.01721806  0.01677341  0.02572851  0.004574973  0.029507362
> coef( summary( randEffBoth ) )
                Estimate Std. error      t value      Pr(> t)
(Intercept) -0.232534256  0.5481180 -0.424241214 6.713899e-01
x1           1.893041511  0.3010145  6.288870695 3.197837e-10
x2           1.967582188  0.8184749  2.403961588 1.621848e-02
logSigmaMu   0.001478768  0.2778205  0.005322744 9.957531e-01
logSigmaNu   0.052591838  0.1629764  0.322695936 7.469255e-01
> coef( summary( randEffBoth ), logSigma = FALSE )
              Estimate Std. error    t value      Pr(> t)
(Intercept) -0.2325343  0.5481180 -0.4242412 6.713899e-01
x1           1.8930415  0.3010145  6.2888707 3.197837e-10
x2           1.9675822  0.8184749  2.4039616 1.621848e-02
sigmaMu      1.0014799  0.2782317  3.5994461 3.188957e-04
sigmaNu      1.0539994  0.1717771  6.1358559 8.470193e-10
> logLik( randEffBoth )
'log Lik.' -64.31274 (df=5)
> extractAIC( randEffBoth )
[1] -40.0000 138.6255
> print.default( randEffBoth )
$maximum
[1] -64.31274

$estimate
 (Intercept)           x1           x2   logSigmaMu   logSigmaNu 
-0.232534256  1.893041511  1.967582188  0.001478768  0.052591838 

$gradient
 (Intercept)           x1           x2   logSigmaMu   logSigmaNu 
-0.004114817 -0.002025237  0.004682574  0.002517484  0.005046947 

$hessian
            (Intercept)          x1         x2   logSigmaMu  logSigmaNu
(Intercept) -9.93290709  -1.4921966 -5.3088980  -0.06938279  -0.3246649
x1          -1.49219663 -15.1461776 -0.5459935   6.29794470   7.6311060
x2          -5.30889801  -0.5459935 -4.3928463   0.15207760   1.0743075
logSigmaMu  -0.06938278   6.2979447  0.1520776 -15.79950631  -1.3777104
logSigmaNu  -0.32466496   7.6311060  1.0743075  -1.37771038 -43.1830365

$code
[1] 3

$message
[1] "Last step could not find a value above the current.\nBoundary of parameter space?  \nConsider switching to a more robust optimisation method temporarily."

$last.step
$last.step$theta0
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
-0.23248870  1.89283433  1.96747546  0.00150166  0.05271351 

$last.step$f0
[1] -64.31274
attr(,"gradient")
             [,1]        [,2]        [,3]        [,4]       [,5]
 [1,] -0.85418983 -0.10561116 -0.18121325 -0.02357408 -0.8364588
 [2,] -1.41649565 -0.02591258 -0.97138758  1.45553029 -1.1647654
 [3,]  1.29749493  1.02169464  0.92570816  1.09197820  0.1541546
 [4,]  0.07087837 -0.25163231 -0.39792272 -0.70155886 -1.8283536
 [5,]  0.08907228  0.80803894  0.64811108 -0.69076899 -0.2831532
 [6,]  0.55948928  0.49476740  0.42916290 -0.29125189 -0.3599609
 [7,] -0.12082809 -3.06103319 -0.23676850 -0.70611426  6.3405957
 [8,] -0.20997941  0.33586893  0.08325523 -0.59053629 -1.0296682
 [9,]  1.03412584  0.66084821  0.28828731  0.19637660 -1.2971992
[10,] -0.42828213 -0.58542991 -0.11730482 -0.39577138 -1.8009127
[11,] -0.04079816  1.09470184 -0.50812302 -0.86660368  2.0006597
[12,]  1.14044311  0.50505633  0.83263154  0.58547068 -0.7447220
[13,]  0.53439169 -0.28148780  0.34773113 -0.28691330 -1.4339704
[14,] -1.63786798 -1.34645384 -0.83769637  2.11880854  2.7640739
[15,] -0.02118696  0.73875974 -0.29931428 -0.89440719 -0.4822676

$last.step$climb
[1]   782605.4 -3559290.2 -1833525.7   393297.0  2090320.9


$fixed
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
      FALSE       FALSE       FALSE       FALSE       FALSE 

$iterations
[1] 95

$type
[1] "BFGSR maximization"

$gradientObs
      (Intercept)          x1          x2  logSigmaMu logSigmaNu
 [1,] -0.85441581 -0.10583646 -0.18133356 -0.02336057 -0.8362970
 [2,] -1.41664833 -0.02623694 -0.97157056  1.45596309 -1.1648055
 [3,]  1.29757425  1.02139161  0.92573579  1.09210578  0.1542595
 [4,]  0.07075854 -0.25179594 -0.39813998 -0.70157996 -1.8278297
 [5,]  0.08908014  0.80788172  0.64816304 -0.69079913 -0.2830867
 [6,]  0.55945411  0.49448887  0.42922286 -0.29128100 -0.3595725
 [7,] -0.12080340 -3.06215132 -0.23683886 -0.70618554  6.3440187
 [8,] -0.20988937  0.33578531  0.08328414 -0.59061228 -1.0295518
 [9,]  1.03423675  0.66059692  0.28832374  0.19652799 -1.2972169
[10,] -0.42844293 -0.58584646 -0.11734586 -0.39558216 -1.8005032
[11,] -0.04076477  1.09477702 -0.50814510 -0.86657679  2.0010138
[12,]  1.14041346  0.50502728  0.83265202  0.58533177 -0.7446469
[13,]  0.53463081 -0.28173437  0.34787775 -0.28669160 -1.4335854
[14,] -1.63820748 -1.34717986 -0.83791978  2.11975507  2.7649220
[15,] -0.02109079  0.73880739 -0.29928307 -0.89449720 -0.4820714

$call
censReg(formula = yBoth ~ x1 + x2, left = 0, right = 3, data = pData, 
    method = "BFGSR")

$terms
yBoth ~ x1 + x2
attr(,"variables")
list(yBoth, x1, x2)
attr(,"factors")
      x1 x2
yBoth  0  0
x1     1  0
x2     0  1
attr(,"term.labels")
[1] "x1" "x2"
attr(,"order")
[1] 1 1
attr(,"intercept")
[1] 1
attr(,"response")
[1] 1
attr(,".Environment")
<environment: R_GlobalEnv>
attr(,"predvars")
list(yBoth, x1, x2)
attr(,"dataClasses")
    yBoth        x1        x2 
"numeric" "numeric" "numeric" 

$nObs
         Total  Left-censored     Uncensored Right-censored 
            60             20             28             12 

$df.residual
[1] 55

$start
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
  0.6056357   0.8113032   1.0023997  -0.7545646  -0.2748137 

attr(,"class")
[1] "censReg" "maxLik"  "maxim"   "list"   
> 
> 
> ## re-order observations/individuals
> set.seed( 234 )
> perm <- sample( nId )
> nData2 <- nData
> nData2$id <- NA
> for( i in 1:nId ) {
+    nData2$id[ nData$id == paste( "F", i, sep = "_" ) ] <-
+       paste( "G", perm[ i ], sep = "_" )
+ }
> pData2 <- pdata.frame( nData2, c( "id", "time" ) )
> randEffBfgsr2 <- censReg( y ~ x1 + x2, data = pData2, method = "BFGSR" )
> all.equal( randEffBfgsr2[ -c(11,12) ], randEffBfgsr[ -c(11,12) ] )
[1] "Component 2: Mean relative difference: 0.0004131909"
[2] "Component 3: Mean relative difference: 0.9263514"   
[3] "Component 4: Mean relative difference: 0.0001482037"
[4] "Component 9: Mean relative difference: 0.05882353"  
> all.equal( sort( randEffBfgsr2[[ 11 ]] ), sort( randEffBfgsr[[ 11 ]] ) )
[1] "Mean relative difference: 0.0002800725"
> 
> # check if the order of observations/individuals influences the likelihood values
> d1c1 <- censReg( y ~ x1 + x2, data = pData, method = "BFGSR", start = coef(randEffBfgsr),
+    iterlim = 0 )
> all.equal( d1c1[-c(5,6,9,12,16)], randEffBfgsr[-c(5,6,9,12,16)] )
[1] TRUE
> d1c1$maximum -  randEffBfgsr$maximum
[1] 0
> 
> d2c2 <- censReg( y ~ x1 + x2, data = pData2, method = "BFGSR", start = coef(randEffBfgsr2),
+    iterlim = 0 )
> all.equal( d2c2[-c(5,6,9,12,16)], randEffBfgsr2[-c(5,6,9,12,16)] )
[1] TRUE
> d2c2$maximum -  randEffBfgsr2$maximum
[1] 0
> 
> d1c2 <- censReg( y ~ x1 + x2, data = pData, method = "BFGSR", 
+    start = coef(randEffBfgsr2), iterlim = 0 )
> d2c2$maximum - d1c2$maximum
[1] 0
> d2c2$gradient - d1c2$gradient
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
          0           0           0           0           0 
> 
> d2c1 <- censReg( y ~ x1 + x2, data = pData2, method = "BFGSR", 
+    start = coef(randEffBfgsr), iterlim = 0 )
> d1c1$maximum - d2c1$maximum
[1] 0
> d1c1$gradient - d2c1$gradient
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
          0           0           0           0           0 
> 
> d2c2$maximum - d2c1$maximum
[1] -5.395683e-07
> d1c1$maximum - d1c2$maximum
[1] 5.395683e-07
> 
> d1c3 <- censReg( y ~ x1 + x2, data = pData, method = "BFGSR", 
+    start = 0.95 * coef(randEffBfgsr), iterlim = 0 )
> d2c3 <- censReg( y ~ x1 + x2, data = pData2, method = "BFGSR", 
+    start = 0.95 * coef(randEffBfgsr), iterlim = 0 )
> d1c3$maximum - d2c3$maximum
[1] 0
> d1c3$gradient - d2c3$gradient
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
          0           0           0           0           0 
> 
> 
> ## unbalanced panel data
> nDataUnb <- nData[ -c( 2, 5, 6, 8 ), ]
> pDataUnb <- pdata.frame( nDataUnb, c( "id", "time" ) )
> randEffBfgsrUnb <- censReg( y ~ x1 + x2, data = pDataUnb, method = "BFGSR" )
> print( randEffBfgsrUnb )

Call:
censReg(formula = y ~ x1 + x2, data = pDataUnb, method = "BFGSR")

Coefficients:
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
  -0.221535    1.640362    2.106413   -0.167642   -0.001552 

> maxLik:::summary.maxLik( randEffBfgsrUnb )
--------------------------------------------
Maximum Likelihood estimation
BFGSR maximization, 82 iterations
Return code 3: Last step could not find a value above the current.
Boundary of parameter space?  
Consider switching to a more robust optimisation method temporarily.
Log-Likelihood: -71.1926 
5  free parameters
Estimates:
              Estimate Std. error t value   Pr(> t)    
(Intercept) -0.2215348  0.4722951 -0.4691   0.63903    
x1           1.6403622  0.2109599  7.7757 7.503e-15 ***
x2           2.1064127  0.6845522  3.0771   0.00209 ** 
logSigmaMu  -0.1676424  0.2714913 -0.6175   0.53691    
logSigmaNu  -0.0015525  0.1322291 -0.0117   0.99063    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> summary( randEffBfgsrUnb )

Call:
censReg(formula = y ~ x1 + x2, data = pDataUnb, method = "BFGSR")

Observations:
         Total  Left-censored     Uncensored Right-censored 
            56             17             39              0 

Coefficients:
             Estimate Std. error t value Pr(> t)    
(Intercept) -0.221535   0.472295  -0.469 0.63903    
x1           1.640362   0.210960   7.776 7.5e-15 ***
x2           2.106413   0.684552   3.077 0.00209 ** 
logSigmaMu  -0.167642   0.271491  -0.617 0.53691    
logSigmaNu  -0.001552   0.132229  -0.012 0.99063    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

BFGSR maximization, 82 iterations
Return code 3: Last step could not find a value above the current.
Boundary of parameter space?  
Consider switching to a more robust optimisation method temporarily.
Log-likelihood: -71.1926 on 5 Df

> logLik( randEffBfgsrUnb )
'log Lik.' -71.1926 (df=5)
> extractAIC( randEffBfgsrUnb )
[1] -36.0000 152.3852
> print.default( randEffBfgsrUnb )
$maximum
[1] -71.1926

$estimate
 (Intercept)           x1           x2   logSigmaMu   logSigmaNu 
-0.221534809  1.640362164  2.106412731 -0.167642358 -0.001552465 

$gradient
 (Intercept)           x1           x2   logSigmaMu   logSigmaNu 
-0.004122583 -0.001457139  0.009746788  0.002393028  0.024114188 

$hessian
            (Intercept)         x1         x2  logSigmaMu logSigmaNu
(Intercept)  -13.801477  -4.350388 -7.5341650  -1.1067616  -1.944842
x1            -4.350388 -25.833517 -2.0597199   4.6537428   4.055793
x2            -7.534165  -2.059720 -6.2709439  -0.1427734  -1.069432
logSigmaMu    -1.106762   4.653743 -0.1427734 -14.9296618  -3.780777
logSigmaNu    -1.944842   4.055793 -1.0694319  -3.7807773 -58.875578

$code
[1] 3

$message
[1] "Last step could not find a value above the current.\nBoundary of parameter space?  \nConsider switching to a more robust optimisation method temporarily."

$last.step
$last.step$theta0
  (Intercept)            x1            x2    logSigmaMu    logSigmaNu 
-0.2216896698  1.6400047156  2.1065142750 -0.1674968963 -0.0008778459 

$last.step$f0
[1] -71.1926
attr(,"gradient")
             [,1]         [,2]        [,3]        [,4]       [,5]
 [1,] -0.50814093  0.090110381  0.10403019 -0.39444350 -0.5301249
 [2,] -1.81665219  0.067967945 -1.24658522  1.79704154 -0.9613745
 [3,]  1.78469392  0.486601532  1.76989347  1.73315892  1.8959563
 [4,]  0.15217489 -0.162238620 -0.39528542 -0.73666693 -1.5884867
 [5,]  0.08159507  1.039450313  0.69826938 -0.67798549 -0.4451371
 [6,]  0.33313666 -0.231043590  0.37402331 -0.53928917 -1.5743869
 [7,] -0.18103896 -3.027078659 -0.24848184 -0.62193685  5.4736811
 [8,]  0.01867612 -0.004070926  0.01068153 -0.41755498 -0.5818470
 [9,]  1.11541287  0.667239997  0.29560658  0.06297268 -1.6859356
[10,] -0.53774642 -0.419649067 -0.20420753 -0.40660401 -1.9749613
[11,] -0.08322611  1.377897444 -0.64738374 -0.82291378  2.4926893
[12,]  1.25907468  0.531563349  0.66997758  0.23126027 -1.7944670
[13,]  0.44632675 -0.163006143  0.28622945 -0.46860857 -1.4509816
[14,] -1.89199210 -1.284417454 -0.96148059  1.98113055  2.6808342
[15,] -0.17496592  1.042315476 -0.49501775 -0.72339159  0.0271588

$last.step$climb
[1] -2660481 -6140912  1744512  2499019 11589869


$fixed
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
      FALSE       FALSE       FALSE       FALSE       FALSE 

$iterations
[1] 82

$type
[1] "BFGSR maximization"

$gradientObs
      (Intercept)           x1          x2  logSigmaMu  logSigmaNu
 [1,] -0.50893067  0.089657178  0.10400210 -0.39408390 -0.52884793
 [2,] -1.81753354  0.067453941 -1.24739175  1.79869929 -0.96166459
 [3,]  1.78584227  0.484586235  1.77145637  1.73540763  1.90054847
 [4,]  0.15177046 -0.162604043 -0.39621544 -0.73700133 -1.58605145
 [5,]  0.08175261  1.039597165  0.69907445 -0.67821197 -0.44341752
 [6,]  0.33259629 -0.233369718  0.37416947 -0.53952493 -1.57177141
 [7,] -0.18108254 -3.032129508 -0.24882935 -0.62220896  5.48602982
 [8,]  0.01868198 -0.004072204  0.01068489 -0.41781445 -0.58158766
 [9,]  1.11621364  0.667021748  0.29583999  0.06330956 -1.68549137
[10,] -0.53829835 -0.421065541 -0.20438492 -0.40614965 -1.97360743
[11,] -0.08314951  1.379072128 -0.64787725 -0.82332328  2.49810403
[12,]  1.25933649  0.531692005  0.67013670  0.23099877 -1.79310515
[13,]  0.44682311 -0.163678112  0.28656847 -0.46814466 -1.44963321
[14,] -1.89342432 -1.286964754 -0.96220726  1.98408396  2.68530692
[15,] -0.17472050  1.043346339 -0.49527968 -0.72364306  0.02930266

$call
censReg(formula = y ~ x1 + x2, data = pDataUnb, method = "BFGSR")

$terms
y ~ x1 + x2
attr(,"variables")
list(y, x1, x2)
attr(,"factors")
   x1 x2
y   0  0
x1  1  0
x2  0  1
attr(,"term.labels")
[1] "x1" "x2"
attr(,"order")
[1] 1 1
attr(,"intercept")
[1] 1
attr(,"response")
[1] 1
attr(,".Environment")
<environment: R_GlobalEnv>
attr(,"predvars")
list(y, x1, x2)
attr(,"dataClasses")
        y        x1        x2 
"numeric" "numeric" "numeric" 

$nObs
         Total  Left-censored     Uncensored Right-censored 
            56             17             39              0 

$df.residual
[1] 51

$start
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
 0.48299720  1.03002625  1.63470549 -0.47772116 -0.04988945 

attr(,"class")
[1] "censReg" "maxLik"  "maxim"   "list"   
> 
> 
> ## NAs in data
> pDataNa <- pData
> obsNa <- which( ! rownames( pData ) %in% rownames( pDataUnb ) )
> pDataNa$y[ obsNa[ 1:2 ] ] <- NA
> pDataNa$x1[ obsNa[ 3 ] ] <- NA
> pDataNa$x2[ obsNa[ c( 1, 2, 4 ) ] ] <- NA
> randEffBfgsrNa <- censReg( y ~ x1 + x2, data = pDataNa, method = "BFGSR" )
> all.equal( randEffBfgsrNa[ -12 ], randEffBfgsrUnb[ -12 ] )
[1] TRUE
> 
> 
> # returning log-likelihood contributions only (no estimations)
> logLikRandEff <- censReg( y ~ x1 + x2, data = pData, start = coef( randEff ),
+    logLikOnly = TRUE )
> print( logLikRandEff )
 [1] -4.252049 -3.739068 -7.046358 -5.300447 -3.354337 -5.307797 -6.291576
 [8] -1.655650 -4.393946 -3.765898 -6.821870 -5.646158 -4.333350 -5.726405
[15] -5.563914
attr(,"gradient")
             [,1]        [,2]        [,3]       [,4]       [,5]
 [1,] -0.85308353  0.22558520 -0.07261010 -0.1440032 -0.9609402
 [2,] -1.70309357  0.04839424 -1.18987552  1.6807831 -1.0133141
 [3,]  1.75084247  0.33367482  1.72755770  1.8353812  1.8043727
 [4,]  0.15577733 -0.20240007 -0.43224660 -0.6891081 -1.4351382
 [5,]  0.12950026  0.98433620  0.68943625 -0.6770204 -0.5543803
 [6,]  0.33035909 -0.30928416  0.38471147 -0.4921375 -1.5793716
 [7,] -0.08212549 -3.18521871 -0.23724729 -0.6766315  6.0271932
 [8,] -0.26685300  0.37888544  0.05565473 -0.5385828 -1.1091111
 [9,]  1.14824183  0.59396387  0.30328556  0.1329802 -1.6172740
[10,] -0.43505392 -0.40640593 -0.15245982 -0.4687582 -1.9364984
[11,] -0.02839185  1.44795739 -0.64407731 -0.9172655  2.7349924
[12,]  1.21047881  0.53669833  0.61328528  0.2055542 -1.7351236
[13,]  0.53592707 -0.22523044  0.33117482 -0.3691166 -1.4082834
[14,] -1.81460674 -1.30608969 -0.91950989  1.9573174  2.5815580
[15,] -0.07791875  1.08513351 -0.45707928 -0.8393922  0.2013187
> all.equal( sum( logLikRandEff ), c( logLik( randEff ) ) )
[1] TRUE
> logLikStart <- censReg( y ~ x1 + x2, data = pData, 
+    start = c( -0.4, 1.7, 2.2, -0.1, -0.01 ), logLikOnly = TRUE )
> print( logLikStart )
 [1] -4.223693 -3.590625 -7.110342 -5.316228 -3.389378 -5.360380 -6.349353
 [8] -1.661668 -4.433769 -3.774324 -6.788058 -5.699416 -4.385225 -5.593147
[15] -5.548283
attr(,"gradient")
             [,1]        [,2]        [,3]       [,4]       [,5]
 [1,] -0.78780430  0.27899526 -0.03948865 -0.1781187 -1.0281108
 [2,] -1.58232641  0.09231159 -1.09619445  1.4850210 -1.0562683
 [3,]  1.72436737  0.26392132  1.72228285  1.9089216  1.8439353
 [4,]  0.18480626 -0.20993642 -0.40681657 -0.6139118 -1.5330720
 [5,]  0.16156500  0.97006006  0.71388764 -0.6642389 -0.5115526
 [6,]  0.36176010 -0.38785781  0.42046000 -0.4277169 -1.5829540
 [7,] -0.04900991 -3.19667670 -0.23065229 -0.6996566  6.1344398
 [8,] -0.21856969  0.35678338  0.07820116 -0.5684845 -1.0658263
 [9,]  1.13458709  0.55150636  0.30101863  0.1460472 -1.6130954
[10,] -0.35438475 -0.38788784 -0.10704963 -0.5248618 -1.9100687
[11,] -0.01373800  1.42364787 -0.62446618 -0.9654173  2.6815112
[12,]  1.16280483  0.49951850  0.60156788  0.2025718 -1.7537215
[13,]  0.59996890 -0.26781383  0.36925229 -0.2994739 -1.3806520
[14,] -1.71185020 -1.20078722 -0.84865925  1.8183688  2.4960866
[15,] -0.03387939  1.05747706 -0.42268903 -0.9163573  0.1985986
> 
> 
> 
> 
