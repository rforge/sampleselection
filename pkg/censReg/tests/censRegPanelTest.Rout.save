
R version 2.14.2 (2012-02-29)
Copyright (C) 2012 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> library( censReg )
Loading required package: maxLik
Loading required package: miscTools
> library( plm )
Loading required package: bdsmatrix

Attaching package: 'bdsmatrix'

The following object(s) are masked from 'package:base':

    backsolve

Loading required package: nlme
Loading required package: Formula
Loading required package: MASS
Loading required package: sandwich
Loading required package: zoo

Attaching package: 'zoo'

The following object(s) are masked from 'package:base':

    as.Date, as.Date.numeric

> 
> nId <- 15
> nTime <- 4
> 
> set.seed( 123 )
> pData <- data.frame(
+    id = rep( paste( "F", 1:nId, sep = "_" ), each = nTime ),
+    time = rep( 1980 + 1:nTime, nId ) )
> pData$ui <- rep( rnorm( nId ), each = nTime )
> pData$x1 <- rnorm( nId * nTime )
> pData$x2 <- runif( nId * nTime )
> pData$ys <- -1 + pData$ui + 2 * pData$x1 + 3 * pData$x2 + rnorm( nId * nTime )
> pData$y <- ifelse( pData$ys > 0, pData$ys, 0 )
> nData <- pData # save data set without information on panel structure
> pData <- pdata.frame( pData, c( "id", "time" ) )
> 
> 
> ## Newton-Raphson method
> randEff <- censReg( y ~ x1 + x2, data = pData )
> print( randEff )

Call:
censReg(formula = y ~ x1 + x2, data = pData)

Coefficients:
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
   -0.36562     1.68000     2.24054    -0.12955    -0.01241 

> print( randEff, logSigma = FALSE )

Call:
censReg(formula = y ~ x1 + x2, data = pData)

Coefficients:
(Intercept)          x1          x2     sigmaMu     sigmaNu 
    -0.3656      1.6800      2.2405      0.8785      0.9877 

> maxLik:::summary.maxLik( randEff )
--------------------------------------------
Maximum Likelihood estimation
Newton-Raphson maximisation, 5 iterations
Return code 1: gradient close to zero
Log-Likelihood: -73.19882 
5  free parameters
Estimates:
             Estimate Std. error t value   Pr(> t)    
(Intercept) -0.365623   0.474457 -0.7706 0.4409361    
x1           1.680004   0.209222  8.0298 9.767e-16 ***
x2           2.240544   0.673889  3.3248 0.0008848 ***
logSigmaMu  -0.129547   0.258070 -0.5020 0.6156793    
logSigmaNu  -0.012408   0.129690 -0.0957 0.9237786    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> summary( randEff )

Call:
censReg(formula = y ~ x1 + x2, data = pData)

Observations:
         Total  Left-censored     Uncensored Right-censored 
            60             20             40              0 

Coefficients:
            Estimate Std. error t value  Pr(> t)    
(Intercept) -0.36562    0.47446  -0.771 0.440936    
x1           1.68000    0.20922   8.030 9.77e-16 ***
x2           2.24054    0.67389   3.325 0.000885 ***
logSigmaMu  -0.12955    0.25807  -0.502 0.615679    
logSigmaNu  -0.01241    0.12969  -0.096 0.923779    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Newton-Raphson maximisation, 5 iterations
Return code 1: gradient close to zero
Log-likelihood: -73.19882 on 5 Df

> print( summary( randEff ), logSigma = FALSE )

Call:
censReg(formula = y ~ x1 + x2, data = pData)

Observations:
         Total  Left-censored     Uncensored Right-censored 
            60             20             40              0 

Coefficients:
            Estimate Std. error t value  Pr(> t)    
(Intercept)  -0.3656     0.4745  -0.771 0.440936    
x1            1.6800     0.2092   8.030 9.77e-16 ***
x2            2.2405     0.6739   3.325 0.000885 ***
sigmaMu       0.8785     0.2267   3.875 0.000107 ***
sigmaNu       0.9877     0.1281   7.711 1.25e-14 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Newton-Raphson maximisation, 5 iterations
Return code 1: gradient close to zero
Log-likelihood: -73.19882 on 5 Df

> coef( randEff )
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
-0.36562313  1.68000400  2.24054376 -0.12954703 -0.01240809 
> coef( randEff, logSigma = FALSE )
(Intercept)          x1          x2     sigmaMu     sigmaNu 
 -0.3656231   1.6800040   2.2405438   0.8784933   0.9876686 
> vcov( randEff )
             (Intercept)           x1           x2   logSigmaMu   logSigmaNu
(Intercept)  0.225109672 -0.020570168 -0.254602886 -0.023824162 -0.002973952
x1          -0.020570168  0.043773972  0.008562225  0.013404079  0.002969957
x2          -0.254602886  0.008562225  0.454125882  0.017179542  0.001505438
logSigmaMu  -0.023824162  0.013404079  0.017179542  0.066600320 -0.002638871
logSigmaNu  -0.002973952  0.002969957  0.001505438 -0.002638871  0.016819442
> vcov( randEff, logSigma = FALSE )
             (Intercept)           x1           x2      sigmaMu      sigmaNu
(Intercept)  0.225109672 -0.020570168 -0.254602886 -0.020929366 -0.002937279
x1          -0.020570168  0.043773972  0.008562225  0.011775394  0.002933333
x2          -0.254602886  0.008562225  0.454125882  0.015092113  0.001486874
sigmaMu     -0.020929366  0.011775394  0.015092113  0.051398826 -0.002289643
sigmaNu     -0.002937279  0.002933333  0.001486874 -0.002289643  0.016407184
> coef( summary( randEff ) )
               Estimate Std. error     t value      Pr(> t)
(Intercept) -0.36562313  0.4744572 -0.77061344 4.409361e-01
x1           1.68000400  0.2092223  8.02975581 9.766687e-16
x2           2.24054376  0.6738886  3.32479829 8.848252e-04
logSigmaMu  -0.12954703  0.2580704 -0.50198333 6.156793e-01
logSigmaNu  -0.01240809  0.1296898 -0.09567514 9.237786e-01
> coef( summary( randEff ), logSigma = FALSE )
              Estimate Std. error    t value      Pr(> t)
(Intercept) -0.3656231  0.4744572 -0.7706134 4.409361e-01
x1           1.6800040  0.2092223  8.0297558 9.766687e-16
x2           2.2405438  0.6738886  3.3247983 8.848252e-04
sigmaMu      0.8784933  0.2267131  3.8749120 1.066632e-04
sigmaNu      0.9876686  0.1280905  7.7107072 1.251225e-14
> logLik( randEff )
'log Lik.' -73.19882 (df=5)
> extractAIC( randEff )
[1] -40.0000 156.3976
> print.default( randEff )
$maximum
[1] -73.19882

$estimate
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
-0.36562313  1.68000400  2.24054376 -0.12954703 -0.01240809 

$gradient
 (Intercept)           x1           x2   logSigmaMu   logSigmaNu 
1.712496e-11 4.533550e-11 1.345586e-11 8.216677e-12 6.209286e-11 

$hessian
            (Intercept)         x1         x2  logSigmaMu  logSigmaNu
(Intercept)  -13.321985  -4.096607 -7.3075697  -2.1079024  -1.3088177
x1            -4.096607 -26.076787 -1.9905305   4.4849638   4.7620891
x2            -7.307570  -1.990530 -6.2362552  -0.6238251  -0.4803054
logSigmaMu    -2.107902   4.484964 -0.6238251 -16.6582041  -3.7223987
logSigmaNu    -1.308818   4.762089 -0.4803054  -3.7223987 -61.0683413

$code
[1] 1

$message
[1] "gradient close to zero"

$last.step
NULL

$fixed
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
      FALSE       FALSE       FALSE       FALSE       FALSE 

$iterations
[1] 5

$type
[1] "Newton-Raphson maximisation"

$gradientObs
      (Intercept)          x1          x2 logSigmaMu logSigmaNu
 [1,] -0.85308353  0.22558520 -0.07261010 -0.1440032 -0.9609402
 [2,] -1.70309357  0.04839424 -1.18987552  1.6807831 -1.0133141
 [3,]  1.75084247  0.33367482  1.72755770  1.8353812  1.8043727
 [4,]  0.15577733 -0.20240007 -0.43224660 -0.6891081 -1.4351382
 [5,]  0.12950026  0.98433620  0.68943625 -0.6770204 -0.5543803
 [6,]  0.33035909 -0.30928416  0.38471147 -0.4921375 -1.5793716
 [7,] -0.08212549 -3.18521871 -0.23724729 -0.6766315  6.0271932
 [8,] -0.26685300  0.37888544  0.05565473 -0.5385828 -1.1091111
 [9,]  1.14824183  0.59396387  0.30328556  0.1329802 -1.6172740
[10,] -0.43505392 -0.40640593 -0.15245982 -0.4687582 -1.9364984
[11,] -0.02839185  1.44795739 -0.64407731 -0.9172655  2.7349924
[12,]  1.21047881  0.53669833  0.61328528  0.2055542 -1.7351236
[13,]  0.53592707 -0.22523044  0.33117482 -0.3691166 -1.4082834
[14,] -1.81460674 -1.30608969 -0.91950989  1.9573174  2.5815580
[15,] -0.07791875  1.08513351 -0.45707928 -0.8393922  0.2013187

$call
censReg(formula = y ~ x1 + x2, data = pData)

$terms
y ~ x1 + x2
attr(,"variables")
list(y, x1, x2)
attr(,"factors")
   x1 x2
y   0  0
x1  1  0
x2  0  1
attr(,"term.labels")
[1] "x1" "x2"
attr(,"order")
[1] 1 1
attr(,"intercept")
[1] 1
attr(,"response")
[1] 1
attr(,".Environment")
<environment: R_GlobalEnv>
attr(,"predvars")
list(y, x1, x2)
attr(,"dataClasses")
        y        x1        x2 
"numeric" "numeric" "numeric" 

$nObs
         Total  Left-censored     Uncensored Right-censored 
            60             20             40              0 

$df.residual
[1] 55

$start
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
  0.4703506   1.0111600   1.6191826  -0.4962510  -0.0620962 

attr(,"class")
[1] "censReg" "maxLik"  "maxim"   "list"   
> 
> 
> ## BHHH method
> randEffBhhh <- censReg( y ~ x1 + x2, data = pData, method = "BHHH" )
> print( randEffBhhh )

Call:
censReg(formula = y ~ x1 + x2, data = pData, method = "BHHH")

Coefficients:
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
    -0.3656      1.6800      2.2406     -0.1296     -0.0124 

> maxLik:::summary.maxLik( randEffBhhh )
--------------------------------------------
Maximum Likelihood estimation
BHHH maximisation, 18 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -73.19882 
5  free parameters
Estimates:
             Estimate Std. error t value   Pr(> t)    
(Intercept) -0.365635   0.555054 -0.6587  0.510065    
x1           1.680016   0.293775  5.7187 1.073e-08 ***
x2           2.240556   0.729501  3.0714  0.002131 ** 
logSigmaMu  -0.129565   0.295017 -0.4392  0.660531    
logSigmaNu  -0.012402   0.140134 -0.0885  0.929481    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> summary( randEffBhhh )

Call:
censReg(formula = y ~ x1 + x2, data = pData, method = "BHHH")

Observations:
         Total  Left-censored     Uncensored Right-censored 
            60             20             40              0 

Coefficients:
            Estimate Std. error t value  Pr(> t)    
(Intercept)  -0.3656     0.5551  -0.659  0.51006    
x1            1.6800     0.2938   5.719 1.07e-08 ***
x2            2.2406     0.7295   3.071  0.00213 ** 
logSigmaMu   -0.1296     0.2950  -0.439  0.66053    
logSigmaNu   -0.0124     0.1401  -0.088  0.92948    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

BHHH maximisation, 18 iterations
Return code 2: successive function values within tolerance limit
Log-likelihood: -73.19882 on 5 Df

> print.default( randEffBhhh )
$maximum
[1] -73.19882

$estimate
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
-0.36563477  1.68001566  2.24055570 -0.12956535 -0.01240161 

$gradient
  (Intercept)            x1            x2    logSigmaMu    logSigmaNu 
 5.028294e-05 -3.315101e-04 -4.246354e-06  3.505038e-04 -2.626408e-04 

$hessian
            (Intercept)         x1         x2  logSigmaMu logSigmaNu
(Intercept)  -13.482494  -4.096061 -8.3241402   2.7373240   3.959016
x1            -4.096061 -17.395897 -2.1956247   2.0949384  19.029556
x2            -8.324140  -2.195625 -7.3456165  -0.2437129   3.421562
logSigmaMu     2.737324   2.094938 -0.2437129 -13.9308908  -3.639137
logSigmaNu     3.959016  19.029556  3.4215617  -3.6391374 -73.168704
attr(,"type")
[1] "BHHH"

$code
[1] 2

$message
[1] "successive function values within tolerance limit"

$last.step
NULL

$fixed
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
      FALSE       FALSE       FALSE       FALSE       FALSE 

$iterations
[1] 18

$type
[1] "BHHH maximisation"

$gradientObs
      (Intercept)          x1          x2 logSigmaMu logSigmaNu
 [1,] -0.85309912  0.22553991 -0.07262972 -0.1439976 -0.9609756
 [2,] -1.70314125  0.04834913 -1.18991475  1.6808211 -1.0132976
 [3,]  1.75089168  0.33368134  1.72757656  1.8353986  1.8044304
 [4,]  0.15581599 -0.20240761 -0.43221921 -0.6890852 -1.4351543
 [5,]  0.12951232  0.98431668  0.68943033 -0.6770023 -0.5544220
 [6,]  0.33038531 -0.30929737  0.38473066 -0.4921403 -1.5793732
 [7,] -0.08212211 -3.18519652 -0.23724499 -0.6766142  6.0271629
 [8,] -0.26685182  0.37888104  0.05565305 -0.5385702 -1.1091241
 [9,]  1.14826405  0.59392337  0.30329461  0.1330245 -1.6172865
[10,] -0.43507487 -0.40642217 -0.15246997 -0.4687544 -1.9364930
[11,] -0.02840097  1.44793082 -0.64407223 -0.9172307  2.7348842
[12,]  1.21050842  0.53669645  0.61330484  0.2056154 -1.7351598
[13,]  0.53595825 -0.22524780  0.33119153 -0.3691112 -1.4082671
[14,] -1.81465694 -1.30619017 -0.91955280  1.9573642  2.5815611
[15,] -0.07793866  1.08511138 -0.45708215 -0.8393671  0.2012520

$call
censReg(formula = y ~ x1 + x2, data = pData, method = "BHHH")

$terms
y ~ x1 + x2
attr(,"variables")
list(y, x1, x2)
attr(,"factors")
   x1 x2
y   0  0
x1  1  0
x2  0  1
attr(,"term.labels")
[1] "x1" "x2"
attr(,"order")
[1] 1 1
attr(,"intercept")
[1] 1
attr(,"response")
[1] 1
attr(,".Environment")
<environment: R_GlobalEnv>
attr(,"predvars")
list(y, x1, x2)
attr(,"dataClasses")
        y        x1        x2 
"numeric" "numeric" "numeric" 

$nObs
         Total  Left-censored     Uncensored Right-censored 
            60             20             40              0 

$df.residual
[1] 55

$start
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
  0.4703506   1.0111600   1.6191826  -0.4962510  -0.0620962 

attr(,"class")
[1] "censReg" "maxLik"  "maxim"   "list"   
> 
> 
> ## BFGS method (optim)
> randEffBfgs <- censReg( y ~ x1 + x2, data = pData, method = "BFGS" )
> print( randEffBfgs )

Call:
censReg(formula = y ~ x1 + x2, data = pData, method = "BFGS")

Coefficients:
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
   -0.36562     1.68000     2.24055    -0.12955    -0.01241 

> maxLik:::summary.maxLik( randEffBfgs )
--------------------------------------------
Maximum Likelihood estimation
BFGS maximisation, 25 iterations
Return code 0: successful convergence 
Log-Likelihood: -73.19882 
5  free parameters
Estimates:
             Estimate Std. error t value   Pr(> t)    
(Intercept) -0.365624   0.474456 -0.7706 0.4409343    
x1           1.680002   0.209222  8.0298 9.767e-16 ***
x2           2.240551   0.673888  3.3248 0.0008848 ***
logSigmaMu  -0.129549   0.258071 -0.5020 0.6156731    
logSigmaNu  -0.012408   0.129690 -0.0957 0.9237762    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> summary( randEffBfgs )

Call:
censReg(formula = y ~ x1 + x2, data = pData, method = "BFGS")

Observations:
         Total  Left-censored     Uncensored Right-censored 
            60             20             40              0 

Coefficients:
            Estimate Std. error t value  Pr(> t)    
(Intercept) -0.36562    0.47446  -0.771 0.440934    
x1           1.68000    0.20922   8.030 9.77e-16 ***
x2           2.24055    0.67389   3.325 0.000885 ***
logSigmaMu  -0.12955    0.25807  -0.502 0.615673    
logSigmaNu  -0.01241    0.12969  -0.096 0.923776    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

BFGS maximisation, 25 iterations
Return code 0: successful convergence 
Log-likelihood: -73.19882 on 5 Df

> print.default( randEffBfgs )
$maximum
[1] -73.19882

$estimate
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
-0.36562386  1.68000222  2.24055118 -0.12954945 -0.01240847 

$gradient
  (Intercept)            x1            x2    logSigmaMu    logSigmaNu 
-3.160077e-05  2.178336e-05 -3.570719e-05  3.081674e-05  2.108131e-05 

$hessian
            (Intercept)         x1         x2  logSigmaMu logSigmaNu
(Intercept)  -13.322030  -4.096615 -7.3075895  -2.1078505  -1.308810
x1            -4.096615 -26.076823 -1.9905334   4.4849768   4.762042
x2            -7.307589  -1.990533 -6.2362665  -0.6237935  -0.480264
logSigmaMu    -2.107850   4.484977 -0.6237936 -16.6581488  -3.722435
logSigmaNu    -1.308810   4.762042 -0.4802640  -3.7224350 -61.068402

$code
[1] 0

$message
[1] "successful convergence "

$last.step
NULL

$fixed
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
      FALSE       FALSE       FALSE       FALSE       FALSE 

$iterations
function 
      25 

$type
[1] "BFGS maximisation"

$constraints
NULL

$gradientObs
      (Intercept)          x1          x2 logSigmaMu logSigmaNu
 [1,] -0.85308743  0.22558129 -0.07261263 -0.1440013 -0.9609385
 [2,] -1.70310343  0.04839017 -1.18988370  1.6807981 -1.0133093
 [3,]  1.75084680  0.33368182  1.72755839  1.8353799  1.8043672
 [4,]  0.15577623 -0.20239996 -0.43224879 -0.6891122 -1.4351265
 [5,]  0.12949863  0.98433692  0.68943374 -0.6770205 -0.5543875
 [6,]  0.33035850 -0.30927350  0.38470918 -0.4921407 -1.5793728
 [7,] -0.08212636 -3.18521917 -0.23724752 -0.6766300  6.0271888
 [8,] -0.26685580  0.37888651  0.05565314 -0.5385807 -1.1091140
 [9,]  1.14824376  0.59396790  0.30328585  0.1329813 -1.6172723
[10,] -0.43505882 -0.40640593 -0.15246287 -0.4687554 -1.9365001
[11,] -0.02839283  1.44796138 -0.64407965 -0.9172624  2.7350038
[12,]  1.21048230  0.53670265  0.61328478  0.2055557 -1.7351212
[13,]  0.53592379 -0.22522781  0.33117257 -0.3691209 -1.4082845
[14,] -1.81461479 -1.30609804 -0.91951560  1.9573273  2.5815634
[15,] -0.07792214  1.08513754 -0.45708262 -0.8393873  0.2013247

$call
censReg(formula = y ~ x1 + x2, data = pData, method = "BFGS")

$terms
y ~ x1 + x2
attr(,"variables")
list(y, x1, x2)
attr(,"factors")
   x1 x2
y   0  0
x1  1  0
x2  0  1
attr(,"term.labels")
[1] "x1" "x2"
attr(,"order")
[1] 1 1
attr(,"intercept")
[1] 1
attr(,"response")
[1] 1
attr(,".Environment")
<environment: R_GlobalEnv>
attr(,"predvars")
list(y, x1, x2)
attr(,"dataClasses")
        y        x1        x2 
"numeric" "numeric" "numeric" 

$nObs
         Total  Left-censored     Uncensored Right-censored 
            60             20             40              0 

$df.residual
[1] 55

$start
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
  0.4703506   1.0111600   1.6191826  -0.4962510  -0.0620962 

attr(,"class")
[1] "censReg" "maxLik"  "maxim"  
> 
> 
> ## BFGS method (R)
> randEffBfgsr <- censReg( y ~ x1 + x2, data = pData, method = "BFGSR" )
> print( randEffBfgsr )

Call:
censReg(formula = y ~ x1 + x2, data = pData, method = "BFGSR")

Coefficients:
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
   -0.37168     1.68028     2.24993    -0.12900    -0.01238 

> maxLik:::summary.maxLik( randEffBfgsr )
--------------------------------------------
Maximum Likelihood estimation
BFGSR maximization, 75 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -73.19892 
5  free parameters
Estimates:
             Estimate Std. error t value   Pr(> t)    
(Intercept) -0.371684   0.475093 -0.7823 0.4340146    
x1           1.680281   0.209289  8.0285 9.865e-16 ***
x2           2.249932   0.674209  3.3371 0.0008464 ***
logSigmaMu  -0.129001   0.257959 -0.5001 0.6170174    
logSigmaNu  -0.012376   0.129702 -0.0954 0.9239807    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> summary( randEffBfgsr )

Call:
censReg(formula = y ~ x1 + x2, data = pData, method = "BFGSR")

Observations:
         Total  Left-censored     Uncensored Right-censored 
            60             20             40              0 

Coefficients:
            Estimate Std. error t value  Pr(> t)    
(Intercept) -0.37168    0.47509  -0.782 0.434015    
x1           1.68028    0.20929   8.029 9.86e-16 ***
x2           2.24993    0.67421   3.337 0.000846 ***
logSigmaMu  -0.12900    0.25796  -0.500 0.617017    
logSigmaNu  -0.01238    0.12970  -0.095 0.923981    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

BFGSR maximization, 75 iterations
Return code 2: successive function values within tolerance limit
Log-likelihood: -73.19892 on 5 Df

> print.default( randEffBfgsr )
$maximum
[1] -73.19892

$estimate
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
-0.37168420  1.68028110  2.24993180 -0.12900083 -0.01237627 

$gradient
  (Intercept)            x1            x2    logSigmaMu    logSigmaNu 
 0.0097820465  0.0015240964 -0.0151696807 -0.0010168324  0.0009058537 

$hessian
            (Intercept)         x1         x2  logSigmaMu  logSigmaNu
(Intercept)  -13.302432  -4.094560 -7.2998139  -2.1424397  -1.2835034
x1            -4.094560 -26.066728 -1.9879190   4.4805708   4.7584213
x2            -7.299814  -1.987919 -6.2323847  -0.6361526  -0.4346552
logSigmaMu    -2.142440   4.480571 -0.6361526 -16.6890197  -3.7170840
logSigmaNu    -1.283503   4.758421 -0.4346552  -3.7170840 -61.0523527

$code
[1] 2

$message
[1] "successive function values within tolerance limit"

$last.step
NULL

$fixed
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
      FALSE       FALSE       FALSE       FALSE       FALSE 

$iterations
[1] 75

$type
[1] "BFGSR maximization"

$gradientObs
      (Intercept)          x1          x2 logSigmaMu logSigmaNu
 [1,] -0.85174362  0.22314592 -0.07377949 -0.1447996 -0.9697124
 [2,] -1.70285401  0.04616161 -1.19102293  1.6827031 -1.0121997
 [3,]  1.74961116  0.33309964  1.72406001  1.8350630  1.7921112
 [4,]  0.15530909 -0.20351057 -0.43417900 -0.6890965 -1.4253305
 [5,]  0.12996830  0.98246772  0.68672516 -0.6768764 -0.5641044
 [6,]  0.32994691 -0.30459305  0.38342814 -0.4918989 -1.5830341
 [7,] -0.07908143 -3.18644740 -0.23666261 -0.6774114  6.0339826
 [8,] -0.26516856  0.37749947  0.05577413 -0.5392187 -1.1083355
 [9,]  1.14893540  0.59372963  0.30322077  0.1353055 -1.6146651
[10,] -0.43316115 -0.40439666 -0.15191541 -0.4701135 -1.9369952
[11,] -0.02751324  1.45120970 -0.64495163 -0.9188258  2.7450418
[12,]  1.20966750  0.53896735  0.61033012  0.2044905 -1.7326548
[13,]  0.53680992 -0.22536686  0.33118626 -0.3680373 -1.4085882
[14,] -1.81419603 -1.30827442 -0.91998783  1.9588390  2.5758709
[15,] -0.07674819  1.08783200 -0.45739537 -0.8411398  0.2095192

$call
censReg(formula = y ~ x1 + x2, data = pData, method = "BFGSR")

$terms
y ~ x1 + x2
attr(,"variables")
list(y, x1, x2)
attr(,"factors")
   x1 x2
y   0  0
x1  1  0
x2  0  1
attr(,"term.labels")
[1] "x1" "x2"
attr(,"order")
[1] 1 1
attr(,"intercept")
[1] 1
attr(,"response")
[1] 1
attr(,".Environment")
<environment: R_GlobalEnv>
attr(,"predvars")
list(y, x1, x2)
attr(,"dataClasses")
        y        x1        x2 
"numeric" "numeric" "numeric" 

$nObs
         Total  Left-censored     Uncensored Right-censored 
            60             20             40              0 

$df.residual
[1] 55

$start
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
  0.4703506   1.0111600   1.6191826  -0.4962510  -0.0620962 

attr(,"class")
[1] "censReg" "maxLik"  "maxim"   "list"   
> 
> 
> ## BHHH with starting values
> randEffBhhhStart <- censReg( y ~ x1 + x2, data = pData, method = "BHHH",
+    start = c( -0.4, 1.7, 2.2, -0.1, -0.01 ) )
> print( randEffBhhhStart )

Call:
censReg(formula = y ~ x1 + x2, data = pData, start = c(-0.4, 
    1.7, 2.2, -0.1, -0.01), method = "BHHH")

Coefficients:
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
    -0.3657      1.6800      2.2406     -0.1296     -0.0124 

> summary( randEffBhhhStart )

Call:
censReg(formula = y ~ x1 + x2, data = pData, start = c(-0.4, 
    1.7, 2.2, -0.1, -0.01), method = "BHHH")

Observations:
         Total  Left-censored     Uncensored Right-censored 
            60             20             40              0 

Coefficients:
            Estimate Std. error t value  Pr(> t)    
(Intercept)  -0.3657     0.5551  -0.659  0.51003    
x1            1.6800     0.2938   5.719 1.07e-08 ***
x2            2.2406     0.7295   3.071  0.00213 ** 
logSigmaMu   -0.1295     0.2950  -0.439  0.66056    
logSigmaNu   -0.0124     0.1401  -0.088  0.92948    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

BHHH maximisation, 10 iterations
Return code 2: successive function values within tolerance limit
Log-likelihood: -73.19882 on 5 Df

> 
> 
> ## left-censoring at 5
> pData$yAdd <- pData$y + 5
> randEffAdd <- censReg( yAdd ~ x1 + x2, data = pData, method = "BFGSR", left = 5 )
> print( randEffAdd )

Call:
censReg(formula = yAdd ~ x1 + x2, left = 5, data = pData, method = "BFGSR")

Coefficients:
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
     4.6332      1.6801      2.2422     -0.1295     -0.0124 

> maxLik:::summary.maxLik( randEffAdd )
--------------------------------------------
Maximum Likelihood estimation
BFGSR maximization, 92 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -73.19883 
5  free parameters
Estimates:
             Estimate Std. error t value   Pr(> t)    
(Intercept)  4.633247   0.474575  9.7629 < 2.2e-16 ***
x1           1.680066   0.209236  8.0295 9.784e-16 ***
x2           2.242247   0.673947  3.3270 0.0008778 ***
logSigmaMu  -0.129457   0.258054 -0.5017 0.6159024    
logSigmaNu  -0.012402   0.129693 -0.0956 0.9238197    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> summary( randEffAdd )

Call:
censReg(formula = yAdd ~ x1 + x2, left = 5, data = pData, method = "BFGSR")

Observations:
         Total  Left-censored     Uncensored Right-censored 
            60             20             40              0 

Coefficients:
            Estimate Std. error t value  Pr(> t)    
(Intercept)   4.6333     0.4746   9.763  < 2e-16 ***
x1            1.6801     0.2092   8.030 9.78e-16 ***
x2            2.2422     0.6740   3.327 0.000878 ***
logSigmaMu   -0.1295     0.2581  -0.502 0.615902    
logSigmaNu   -0.0124     0.1297  -0.096 0.923820    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

BFGSR maximization, 92 iterations
Return code 2: successive function values within tolerance limit
Log-likelihood: -73.19883 on 5 Df

> coef( randEffAdd )
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
 4.63324665  1.68006583  2.24224732 -0.12945712 -0.01240166 
> coef( randEffAdd, logSigma = FALSE )
(Intercept)          x1          x2     sigmaMu     sigmaNu 
  4.6332467   1.6800658   2.2422473   0.8785723   0.9876749 
> vcov( randEffAdd )
             (Intercept)           x1           x2   logSigmaMu   logSigmaNu
(Intercept)  0.225221105 -0.020596783 -0.254693338 -0.023884381 -0.002991826
x1          -0.020596783  0.043779537  0.008589306  0.013408570  0.002970130
x2          -0.254693338  0.008589306  0.454205222  0.017216289  0.001548624
logSigmaMu  -0.023884381  0.013408570  0.017216289  0.066592030 -0.002636315
logSigmaNu  -0.002991826  0.002970130  0.001548624 -0.002636315  0.016820196
> vcov( randEffAdd, logSigma = FALSE )
             (Intercept)           x1           x2      sigmaMu      sigmaNu
(Intercept)  0.225221105 -0.020596783 -0.254693338 -0.020984154 -0.002954952
x1          -0.020596783  0.043779537  0.008589306  0.011780397  0.002933523
x2          -0.254693338  0.008589306  0.454205222  0.015125754  0.001529537
sigmaMu     -0.020984154  0.011780397  0.015125754  0.051401670 -0.002287646
sigmaNu     -0.002954952  0.002933523  0.001529537 -0.002287646  0.016408131
> logLik( randEffAdd )
'log Lik.' -73.19883 (df=5)
> extractAIC( randEffAdd )
[1] -40.0000 156.3977
> print.default( randEffAdd )
$maximum
[1] -73.19883

$estimate
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
 4.63324665  1.68006583  2.24224732 -0.12945712 -0.01240166 

$gradient
  (Intercept)            x1            x2    logSigmaMu    logSigmaNu 
 2.155546e-03  6.059722e-05 -2.547218e-03  7.693342e-05  2.323640e-04 

$hessian
            (Intercept)         x1         x2  logSigmaMu  logSigmaNu
(Intercept)  -13.318767  -4.096320 -7.3063579  -2.1148981  -1.3044776
x1            -4.096320 -26.074867 -1.9901000   4.4840836   4.7617543
x2            -7.306358  -1.990100 -6.2356647  -0.6264024  -0.4722413
logSigmaMu    -2.114898   4.484084 -0.6264024 -16.6636526  -3.7220905
logSigmaNu    -1.304478   4.761754 -0.4722413  -3.7220905 -61.0651061

$code
[1] 2

$message
[1] "successive function values within tolerance limit"

$last.step
NULL

$fixed
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
      FALSE       FALSE       FALSE       FALSE       FALSE 

$iterations
[1] 92

$type
[1] "BFGSR maximization"

$gradientObs
      (Intercept)          x1          x2 logSigmaMu logSigmaNu
 [1,] -0.85282731  0.22514193 -0.07282008 -0.1441620 -0.9625735
 [2,] -1.70305051  0.04797308 -1.19008651  1.6810867 -1.0131152
 [3,]  1.75068732  0.33356958  1.72696334  1.8354278  1.8022493
 [4,]  0.15574056 -0.20261062 -0.43256804 -0.6890532 -1.4333910
 [5,]  0.12961584  0.98398362  0.68895838 -0.6769720 -0.5561547
 [6,]  0.33033491 -0.30844383  0.38451605 -0.4920574 -1.5800340
 [7,] -0.08155106 -3.18545701 -0.23713732 -0.6767708  6.0284926
 [8,] -0.26652416  0.37862046  0.05568521 -0.5387016 -1.1089630
 [9,]  1.14839504  0.59388626  0.30328426  0.1334570 -1.6167913
[10,] -0.43469213 -0.40604378 -0.15235022 -0.4690274 -1.9365739
[11,] -0.02822775  1.44853937 -0.64422984 -0.9175445  2.7367786
[12,]  1.21034641  0.53710484  0.61276142  0.2054305 -1.7347030
[13,]  0.53614796 -0.22529137  0.33121077 -0.3688837 -1.4083057
[14,] -1.81454073 -1.30652509 -0.91960576  1.9575716  2.5805249
[15,] -0.07769883  1.08561316 -0.45712888 -0.8397241  0.2027923

$call
censReg(formula = yAdd ~ x1 + x2, left = 5, data = pData, method = "BFGSR")

$terms
yAdd ~ x1 + x2
attr(,"variables")
list(yAdd, x1, x2)
attr(,"factors")
     x1 x2
yAdd  0  0
x1    1  0
x2    0  1
attr(,"term.labels")
[1] "x1" "x2"
attr(,"order")
[1] 1 1
attr(,"intercept")
[1] 1
attr(,"response")
[1] 1
attr(,".Environment")
<environment: R_GlobalEnv>
attr(,"predvars")
list(yAdd, x1, x2)
attr(,"dataClasses")
     yAdd        x1        x2 
"numeric" "numeric" "numeric" 

$nObs
         Total  Left-censored     Uncensored Right-censored 
            60             20             40              0 

$df.residual
[1] 55

$start
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
  5.4703506   1.0111600   1.6191826  -0.4962510  -0.0620962 

attr(,"class")
[1] "censReg" "maxLik"  "maxim"   "list"   
> 
> 
> ## right-censoring
> pData$yNeg <- - pData$y
> randEffNeg <- censReg( yNeg ~ x1 + x2, data = pData, method = "BFGSR",
+    left = -Inf, right = 0 )
> print( randEffNeg )

Call:
censReg(formula = yNeg ~ x1 + x2, left = -Inf, right = 0, data = pData, 
    method = "BFGSR")

Coefficients:
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
    0.37168    -1.68028    -2.24993    -0.12900    -0.01238 

> maxLik:::summary.maxLik( randEffNeg )
--------------------------------------------
Maximum Likelihood estimation
BFGSR maximization, 75 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -73.19892 
5  free parameters
Estimates:
             Estimate Std. error t value   Pr(> t)    
(Intercept)  0.371684   0.475093  0.7823 0.4340146    
x1          -1.680281   0.209289 -8.0285 9.865e-16 ***
x2          -2.249932   0.674209 -3.3371 0.0008464 ***
logSigmaMu  -0.129001   0.257959 -0.5001 0.6170173    
logSigmaNu  -0.012376   0.129702 -0.0954 0.9239807    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> summary( randEffNeg )

Call:
censReg(formula = yNeg ~ x1 + x2, left = -Inf, right = 0, data = pData, 
    method = "BFGSR")

Observations:
         Total  Left-censored     Uncensored Right-censored 
            60              0             40             20 

Coefficients:
            Estimate Std. error t value  Pr(> t)    
(Intercept)  0.37168    0.47509   0.782 0.434015    
x1          -1.68028    0.20929  -8.029 9.86e-16 ***
x2          -2.24993    0.67421  -3.337 0.000846 ***
logSigmaMu  -0.12900    0.25796  -0.500 0.617017    
logSigmaNu  -0.01238    0.12970  -0.095 0.923981    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

BFGSR maximization, 75 iterations
Return code 2: successive function values within tolerance limit
Log-likelihood: -73.19892 on 5 Df

> coef( randEffNeg )
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
 0.37168419 -1.68028108 -2.24993181 -0.12900084 -0.01237627 
> coef( randEffNeg, logSigma = FALSE )
(Intercept)          x1          x2     sigmaMu     sigmaNu 
  0.3716842  -1.6802811  -2.2499318   0.8789732   0.9877000 
> vcov( randEffNeg )
             (Intercept)           x1           x2   logSigmaMu   logSigmaNu
(Intercept)  0.225713077 -0.020709715 -0.255088423  0.024127578  0.003074236
x1          -0.020709715  0.043801797  0.008707984 -0.013424829 -0.002969946
x2          -0.255088423  0.008707984  0.454557714 -0.017368517 -0.001747796
logSigmaMu   0.024127578 -0.013424829 -0.017368517  0.066543032 -0.002621464
logSigmaNu   0.003074236 -0.002969946 -0.001747796 -0.002621464  0.016822653
> vcov( randEffNeg, logSigma = FALSE )
             (Intercept)           x1           x2      sigmaMu      sigmaNu
(Intercept)  0.225713077 -0.020709715 -0.255088423  0.021207495  0.003036423
x1          -0.020709715  0.043801797  0.008707984 -0.011800065 -0.002933415
x2          -0.255088423  0.008707984  0.454557714 -0.015266462 -0.001726298
sigmaMu      0.021207495 -0.011800065 -0.015266462  0.051410743 -0.002275855
sigmaNu      0.003036423 -0.002933415 -0.001726298 -0.002275855  0.016411361
> logLik( randEffNeg )
'log Lik.' -73.19892 (df=5)
> extractAIC( randEffNeg )
[1] -40.0000 156.3978
> print.default( randEffNeg )
$maximum
[1] -73.19892

$estimate
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
 0.37168419 -1.68028108 -2.24993181 -0.12900084 -0.01237627 

$gradient
  (Intercept)            x1            x2    logSigmaMu    logSigmaNu 
-0.0097818998 -0.0015245430  0.0151698070 -0.0010167759  0.0009057122 

$hessian
            (Intercept)         x1         x2  logSigmaMu  logSigmaNu
(Intercept)  -13.302432  -4.094560 -7.2998140   2.1424393   1.2835036
x1            -4.094560 -26.066728 -1.9879190  -4.4805709  -4.7584205
x2            -7.299814  -1.987919 -6.2323847   0.6361524   0.4346552
logSigmaMu     2.142439  -4.480571  0.6361524 -16.6890193  -3.7170841
logSigmaNu     1.283504  -4.758421  0.4346552  -3.7170841 -61.0523527

$code
[1] 2

$message
[1] "successive function values within tolerance limit"

$last.step
NULL

$fixed
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
      FALSE       FALSE       FALSE       FALSE       FALSE 

$iterations
[1] 75

$type
[1] "BFGSR maximization"

$gradientObs
      (Intercept)          x1          x2 logSigmaMu logSigmaNu
 [1,]  0.85174362 -0.22314593  0.07377949 -0.1447996 -0.9697123
 [2,]  1.70285405 -0.04616162  1.19102295  1.6827031 -1.0121997
 [3,] -1.74961118 -0.33309971 -1.72406001  1.8350630  1.7921111
 [4,] -0.15530909  0.20351055  0.43417900 -0.6890965 -1.4253305
 [5,] -0.12996829 -0.98246774 -0.68672515 -0.6768764 -0.5641044
 [6,] -0.32994691  0.30459295 -0.38342812 -0.4918989 -1.5830341
 [7,]  0.07908144  3.18644736  0.23666261 -0.6774114  6.0339824
 [8,]  0.26516858 -0.37749949 -0.05577412 -0.5392187 -1.1083355
 [9,] -1.14893540 -0.59372968 -0.30322077  0.1353055 -1.6146651
[10,]  0.43316117  0.40439664  0.15191542 -0.4701135 -1.9369952
[11,]  0.02751325 -1.45120972  0.64495164 -0.9188258  2.7450418
[12,] -1.20966751 -0.53896737 -0.61033013  0.2044905 -1.7326548
[13,] -0.53680988  0.22536683 -0.33118624 -0.3680374 -1.4085882
[14,]  1.81419605  1.30827440  0.91998784  1.9588390  2.5758709
[15,]  0.07674821 -1.08783202  0.45739539 -0.8411398  0.2095193

$call
censReg(formula = yNeg ~ x1 + x2, left = -Inf, right = 0, data = pData, 
    method = "BFGSR")

$terms
yNeg ~ x1 + x2
attr(,"variables")
list(yNeg, x1, x2)
attr(,"factors")
     x1 x2
yNeg  0  0
x1    1  0
x2    0  1
attr(,"term.labels")
[1] "x1" "x2"
attr(,"order")
[1] 1 1
attr(,"intercept")
[1] 1
attr(,"response")
[1] 1
attr(,".Environment")
<environment: R_GlobalEnv>
attr(,"predvars")
list(yNeg, x1, x2)
attr(,"dataClasses")
     yNeg        x1        x2 
"numeric" "numeric" "numeric" 

$nObs
         Total  Left-censored     Uncensored Right-censored 
            60              0             40             20 

$df.residual
[1] 55

$start
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
 -0.4703506  -1.0111600  -1.6191826  -0.4962510  -0.0620962 

attr(,"class")
[1] "censReg" "maxLik"  "maxim"   "list"   
> 
> 
> ## right-censoring at -5
> pData$yAddNeg <- - pData$yAdd
> randEffAddNeg <- censReg( yAddNeg ~ x1 + x2, data = pData, method = "BFGSR",
+    left = -Inf, right = -5 )
> print( randEffAddNeg )

Call:
censReg(formula = yAddNeg ~ x1 + x2, left = -Inf, right = -5, 
    data = pData, method = "BFGSR")

Coefficients:
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
   -4.62779    -1.68067    -2.24971    -0.12825    -0.01244 

> maxLik:::summary.maxLik( randEffAddNeg )
--------------------------------------------
Maximum Likelihood estimation
BFGSR maximization, 70 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -73.19893 
5  free parameters
Estimates:
             Estimate Std. error t value   Pr(> t)    
(Intercept) -4.627785   0.475359 -9.7354 < 2.2e-16 ***
x1          -1.680675   0.209310 -8.0296 9.779e-16 ***
x2          -2.249707   0.674265 -3.3365 0.0008483 ***
logSigmaMu  -0.128246   0.257783 -0.4975 0.6188395    
logSigmaNu  -0.012445   0.129694 -0.0960 0.9235564    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> summary( randEffAddNeg )

Call:
censReg(formula = yAddNeg ~ x1 + x2, left = -Inf, right = -5, 
    data = pData, method = "BFGSR")

Observations:
         Total  Left-censored     Uncensored Right-censored 
            60              0             40             20 

Coefficients:
            Estimate Std. error t value  Pr(> t)    
(Intercept) -4.62779    0.47536  -9.735  < 2e-16 ***
x1          -1.68067    0.20931  -8.030 9.78e-16 ***
x2          -2.24971    0.67427  -3.337 0.000848 ***
logSigmaMu  -0.12825    0.25778  -0.497 0.618840    
logSigmaNu  -0.01244    0.12969  -0.096 0.923556    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

BFGSR maximization, 70 iterations
Return code 2: successive function values within tolerance limit
Log-likelihood: -73.19893 on 5 Df

> coef( randEffAddNeg )
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
-4.62778519 -1.68067482 -2.24970713 -0.12824569 -0.01244478 
> coef( randEffAddNeg, logSigma = FALSE )
(Intercept)          x1          x2     sigmaMu     sigmaNu 
 -4.6277852  -1.6806748  -2.2497071   0.8796372   0.9876323 
> vcov( randEffAddNeg )
            (Intercept)           x1           x2   logSigmaMu   logSigmaNu
(Intercept)  0.22596589 -0.020745239 -0.255219770  0.024192048  0.003065220
x1          -0.02074524  0.043810598  0.008720891 -0.013417790 -0.002980416
x2          -0.25521977  0.008720891  0.454633491 -0.017362209 -0.001734718
logSigmaMu   0.02419205 -0.013417790 -0.017362209  0.066451823 -0.002597771
logSigmaNu   0.00306522 -0.002980416 -0.001734718 -0.002597771  0.016820544
> vcov( randEffAddNeg, logSigma = FALSE )
            (Intercept)           x1           x2      sigmaMu      sigmaNu
(Intercept)  0.22596589 -0.020745239 -0.255219770  0.021280226  0.003027310
x1          -0.02074524  0.043810598  0.008720891 -0.011802788 -0.002943555
x2          -0.25521977  0.008720891  0.454633491 -0.015272445 -0.001713263
sigmaMu      0.02128023 -0.011802788 -0.015272445  0.051417873 -0.002256835
sigmaNu      0.00302731 -0.002943555 -0.001713263 -0.002256835  0.016407056
> logLik( randEffAddNeg )
'log Lik.' -73.19893 (df=5)
> extractAIC( randEffAddNeg )
[1] -40.0000 156.3979
> print.default( randEffAddNeg )
$maximum
[1] -73.19893

$estimate
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
-4.62778519 -1.68067482 -2.24970713 -0.12824569 -0.01244478 

$gradient
 (Intercept)           x1           x2   logSigmaMu   logSigmaNu 
-0.015328816  0.003063483  0.011134048 -0.010327072  0.004939969 

$hessian
            (Intercept)         x1         x2  logSigmaMu  logSigmaNu
(Intercept)  -13.286273  -4.092761 -7.2929015   2.1549741   1.2766662
x1            -4.092761 -26.064045 -1.9868281  -4.4783429  -4.7689766
x2            -7.292901  -1.986828 -6.2292928   0.6432353   0.4338555
logSigmaMu     2.154974  -4.478343  0.6432353 -16.7139063  -3.7011805
logSigmaNu     1.276666  -4.768977  0.4338555  -3.7011805 -61.0556338

$code
[1] 2

$message
[1] "successive function values within tolerance limit"

$last.step
NULL

$fixed
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
      FALSE       FALSE       FALSE       FALSE       FALSE 

$iterations
[1] 70

$type
[1] "BFGSR maximization"

$gradientObs
      (Intercept)          x1          x2 logSigmaMu logSigmaNu
 [1,]  0.85090950 -0.22377695  0.07338671 -0.1451295 -0.9707984
 [2,]  1.70051826 -0.04690529  1.18931179  1.6800443 -1.0132199
 [3,] -1.74795899 -0.33095218 -1.72325930  1.8349426  1.7912806
 [4,] -0.15488388  0.20370565  0.43451660 -0.6886591 -1.4256329
 [5,] -0.13017176 -0.98218200 -0.68691748 -0.6770767 -0.5635698
 [6,] -0.32942407  0.30662763 -0.38341901 -0.4914201 -1.5828822
 [7,]  0.07856172  3.18753489  0.23662047 -0.6780546  6.0383062
 [8,]  0.26437148 -0.37710217 -0.05612481 -0.5399004 -1.1074528
 [9,] -1.14843682 -0.59312783 -0.30306088  0.1349108 -1.6145664
[10,]  0.43186136  0.40424777  0.15118659 -0.4707442 -1.9365660
[11,]  0.02712560 -1.45122706  0.64472118 -0.9200842  2.7458834
[12,] -1.20851835 -0.53841264 -0.60978947  0.2031400 -1.7322261
[13,] -0.53727967  0.22581633 -0.33147792 -0.3670498 -1.4084202
[14,]  1.81230487  1.30653345  0.91866787  1.9573788  2.5744977
[15,]  0.07569193 -1.08771610  0.45677170 -0.8426250  0.2103066

$call
censReg(formula = yAddNeg ~ x1 + x2, left = -Inf, right = -5, 
    data = pData, method = "BFGSR")

$terms
yAddNeg ~ x1 + x2
attr(,"variables")
list(yAddNeg, x1, x2)
attr(,"factors")
        x1 x2
yAddNeg  0  0
x1       1  0
x2       0  1
attr(,"term.labels")
[1] "x1" "x2"
attr(,"order")
[1] 1 1
attr(,"intercept")
[1] 1
attr(,"response")
[1] 1
attr(,".Environment")
<environment: R_GlobalEnv>
attr(,"predvars")
list(yAddNeg, x1, x2)
attr(,"dataClasses")
  yAddNeg        x1        x2 
"numeric" "numeric" "numeric" 

$nObs
         Total  Left-censored     Uncensored Right-censored 
            60              0             40             20 

$df.residual
[1] 55

$start
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
 -5.4703506  -1.0111600  -1.6191826  -0.4962510  -0.0620962 

attr(,"class")
[1] "censReg" "maxLik"  "maxim"   "list"   
> 
> 
> ## both right and left censoring
> pData$yBoth <- ifelse( pData$y < 3, pData$y, 3 )
> randEffBoth <- censReg( yBoth ~ x1 + x2, data = pData, method = "BFGSR",
+    left = 0, right = 3 )
> print( randEffBoth )

Call:
censReg(formula = yBoth ~ x1 + x2, left = 0, right = 3, data = pData, 
    method = "BFGSR")

Coefficients:
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
  -0.233123    1.893345    1.968169    0.001836    0.052662 

> maxLik:::summary.maxLik( randEffBoth )
--------------------------------------------
Maximum Likelihood estimation
BFGSR maximization, 94 iterations
Return code 3: Last step could not find a value above the current.
Boundary of parameter space?  
Consider switching to a more robust optimisation method temporarily.
Log-Likelihood: -64.31274 
5  free parameters
Estimates:
              Estimate Std. error t value  Pr(> t)    
(Intercept) -0.2331227  0.5483148 -0.4252  0.67072    
x1           1.8933449  0.3010918  6.2883 3.21e-10 ***
x2           1.9681686  0.8186375  2.4042  0.01621 *  
logSigmaMu   0.0018361  0.2777643  0.0066  0.99473    
logSigmaNu   0.0526617  0.1629837  0.3231  0.74661    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> summary( randEffBoth )

Call:
censReg(formula = yBoth ~ x1 + x2, left = 0, right = 3, data = pData, 
    method = "BFGSR")

Observations:
         Total  Left-censored     Uncensored Right-censored 
            60             20             28             12 

Coefficients:
             Estimate Std. error t value  Pr(> t)    
(Intercept) -0.233123   0.548315  -0.425   0.6707    
x1           1.893345   0.301092   6.288 3.21e-10 ***
x2           1.968169   0.818637   2.404   0.0162 *  
logSigmaMu   0.001836   0.277764   0.007   0.9947    
logSigmaNu   0.052662   0.162984   0.323   0.7466    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

BFGSR maximization, 94 iterations
Return code 3: Last step could not find a value above the current.
Boundary of parameter space?  
Consider switching to a more robust optimisation method temporarily.
Log-likelihood: -64.31274 on 5 Df

> print( summary( randEffBoth ), logSigma = FALSE )

Call:
censReg(formula = yBoth ~ x1 + x2, left = 0, right = 3, data = pData, 
    method = "BFGSR")

Observations:
         Total  Left-censored     Uncensored Right-censored 
            60             20             28             12 

Coefficients:
            Estimate Std. error t value  Pr(> t)    
(Intercept)  -0.2331     0.5483  -0.425 0.670718    
x1            1.8933     0.3011   6.288 3.21e-10 ***
x2            1.9682     0.8186   2.404 0.016208 *  
sigmaMu       1.0018     0.2783   3.600 0.000318 ***
sigmaNu       1.0541     0.1718   6.136 8.48e-10 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

BFGSR maximization, 94 iterations
Return code 3: Last step could not find a value above the current.
Boundary of parameter space?  
Consider switching to a more robust optimisation method temporarily.
Log-likelihood: -64.31274 on 5 Df

> coef( randEffBoth )
 (Intercept)           x1           x2   logSigmaMu   logSigmaNu 
-0.233122739  1.893344896  1.968168567  0.001836088  0.052661746 
> coef( randEffBoth, logSigma = FALSE )
(Intercept)          x1          x2     sigmaMu     sigmaNu 
 -0.2331227   1.8933449   1.9681686   1.0018378   1.0540730 
> vcov( randEffBoth )
            (Intercept)          x1          x2   logSigmaMu   logSigmaNu
(Intercept)  0.30064911 -0.03136477 -0.36392982 -0.015924074 -0.016357221
x1          -0.03136477  0.09065626  0.03175307  0.035185986  0.015930266
x2          -0.36392982  0.03175307  0.67016733  0.018589204  0.024438158
logSigmaMu  -0.01592407  0.03518599  0.01858920  0.077153015  0.004354154
logSigmaNu  -0.01635722  0.01593027  0.02443816  0.004354154  0.026563687
> vcov( randEffBoth, logSigma = FALSE )
            (Intercept)          x1          x2      sigmaMu      sigmaNu
(Intercept)  0.30064911 -0.03136477 -0.36392982 -0.015953338 -0.017241706
x1          -0.03136477  0.09065626  0.03175307  0.035250650  0.016791663
x2          -0.36392982  0.03175307  0.67016733  0.018623366  0.025759603
sigmaMu     -0.01595334  0.03525065  0.01862337  0.077436855  0.004598031
sigmaNu     -0.01724171  0.01679166  0.02575960  0.004598031  0.029514115
> coef( summary( randEffBoth ) )
                Estimate Std. error      t value      Pr(> t)
(Intercept) -0.233122739  0.5483148 -0.425162231 6.707184e-01
x1           1.893344896  0.3010918  6.288265019 3.210335e-10
x2           1.968168567  0.8186375  2.404200397 1.620789e-02
logSigmaMu   0.001836088  0.2777643  0.006610238 9.947258e-01
logSigmaNu   0.052661746  0.1629837  0.323110503 7.466116e-01
> coef( summary( randEffBoth ), logSigma = FALSE )
              Estimate Std. error    t value      Pr(> t)
(Intercept) -0.2331227  0.5483148 -0.4251622 6.707184e-01
x1           1.8933449  0.3010918  6.2882650 3.210335e-10
x2           1.9681686  0.8186375  2.4042004 1.620789e-02
sigmaMu      1.0018378  0.2782748  3.6001745 3.180037e-04
sigmaNu      1.0540730  0.1717967  6.1355828 8.484756e-10
> logLik( randEffBoth )
'log Lik.' -64.31274 (df=5)
> extractAIC( randEffBoth )
[1] -40.0000 138.6255
> print.default( randEffBoth )
$maximum
[1] -64.31274

$estimate
 (Intercept)           x1           x2   logSigmaMu   logSigmaNu 
-0.233122739  1.893344896  1.968168567  0.001836088  0.052661746 

$gradient
 (Intercept)           x1           x2   logSigmaMu   logSigmaNu 
-0.001884191 -0.003277903  0.005194190 -0.001184273  0.004673679 

$hessian
            (Intercept)          x1         x2   logSigmaMu  logSigmaNu
(Intercept) -9.92503186  -1.4904572 -5.3052425  -0.07216323  -0.3251808
x1          -1.49045723 -15.1408725 -0.5449715   6.29807404   7.6312332
x2          -5.30524245  -0.5449715 -4.3906896   0.15079881   1.0746354
logSigmaMu  -0.07216323   6.2980740  0.1507988 -15.80748586  -1.3690642
logSigmaNu  -0.32518078   7.6312332  1.0746354  -1.36906424 -43.1863094

$code
[1] 3

$message
[1] "Last step could not find a value above the current.\nBoundary of parameter space?  \nConsider switching to a more robust optimisation method temporarily."

$last.step
$last.step$theta0
 (Intercept)           x1           x2   logSigmaMu   logSigmaNu 
-0.233112922  1.893254643  1.968172992  0.001848636  0.052949941 

$last.step$f0
[1] -64.31274
attr(,"gradient")
             [,1]        [,2]        [,3]        [,4]       [,5]
 [1,] -0.85368277 -0.10560043 -0.18114264 -0.02392748 -0.8371164
 [2,] -1.41582667 -0.02618016 -0.97100987  1.45496296 -1.1648037
 [3,]  1.29694996  1.02112849  0.92527957  1.09169349  0.1537995
 [4,]  0.07080471 -0.25178004 -0.39790599 -0.70143471 -1.8283483
 [5,]  0.08914300  0.80762597  0.64778196 -0.69075068 -0.2839328
 [6,]  0.55926747  0.49451360  0.42899520 -0.29125438 -0.3606901
 [7,] -0.12052554 -3.06016491 -0.23664241 -0.70631672  6.3400543
 [8,] -0.20970129  0.33565196  0.08330277 -0.59066905 -1.0294995
 [9,]  1.03385072  0.66030938  0.28820502  0.19649094 -1.2972767
[10,] -0.42788403 -0.58522103 -0.11711670 -0.39595405 -1.8009923
[11,] -0.04063760  1.09436785 -0.50788491 -0.86686053  1.9995620
[12,]  1.13992020  0.50483443  0.83225977  0.58488203 -0.7450382
[13,]  0.53447844 -0.28152402  0.34774212 -0.28664897 -1.4342469
[14,] -1.63712432 -1.34595974 -0.83732735  2.11822793  2.7627702
[15,] -0.02099748  0.73834760 -0.29905319 -0.89478635 -0.4827146

$last.step$climb
[1]   168648.74 -1550526.36    76028.19   215571.41  4951143.78


$fixed
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
      FALSE       FALSE       FALSE       FALSE       FALSE 

$iterations
[1] 94

$type
[1] "BFGSR maximization"

$gradientObs
      (Intercept)          x1          x2  logSigmaMu logSigmaNu
 [1,] -0.85399535 -0.10575069 -0.18125064 -0.02373537 -0.8368361
 [2,] -1.41587302 -0.02627202 -0.97109746  1.45518426 -1.1648897
 [3,]  1.29711332  1.02096366  0.92538811  1.09202104  0.1539853
 [4,]  0.07048706 -0.25194713 -0.39836450 -0.70145841 -1.8275690
 [5,]  0.08915248  0.80759819  0.64799503 -0.69088289 -0.2834983
 [6,]  0.55927600  0.49427315  0.42911754 -0.29119460 -0.3598842
 [7,] -0.12046852 -3.06218288 -0.23676709 -0.70652636  6.3454557
 [8,] -0.20957364  0.33557736  0.08337209 -0.59086644 -1.0292384
 [9,]  1.03399912  0.66031288  0.28823933  0.19651389 -1.2971303
[10,] -0.42793526 -0.58568845 -0.11708559 -0.39576894 -1.8004934
[11,] -0.04041234  1.09485495 -0.50795682 -0.86710722  2.0010778
[12,]  1.13979703  0.50489045  0.83223796  0.58464277 -0.7446872
[13,]  0.53478710 -0.28185901  0.34794282 -0.28626504 -1.4336866
[14,] -1.63754324 -1.34674928 -0.83755339  2.11941053  2.7637700
[15,] -0.02069494  0.73870091 -0.29902321 -0.89515149 -0.4817019

$call
censReg(formula = yBoth ~ x1 + x2, left = 0, right = 3, data = pData, 
    method = "BFGSR")

$terms
yBoth ~ x1 + x2
attr(,"variables")
list(yBoth, x1, x2)
attr(,"factors")
      x1 x2
yBoth  0  0
x1     1  0
x2     0  1
attr(,"term.labels")
[1] "x1" "x2"
attr(,"order")
[1] 1 1
attr(,"intercept")
[1] 1
attr(,"response")
[1] 1
attr(,".Environment")
<environment: R_GlobalEnv>
attr(,"predvars")
list(yBoth, x1, x2)
attr(,"dataClasses")
    yBoth        x1        x2 
"numeric" "numeric" "numeric" 

$nObs
         Total  Left-censored     Uncensored Right-censored 
            60             20             28             12 

$df.residual
[1] 55

$start
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
  0.6056357   0.8113032   1.0023997  -0.7545646  -0.2748137 

attr(,"class")
[1] "censReg" "maxLik"  "maxim"   "list"   
> 
> 
> ## re-order observations/individuals
> set.seed( 234 )
> perm <- sample( nId )
> nData2 <- nData
> nData2$id <- NA
> for( i in 1:nId ) {
+    nData2$id[ nData$id == paste( "F", i, sep = "_" ) ] <-
+       paste( "G", perm[ i ], sep = "_" )
+ }
> pData2 <- pdata.frame( nData2, c( "id", "time" ) )
> randEffBfgsr2 <- censReg( y ~ x1 + x2, data = pData2, method = "BFGSR" )
> all.equal( randEffBfgsr2[ -c(11,12) ], randEffBfgsr[ -c(11,12) ] )
[1] "Component 1: Mean relative difference: 7.675664e-07"
[2] "Component 2: Mean relative difference: 0.001248174" 
[3] "Component 3: Mean relative difference: 0.6277227"   
[4] "Component 4: Mean relative difference: 0.0007419868"
[5] "Component 9: Mean relative difference: 0.03846154"  
> all.equal( sort( randEffBfgsr2[[ 11 ]] ), sort( randEffBfgsr[[ 11 ]] ) )
[1] "Mean relative difference: 0.0007699032"
> 
> # check if the order of observations/individuals influences the likelihood values
> d1c1 <- censReg( y ~ x1 + x2, data = pData, method = "BFGSR", start = coef(randEffBfgsr),
+    iterlim = 0 )
> all.equal( d1c1[-c(5,6,9,12,16)], randEffBfgsr[-c(5,6,9,12,16)] )
[1] TRUE
> d1c1$maximum -  randEffBfgsr$maximum
[1] 0
> 
> d2c2 <- censReg( y ~ x1 + x2, data = pData2, method = "BFGSR", start = coef(randEffBfgsr2),
+    iterlim = 0 )
> all.equal( d2c2[-c(5,6,9,12,16)], randEffBfgsr2[-c(5,6,9,12,16)] )
[1] TRUE
> d2c2$maximum -  randEffBfgsr2$maximum
[1] 0
> 
> d1c2 <- censReg( y ~ x1 + x2, data = pData, method = "BFGSR", 
+    start = coef(randEffBfgsr2), iterlim = 0 )
> d2c2$maximum - d1c2$maximum
[1] 0
> d2c2$gradient - d1c2$gradient
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
          0           0           0           0           0 
> 
> d2c1 <- censReg( y ~ x1 + x2, data = pData2, method = "BFGSR", 
+    start = coef(randEffBfgsr), iterlim = 0 )
> d1c1$maximum - d2c1$maximum
[1] 0
> d1c1$gradient - d2c1$gradient
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
          0           0           0           0           0 
> 
> d2c2$maximum - d2c1$maximum
[1] 5.618499e-05
> d1c1$maximum - d1c2$maximum
[1] -5.618499e-05
> 
> d1cS <- censReg( y ~ x1 + x2, data = pData, method = "BFGSR", 
+    start = randEffBfgsr$start, iterlim = 0 )
> d2cS <- censReg( y ~ x1 + x2, data = pData2, method = "BFGSR", 
+    start = randEffBfgsr$start, iterlim = 0 )
> d1cS$maximum - d2cS$maximum
[1] 0
> d1cS$gradient - d2cS$gradient
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
          0           0           0           0           0 
> 
> 
> ## unbalanced panel data
> nDataUnb <- nData[ -c( 2, 5, 6, 8 ), ]
> pDataUnb <- pdata.frame( nDataUnb, c( "id", "time" ) )
> randEffBfgsrUnb <- censReg( y ~ x1 + x2, data = pDataUnb, method = "BFGSR" )
> print( randEffBfgsrUnb )

Call:
censReg(formula = y ~ x1 + x2, data = pDataUnb, method = "BFGSR")

Coefficients:
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
  -0.221521    1.640492    2.106462   -0.167685   -0.001704 

> maxLik:::summary.maxLik( randEffBfgsrUnb )
--------------------------------------------
Maximum Likelihood estimation
BFGSR maximization, 82 iterations
Return code 3: Last step could not find a value above the current.
Boundary of parameter space?  
Consider switching to a more robust optimisation method temporarily.
Log-Likelihood: -71.1926 
5  free parameters
Estimates:
              Estimate Std. error t value  Pr(> t)    
(Intercept) -0.2215211  0.4722495 -0.4691 0.639015    
x1           1.6404921  0.2109433  7.7769 7.43e-15 ***
x2           2.1064621  0.6844628  3.0775 0.002087 ** 
logSigmaMu  -0.1676852  0.2714668 -0.6177 0.536773    
logSigmaNu  -0.0017042  0.1322126 -0.0129 0.989716    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> summary( randEffBfgsrUnb )

Call:
censReg(formula = y ~ x1 + x2, data = pDataUnb, method = "BFGSR")

Observations:
         Total  Left-censored     Uncensored Right-censored 
            56             17             39              0 

Coefficients:
             Estimate Std. error t value  Pr(> t)    
(Intercept) -0.221521   0.472250  -0.469  0.63902    
x1           1.640492   0.210943   7.777 7.43e-15 ***
x2           2.106462   0.684463   3.078  0.00209 ** 
logSigmaMu  -0.167685   0.271467  -0.618  0.53677    
logSigmaNu  -0.001704   0.132213  -0.013  0.98972    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

BFGSR maximization, 82 iterations
Return code 3: Last step could not find a value above the current.
Boundary of parameter space?  
Consider switching to a more robust optimisation method temporarily.
Log-likelihood: -71.1926 on 5 Df

> logLik( randEffBfgsrUnb )
'log Lik.' -71.1926 (df=5)
> extractAIC( randEffBfgsrUnb )
[1] -36.0000 152.3852
> print.default( randEffBfgsrUnb )
$maximum
[1] -71.1926

$estimate
 (Intercept)           x1           x2   logSigmaMu   logSigmaNu 
-0.221521080  1.640492066  2.106462085 -0.167685217 -0.001704224 

$gradient
 (Intercept)           x1           x2   logSigmaMu   logSigmaNu 
-0.004906748 -0.005790265  0.009234535  0.004189312  0.033660248 

$hessian
            (Intercept)         x1         x2  logSigmaMu logSigmaNu
(Intercept)  -13.803604  -4.351790 -7.5354815  -1.1060963  -1.943021
x1            -4.351790 -25.839222 -2.0602564   4.6556001   4.062707
x2            -7.535481  -2.060256 -6.2723112  -0.1424313  -1.068333
logSigmaMu    -1.106096   4.655600 -0.1424313 -14.9325417  -3.783056
logSigmaNu    -1.943021   4.062707 -1.0683328  -3.7830559 -58.891943

$code
[1] 3

$message
[1] "Last step could not find a value above the current.\nBoundary of parameter space?  \nConsider switching to a more robust optimisation method temporarily."

$last.step
$last.step$theta0
  (Intercept)            x1            x2    logSigmaMu    logSigmaNu 
-0.2217954660  1.6398961762  2.1066030557 -0.1674620255 -0.0008600295 

$last.step$f0
[1] -71.1926
attr(,"gradient")
             [,1]         [,2]        [,3]        [,4]        [,5]
 [1,] -0.50795234  0.090380537  0.10414043 -0.39457941 -0.53017104
 [2,] -1.81646648  0.068174046 -1.24643327  1.79672701 -0.96137030
 [3,]  1.78470175  0.486970327  1.76984322  1.73332855  1.89553776
 [4,]  0.15218927 -0.162184565 -0.39526306 -0.73663620 -1.58851154
 [5,]  0.08162691  1.039538304  0.69825954 -0.67799015 -0.44517180
 [6,]  0.33326735 -0.230488502  0.37401698 -0.53914241 -1.57462786
 [7,] -0.18095916 -3.026780652 -0.24844483 -0.62197661  5.47277538
 [8,]  0.01869347 -0.004074709  0.01069146 -0.41756286 -0.58183794
 [9,]  1.11539039  0.667471834  0.29559077  0.06296681 -1.68578360
[10,] -0.53757099 -0.419398622 -0.20413799 -0.40672904 -1.97512178
[11,] -0.08312763  1.378039323 -0.64737480 -0.82301642  2.49295181
[12,]  1.25904324  0.531646634  0.66990824  0.23130027 -1.79440978
[13,]  0.44628337 -0.162930895  0.28619507 -0.46862530 -1.45107728
[14,] -1.89172361 -1.283817975 -0.96128128  1.98059902  2.68048903
[15,] -0.17487828  1.042408749 -0.49500158 -0.72348133  0.02744031

$last.step$climb
[1]  -4713918 -10237306   2421860   3834396  14503144


$fixed
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
      FALSE       FALSE       FALSE       FALSE       FALSE 

$iterations
[1] 82

$type
[1] "BFGSR maximization"

$gradientObs
      (Intercept)          x1          x2  logSigmaMu  logSigmaNu
 [1,] -0.50918122  0.08940056  0.10392613 -0.39394764 -0.52864385
 [2,] -1.81781369  0.06721654 -1.24765565  1.79923470 -0.96171408
 [3,]  1.78607112  0.48397676  1.77177319  1.73579942  1.90157409
 [4,]  0.15167200 -0.16272022 -0.39644695 -0.73709132 -1.58540751
 [5,]  0.08177557  1.03956402  0.69921778 -0.67825744 -0.44315918
 [6,]  0.33241295 -0.23407117  0.37418718 -0.53964651 -1.57113851
 [7,] -0.18109195 -3.03336089 -0.24891363 -0.62226316  5.48916273
 [8,]  0.01867797 -0.00407133  0.01068259 -0.41786800 -0.58153449
 [9,]  1.11641143  0.66686199  0.29589933  0.06340986 -1.68543106
[10,] -0.53848176 -0.42146542 -0.20445196 -0.40600531 -1.97325145
[11,] -0.08316189  1.37929903 -0.64799427 -0.82338116  2.49925247
[12,]  1.25940014  0.53170784  0.67016992  0.23091367 -1.79282061
[13,]  0.44695565 -0.16385615  0.28665480 -0.46803025 -1.44930705
[14,] -1.89385832 -1.28782636 -0.96246738  1.98499172  2.68636216
[15,] -0.17469476  1.04355453 -0.49534656 -0.72366925  0.02971657

$call
censReg(formula = y ~ x1 + x2, data = pDataUnb, method = "BFGSR")

$terms
y ~ x1 + x2
attr(,"variables")
list(y, x1, x2)
attr(,"factors")
   x1 x2
y   0  0
x1  1  0
x2  0  1
attr(,"term.labels")
[1] "x1" "x2"
attr(,"order")
[1] 1 1
attr(,"intercept")
[1] 1
attr(,"response")
[1] 1
attr(,".Environment")
<environment: R_GlobalEnv>
attr(,"predvars")
list(y, x1, x2)
attr(,"dataClasses")
        y        x1        x2 
"numeric" "numeric" "numeric" 

$nObs
         Total  Left-censored     Uncensored Right-censored 
            56             17             39              0 

$df.residual
[1] 51

$start
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
 0.48299720  1.03002625  1.63470549 -0.47772116 -0.04988945 

attr(,"class")
[1] "censReg" "maxLik"  "maxim"   "list"   
> 
> 
> ## NAs in data
> pDataNa <- pData
> obsNa <- which( ! rownames( pData ) %in% rownames( pDataUnb ) )
> pDataNa$y[ obsNa[ 1:2 ] ] <- NA
> pDataNa$x1[ obsNa[ 3 ] ] <- NA
> pDataNa$x2[ obsNa[ c( 1, 2, 4 ) ] ] <- NA
> randEffBfgsrNa <- censReg( y ~ x1 + x2, data = pDataNa, method = "BFGSR" )
> all.equal( randEffBfgsrNa[ -12 ], randEffBfgsrUnb[ -12 ] )
[1] TRUE
> 
> 
> # returning log-likelihood contributions only (no estimations)
> logLikRandEff <- censReg( y ~ x1 + x2, data = pData, start = coef( randEff ),
+    logLikOnly = TRUE )
> print( logLikRandEff )
 [1] -4.252049 -3.739068 -7.046358 -5.300447 -3.354337 -5.307797 -6.291576
 [8] -1.655650 -4.393946 -3.765898 -6.821870 -5.646158 -4.333350 -5.726405
[15] -5.563914
attr(,"gradient")
             [,1]        [,2]        [,3]       [,4]       [,5]
 [1,] -0.85308353  0.22558520 -0.07261010 -0.1440032 -0.9609402
 [2,] -1.70309357  0.04839424 -1.18987552  1.6807831 -1.0133141
 [3,]  1.75084247  0.33367482  1.72755770  1.8353812  1.8043727
 [4,]  0.15577733 -0.20240007 -0.43224660 -0.6891081 -1.4351382
 [5,]  0.12950026  0.98433620  0.68943625 -0.6770204 -0.5543803
 [6,]  0.33035909 -0.30928416  0.38471147 -0.4921375 -1.5793716
 [7,] -0.08212549 -3.18521871 -0.23724729 -0.6766315  6.0271932
 [8,] -0.26685300  0.37888544  0.05565473 -0.5385828 -1.1091111
 [9,]  1.14824183  0.59396387  0.30328556  0.1329802 -1.6172740
[10,] -0.43505392 -0.40640593 -0.15245982 -0.4687582 -1.9364984
[11,] -0.02839185  1.44795739 -0.64407731 -0.9172655  2.7349924
[12,]  1.21047881  0.53669833  0.61328528  0.2055542 -1.7351236
[13,]  0.53592707 -0.22523044  0.33117482 -0.3691166 -1.4082834
[14,] -1.81460674 -1.30608969 -0.91950989  1.9573174  2.5815580
[15,] -0.07791875  1.08513351 -0.45707928 -0.8393922  0.2013187
> all.equal( sum( logLikRandEff ), c( logLik( randEff ) ) )
[1] TRUE
> logLikStart <- censReg( y ~ x1 + x2, data = pData, 
+    start = c( -0.4, 1.7, 2.2, -0.1, -0.01 ), logLikOnly = TRUE )
> print( logLikStart )
 [1] -4.223693 -3.590625 -7.110342 -5.316228 -3.389378 -5.360380 -6.349353
 [8] -1.661668 -4.433769 -3.774324 -6.788058 -5.699416 -4.385225 -5.593147
[15] -5.548283
attr(,"gradient")
             [,1]        [,2]        [,3]       [,4]       [,5]
 [1,] -0.78780430  0.27899526 -0.03948865 -0.1781187 -1.0281108
 [2,] -1.58232641  0.09231159 -1.09619445  1.4850210 -1.0562683
 [3,]  1.72436737  0.26392132  1.72228285  1.9089216  1.8439353
 [4,]  0.18480626 -0.20993642 -0.40681657 -0.6139118 -1.5330720
 [5,]  0.16156500  0.97006006  0.71388764 -0.6642389 -0.5115526
 [6,]  0.36176010 -0.38785781  0.42046000 -0.4277169 -1.5829540
 [7,] -0.04900991 -3.19667670 -0.23065229 -0.6996566  6.1344398
 [8,] -0.21856969  0.35678338  0.07820116 -0.5684845 -1.0658263
 [9,]  1.13458709  0.55150636  0.30101863  0.1460472 -1.6130954
[10,] -0.35438475 -0.38788784 -0.10704963 -0.5248618 -1.9100687
[11,] -0.01373800  1.42364787 -0.62446618 -0.9654173  2.6815112
[12,]  1.16280483  0.49951850  0.60156788  0.2025718 -1.7537215
[13,]  0.59996890 -0.26781383  0.36925229 -0.2994739 -1.3806520
[14,] -1.71185020 -1.20078722 -0.84865925  1.8183688  2.4960866
[15,] -0.03387939  1.05747706 -0.42268903 -0.9163573  0.1985986
> 
> 
> 
> 
