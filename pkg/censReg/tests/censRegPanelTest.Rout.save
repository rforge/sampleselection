
R version 2.14.2 (2012-02-29)
Copyright (C) 2012 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> library( censReg )
Loading required package: maxLik
Loading required package: miscTools
> library( plm )
Loading required package: bdsmatrix

Attaching package: 'bdsmatrix'

The following object(s) are masked from 'package:base':

    backsolve

Loading required package: nlme
Loading required package: Formula
Loading required package: MASS
Loading required package: sandwich
Loading required package: zoo

Attaching package: 'zoo'

The following object(s) are masked from 'package:base':

    as.Date, as.Date.numeric

> 
> nId <- 15
> nTime <- 4
> 
> set.seed( 123 )
> pData <- data.frame(
+    id = rep( paste( "F", 1:nId, sep = "_" ), each = nTime ),
+    time = rep( 1980 + 1:nTime, nId ) )
> pData$ui <- rep( rnorm( nId ), each = nTime )
> pData$x1 <- rnorm( nId * nTime )
> pData$x2 <- runif( nId * nTime )
> pData$ys <- -1 + pData$ui + 2 * pData$x1 + 3 * pData$x2 + rnorm( nId * nTime )
> pData$y <- ifelse( pData$ys > 0, pData$ys, 0 )
> nData <- pData # save data set without information on panel structure
> pData <- pdata.frame( pData, c( "id", "time" ) )
> 
> 
> ## Newton-Raphson method
> randEff <- censReg( y ~ x1 + x2, data = pData )
> print( randEff )

Call:
censReg(formula = y ~ x1 + x2, data = pData)

Coefficients:
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
   -0.36562     1.68000     2.24054    -0.12955    -0.01241 

> print( randEff, logSigma = FALSE )

Call:
censReg(formula = y ~ x1 + x2, data = pData)

Coefficients:
(Intercept)          x1          x2     sigmaMu     sigmaNu 
    -0.3656      1.6800      2.2405      0.8785      0.9877 

> maxLik:::summary.maxLik( randEff )
--------------------------------------------
Maximum Likelihood estimation
Newton-Raphson maximisation, 5 iterations
Return code 1: gradient close to zero
Log-Likelihood: -73.19882 
5  free parameters
Estimates:
             Estimate Std. error t value   Pr(> t)    
(Intercept) -0.365623   0.474457 -0.7706 0.4409361    
x1           1.680004   0.209222  8.0298 9.767e-16 ***
x2           2.240544   0.673889  3.3248 0.0008848 ***
logSigmaMu  -0.129547   0.258070 -0.5020 0.6156792    
logSigmaNu  -0.012408   0.129690 -0.0957 0.9237786    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> summary( randEff )

Call:
censReg(formula = y ~ x1 + x2, data = pData)

Observations:
         Total  Left-censored     Uncensored Right-censored 
            60             20             40              0 

Coefficients:
            Estimate Std. error t value  Pr(> t)    
(Intercept) -0.36562    0.47446  -0.771 0.440936    
x1           1.68000    0.20922   8.030 9.77e-16 ***
x2           2.24054    0.67389   3.325 0.000885 ***
logSigmaMu  -0.12955    0.25807  -0.502 0.615679    
logSigmaNu  -0.01241    0.12969  -0.096 0.923779    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Newton-Raphson maximisation, 5 iterations
Return code 1: gradient close to zero
Log-likelihood: -73.19882 on 5 Df

> print( summary( randEff ), logSigma = FALSE )

Call:
censReg(formula = y ~ x1 + x2, data = pData)

Observations:
         Total  Left-censored     Uncensored Right-censored 
            60             20             40              0 

Coefficients:
            Estimate Std. error t value  Pr(> t)    
(Intercept)  -0.3656     0.4745  -0.771 0.440936    
x1            1.6800     0.2092   8.030 9.77e-16 ***
x2            2.2405     0.6739   3.325 0.000885 ***
sigmaMu       0.8785     0.2267   3.875 0.000107 ***
sigmaNu       0.9877     0.1281   7.711 1.25e-14 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Newton-Raphson maximisation, 5 iterations
Return code 1: gradient close to zero
Log-likelihood: -73.19882 on 5 Df

> coef( randEff )
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
-0.36562313  1.68000400  2.24054376 -0.12954703 -0.01240809 
> coef( randEff, logSigma = FALSE )
(Intercept)          x1          x2     sigmaMu     sigmaNu 
 -0.3656231   1.6800040   2.2405438   0.8784933   0.9876686 
> vcov( randEff )
             (Intercept)           x1           x2   logSigmaMu   logSigmaNu
(Intercept)  0.225109672 -0.020570168 -0.254602886 -0.023824162 -0.002973952
x1          -0.020570168  0.043773972  0.008562225  0.013404079  0.002969957
x2          -0.254602886  0.008562225  0.454125882  0.017179542  0.001505438
logSigmaMu  -0.023824162  0.013404079  0.017179542  0.066600320 -0.002638871
logSigmaNu  -0.002973952  0.002969957  0.001505438 -0.002638871  0.016819442
> vcov( randEff, logSigma = FALSE )
             (Intercept)           x1           x2      sigmaMu      sigmaNu
(Intercept)  0.225109672 -0.020570168 -0.254602886 -0.020929366 -0.002937279
x1          -0.020570168  0.043773972  0.008562225  0.011775394  0.002933333
x2          -0.254602886  0.008562225  0.454125882  0.015092113  0.001486874
sigmaMu     -0.020929366  0.011775394  0.015092113  0.051398826 -0.002289643
sigmaNu     -0.002937279  0.002933333  0.001486874 -0.002289643  0.016407184
> coef( summary( randEff ) )
               Estimate Std. error     t value      Pr(> t)
(Intercept) -0.36562313  0.4744572 -0.77061344 4.409361e-01
x1           1.68000400  0.2092223  8.02975581 9.766687e-16
x2           2.24054376  0.6738886  3.32479829 8.848252e-04
logSigmaMu  -0.12954703  0.2580704 -0.50198333 6.156792e-01
logSigmaNu  -0.01240809  0.1296898 -0.09567514 9.237786e-01
> coef( summary( randEff ), logSigma = FALSE )
              Estimate Std. error    t value      Pr(> t)
(Intercept) -0.3656231  0.4744572 -0.7706134 4.409361e-01
x1           1.6800040  0.2092223  8.0297558 9.766687e-16
x2           2.2405438  0.6738886  3.3247983 8.848252e-04
sigmaMu      0.8784933  0.2267131  3.8749120 1.066632e-04
sigmaNu      0.9876686  0.1280905  7.7107072 1.251225e-14
> logLik( randEff )
'log Lik.' -73.19882 (df=5)
> extractAIC( randEff )
[1] -40.0000 156.3976
> print.default( randEff )
$maximum
[1] -73.19882

$estimate
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
-0.36562313  1.68000400  2.24054376 -0.12954703 -0.01240809 

$gradient
 (Intercept)           x1           x2   logSigmaMu   logSigmaNu 
1.711601e-11 4.533546e-11 1.345131e-11 8.231277e-12 6.206993e-11 

$hessian
            (Intercept)         x1         x2  logSigmaMu  logSigmaNu
(Intercept)  -13.321985  -4.096607 -7.3075697  -2.1079024  -1.3088177
x1            -4.096607 -26.076787 -1.9905305   4.4849638   4.7620891
x2            -7.307570  -1.990530 -6.2362552  -0.6238251  -0.4803054
logSigmaMu    -2.107902   4.484964 -0.6238251 -16.6582041  -3.7223987
logSigmaNu    -1.308818   4.762089 -0.4803054  -3.7223987 -61.0683413

$code
[1] 1

$message
[1] "gradient close to zero"

$last.step
NULL

$fixed
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
      FALSE       FALSE       FALSE       FALSE       FALSE 

$iterations
[1] 5

$type
[1] "Newton-Raphson maximisation"

$gradientObs
      (Intercept)          x1          x2 logSigmaMu logSigmaNu
 [1,] -0.85308353  0.22558520 -0.07261010 -0.1440032 -0.9609402
 [2,] -1.70309357  0.04839424 -1.18987552  1.6807831 -1.0133141
 [3,]  1.75084247  0.33367482  1.72755770  1.8353812  1.8043727
 [4,]  0.15577733 -0.20240007 -0.43224660 -0.6891081 -1.4351382
 [5,]  0.12950026  0.98433620  0.68943625 -0.6770204 -0.5543803
 [6,]  0.33035909 -0.30928416  0.38471147 -0.4921375 -1.5793716
 [7,] -0.08212549 -3.18521871 -0.23724729 -0.6766315  6.0271932
 [8,] -0.26685300  0.37888544  0.05565473 -0.5385828 -1.1091111
 [9,]  1.14824183  0.59396387  0.30328556  0.1329802 -1.6172740
[10,] -0.43505392 -0.40640593 -0.15245982 -0.4687582 -1.9364984
[11,] -0.02839185  1.44795739 -0.64407731 -0.9172655  2.7349924
[12,]  1.21047881  0.53669833  0.61328528  0.2055542 -1.7351236
[13,]  0.53592707 -0.22523044  0.33117482 -0.3691166 -1.4082834
[14,] -1.81460674 -1.30608969 -0.91950989  1.9573174  2.5815580
[15,] -0.07791875  1.08513351 -0.45707928 -0.8393922  0.2013187

$call
censReg(formula = y ~ x1 + x2, data = pData)

$terms
y ~ x1 + x2
attr(,"variables")
list(y, x1, x2)
attr(,"factors")
   x1 x2
y   0  0
x1  1  0
x2  0  1
attr(,"term.labels")
[1] "x1" "x2"
attr(,"order")
[1] 1 1
attr(,"intercept")
[1] 1
attr(,"response")
[1] 1
attr(,".Environment")
<environment: R_GlobalEnv>
attr(,"predvars")
list(y, x1, x2)
attr(,"dataClasses")
        y        x1        x2 
"numeric" "numeric" "numeric" 

$nObs
         Total  Left-censored     Uncensored Right-censored 
            60             20             40              0 

$df.residual
[1] 55

$start
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
  0.4703506   1.0111600   1.6191826  -0.4962510  -0.0620962 

attr(,"class")
[1] "censReg" "maxLik"  "maxim"   "list"   
> 
> 
> ## BHHH method
> randEffBhhh <- censReg( y ~ x1 + x2, data = pData, method = "BHHH" )
> print( randEffBhhh )

Call:
censReg(formula = y ~ x1 + x2, data = pData, method = "BHHH")

Coefficients:
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
    -0.3656      1.6800      2.2406     -0.1296     -0.0124 

> maxLik:::summary.maxLik( randEffBhhh )
--------------------------------------------
Maximum Likelihood estimation
BHHH maximisation, 18 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -73.19882 
5  free parameters
Estimates:
             Estimate Std. error t value   Pr(> t)    
(Intercept) -0.365635   0.555054 -0.6587  0.510065    
x1           1.680016   0.293775  5.7187 1.073e-08 ***
x2           2.240556   0.729501  3.0714  0.002131 ** 
logSigmaMu  -0.129565   0.295017 -0.4392  0.660531    
logSigmaNu  -0.012402   0.140134 -0.0885  0.929481    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> summary( randEffBhhh )

Call:
censReg(formula = y ~ x1 + x2, data = pData, method = "BHHH")

Observations:
         Total  Left-censored     Uncensored Right-censored 
            60             20             40              0 

Coefficients:
            Estimate Std. error t value  Pr(> t)    
(Intercept)  -0.3656     0.5551  -0.659  0.51006    
x1            1.6800     0.2938   5.719 1.07e-08 ***
x2            2.2406     0.7295   3.071  0.00213 ** 
logSigmaMu   -0.1296     0.2950  -0.439  0.66053    
logSigmaNu   -0.0124     0.1401  -0.088  0.92948    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

BHHH maximisation, 18 iterations
Return code 2: successive function values within tolerance limit
Log-likelihood: -73.19882 on 5 Df

> print.default( randEffBhhh )
$maximum
[1] -73.19882

$estimate
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
-0.36563477  1.68001566  2.24055570 -0.12956535 -0.01240161 

$gradient
  (Intercept)            x1            x2    logSigmaMu    logSigmaNu 
 5.028294e-05 -3.315101e-04 -4.246354e-06  3.505038e-04 -2.626408e-04 

$hessian
            (Intercept)         x1         x2  logSigmaMu logSigmaNu
(Intercept)  -13.482494  -4.096061 -8.3241402   2.7373240   3.959016
x1            -4.096061 -17.395897 -2.1956247   2.0949384  19.029556
x2            -8.324140  -2.195625 -7.3456165  -0.2437129   3.421562
logSigmaMu     2.737324   2.094938 -0.2437129 -13.9308908  -3.639137
logSigmaNu     3.959016  19.029556  3.4215617  -3.6391374 -73.168704
attr(,"type")
[1] "BHHH"

$code
[1] 2

$message
[1] "successive function values within tolerance limit"

$last.step
NULL

$fixed
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
      FALSE       FALSE       FALSE       FALSE       FALSE 

$iterations
[1] 18

$type
[1] "BHHH maximisation"

$gradientObs
      (Intercept)          x1          x2 logSigmaMu logSigmaNu
 [1,] -0.85309912  0.22553991 -0.07262972 -0.1439976 -0.9609756
 [2,] -1.70314125  0.04834913 -1.18991475  1.6808211 -1.0132976
 [3,]  1.75089168  0.33368134  1.72757656  1.8353986  1.8044304
 [4,]  0.15581599 -0.20240761 -0.43221921 -0.6890852 -1.4351543
 [5,]  0.12951232  0.98431668  0.68943033 -0.6770023 -0.5544220
 [6,]  0.33038531 -0.30929737  0.38473066 -0.4921403 -1.5793732
 [7,] -0.08212211 -3.18519652 -0.23724499 -0.6766142  6.0271629
 [8,] -0.26685182  0.37888104  0.05565305 -0.5385702 -1.1091241
 [9,]  1.14826405  0.59392337  0.30329461  0.1330245 -1.6172865
[10,] -0.43507487 -0.40642217 -0.15246997 -0.4687544 -1.9364930
[11,] -0.02840097  1.44793082 -0.64407223 -0.9172307  2.7348842
[12,]  1.21050842  0.53669645  0.61330484  0.2056154 -1.7351598
[13,]  0.53595825 -0.22524780  0.33119153 -0.3691112 -1.4082671
[14,] -1.81465694 -1.30619017 -0.91955280  1.9573642  2.5815611
[15,] -0.07793866  1.08511138 -0.45708215 -0.8393671  0.2012520

$call
censReg(formula = y ~ x1 + x2, data = pData, method = "BHHH")

$terms
y ~ x1 + x2
attr(,"variables")
list(y, x1, x2)
attr(,"factors")
   x1 x2
y   0  0
x1  1  0
x2  0  1
attr(,"term.labels")
[1] "x1" "x2"
attr(,"order")
[1] 1 1
attr(,"intercept")
[1] 1
attr(,"response")
[1] 1
attr(,".Environment")
<environment: R_GlobalEnv>
attr(,"predvars")
list(y, x1, x2)
attr(,"dataClasses")
        y        x1        x2 
"numeric" "numeric" "numeric" 

$nObs
         Total  Left-censored     Uncensored Right-censored 
            60             20             40              0 

$df.residual
[1] 55

$start
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
  0.4703506   1.0111600   1.6191826  -0.4962510  -0.0620962 

attr(,"class")
[1] "censReg" "maxLik"  "maxim"   "list"   
> 
> 
> ## BFGS method (optim)
> randEffBfgs <- censReg( y ~ x1 + x2, data = pData, method = "BFGS" )
> print( randEffBfgs )

Call:
censReg(formula = y ~ x1 + x2, data = pData, method = "BFGS")

Coefficients:
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
   -0.36562     1.68000     2.24055    -0.12955    -0.01241 

> maxLik:::summary.maxLik( randEffBfgs )
--------------------------------------------
Maximum Likelihood estimation
BFGS maximisation, 25 iterations
Return code 0: successful convergence 
Log-Likelihood: -73.19882 
5  free parameters
Estimates:
             Estimate Std. error t value   Pr(> t)    
(Intercept) -0.365624   0.474456 -0.7706 0.4409343    
x1           1.680002   0.209222  8.0298 9.767e-16 ***
x2           2.240551   0.673888  3.3248 0.0008848 ***
logSigmaMu  -0.129549   0.258071 -0.5020 0.6156731    
logSigmaNu  -0.012408   0.129690 -0.0957 0.9237762    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> summary( randEffBfgs )

Call:
censReg(formula = y ~ x1 + x2, data = pData, method = "BFGS")

Observations:
         Total  Left-censored     Uncensored Right-censored 
            60             20             40              0 

Coefficients:
            Estimate Std. error t value  Pr(> t)    
(Intercept) -0.36562    0.47446  -0.771 0.440934    
x1           1.68000    0.20922   8.030 9.77e-16 ***
x2           2.24055    0.67389   3.325 0.000885 ***
logSigmaMu  -0.12955    0.25807  -0.502 0.615673    
logSigmaNu  -0.01241    0.12969  -0.096 0.923776    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

BFGS maximisation, 25 iterations
Return code 0: successful convergence 
Log-likelihood: -73.19882 on 5 Df

> print.default( randEffBfgs )
$maximum
[1] -73.19882

$estimate
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
-0.36562386  1.68000222  2.24055118 -0.12954945 -0.01240847 

$gradient
  (Intercept)            x1            x2    logSigmaMu    logSigmaNu 
-3.160077e-05  2.178336e-05 -3.570719e-05  3.081674e-05  2.108131e-05 

$hessian
            (Intercept)         x1         x2  logSigmaMu logSigmaNu
(Intercept)  -13.322030  -4.096615 -7.3075895  -2.1078505  -1.308810
x1            -4.096615 -26.076823 -1.9905334   4.4849768   4.762042
x2            -7.307589  -1.990533 -6.2362665  -0.6237935  -0.480264
logSigmaMu    -2.107850   4.484977 -0.6237936 -16.6581488  -3.722435
logSigmaNu    -1.308810   4.762042 -0.4802640  -3.7224350 -61.068402

$code
[1] 0

$message
[1] "successful convergence "

$last.step
NULL

$fixed
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
      FALSE       FALSE       FALSE       FALSE       FALSE 

$iterations
function 
      25 

$type
[1] "BFGS maximisation"

$constraints
NULL

$gradientObs
      (Intercept)          x1          x2 logSigmaMu logSigmaNu
 [1,] -0.85308743  0.22558129 -0.07261263 -0.1440013 -0.9609385
 [2,] -1.70310343  0.04839017 -1.18988370  1.6807981 -1.0133093
 [3,]  1.75084680  0.33368182  1.72755839  1.8353799  1.8043672
 [4,]  0.15577623 -0.20239996 -0.43224879 -0.6891122 -1.4351265
 [5,]  0.12949863  0.98433692  0.68943374 -0.6770205 -0.5543875
 [6,]  0.33035850 -0.30927350  0.38470918 -0.4921407 -1.5793728
 [7,] -0.08212636 -3.18521917 -0.23724752 -0.6766300  6.0271888
 [8,] -0.26685580  0.37888651  0.05565314 -0.5385807 -1.1091140
 [9,]  1.14824376  0.59396790  0.30328585  0.1329813 -1.6172723
[10,] -0.43505882 -0.40640593 -0.15246287 -0.4687554 -1.9365001
[11,] -0.02839283  1.44796138 -0.64407965 -0.9172624  2.7350038
[12,]  1.21048230  0.53670265  0.61328478  0.2055557 -1.7351212
[13,]  0.53592379 -0.22522781  0.33117257 -0.3691209 -1.4082845
[14,] -1.81461479 -1.30609804 -0.91951560  1.9573273  2.5815634
[15,] -0.07792214  1.08513754 -0.45708262 -0.8393873  0.2013247

$call
censReg(formula = y ~ x1 + x2, data = pData, method = "BFGS")

$terms
y ~ x1 + x2
attr(,"variables")
list(y, x1, x2)
attr(,"factors")
   x1 x2
y   0  0
x1  1  0
x2  0  1
attr(,"term.labels")
[1] "x1" "x2"
attr(,"order")
[1] 1 1
attr(,"intercept")
[1] 1
attr(,"response")
[1] 1
attr(,".Environment")
<environment: R_GlobalEnv>
attr(,"predvars")
list(y, x1, x2)
attr(,"dataClasses")
        y        x1        x2 
"numeric" "numeric" "numeric" 

$nObs
         Total  Left-censored     Uncensored Right-censored 
            60             20             40              0 

$df.residual
[1] 55

$start
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
  0.4703506   1.0111600   1.6191826  -0.4962510  -0.0620962 

attr(,"class")
[1] "censReg" "maxLik"  "maxim"  
> 
> 
> ## BFGS method (R)
> randEffBfgsr <- censReg( y ~ x1 + x2, data = pData, method = "BFGSR" )
> print( randEffBfgsr )

Call:
censReg(formula = y ~ x1 + x2, data = pData, method = "BFGSR")

Coefficients:
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
   -0.37046     1.68029     2.24816    -0.12913    -0.01195 

> maxLik:::summary.maxLik( randEffBfgsr )
--------------------------------------------
Maximum Likelihood estimation
BFGSR maximization, 80 iterations
Return code 3: Last step could not find a value above the current.
Boundary of parameter space?  
Consider switching to a more robust optimisation method temporarily.
Log-Likelihood: -73.19889 
5  free parameters
Estimates:
             Estimate Std. error t value   Pr(> t)    
(Intercept) -0.370461   0.475017 -0.7799 0.4354555    
x1           1.680285   0.209353  8.0261 1.006e-15 ***
x2           2.248158   0.674381  3.3337 0.0008571 ***
logSigmaMu  -0.129131   0.258083 -0.5003 0.6168314    
logSigmaNu  -0.011953   0.129751 -0.0921 0.9266019    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> summary( randEffBfgsr )

Call:
censReg(formula = y ~ x1 + x2, data = pData, method = "BFGSR")

Observations:
         Total  Left-censored     Uncensored Right-censored 
            60             20             40              0 

Coefficients:
            Estimate Std. error t value  Pr(> t)    
(Intercept) -0.37046    0.47502  -0.780 0.435455    
x1           1.68029    0.20935   8.026 1.01e-15 ***
x2           2.24816    0.67438   3.334 0.000857 ***
logSigmaMu  -0.12913    0.25808  -0.500 0.616831    
logSigmaNu  -0.01195    0.12975  -0.092 0.926602    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

BFGSR maximization, 80 iterations
Return code 3: Last step could not find a value above the current.
Boundary of parameter space?  
Consider switching to a more robust optimisation method temporarily.
Log-likelihood: -73.19889 on 5 Df

> print.default( randEffBfgsr )
$maximum
[1] -73.19889

$estimate
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
-0.37046124  1.68028520  2.24815849 -0.12913079 -0.01195278 

$gradient
 (Intercept)           x1           x2   logSigmaMu   logSigmaNu 
 0.006171986  0.001368500 -0.013159270 -0.001894383 -0.025233003 

$hessian
            (Intercept)         x1         x2  logSigmaMu  logSigmaNu
(Intercept)  -13.303435  -4.092004 -7.2985828  -2.1290573  -1.2928452
x1            -4.092004 -26.049375 -1.9870860   4.4802057   4.7582167
x2            -7.298583  -1.987086 -6.2294144  -0.6302189  -0.4454241
logSigmaMu    -2.129057   4.480206 -0.6302189 -16.6682717  -3.7183210
logSigmaNu    -1.292845   4.758217 -0.4454242  -3.7183210 -61.0106993

$code
[1] 3

$message
[1] "Last step could not find a value above the current.\nBoundary of parameter space?  \nConsider switching to a more robust optimisation method temporarily."

$last.step
$last.step$theta0
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
-0.37030362  1.68022156  2.24780925 -0.12920178 -0.01271273 

$last.step$f0
[1] -73.19889
attr(,"gradient")
             [,1]        [,2]        [,3]       [,4]       [,5]
 [1,] -0.85243668  0.22398181 -0.07347532 -0.1444240 -0.9667924
 [2,] -1.70319039  0.04665937 -1.19102875  1.6827424 -1.0125145
 [3,]  1.75066640  0.33276214  1.72569856  1.8367051  1.7969247
 [4,]  0.15520074 -0.20337614 -0.43422367 -0.6891452 -1.4263674
 [5,]  0.12996182  0.98310020  0.68773604 -0.6769697 -0.5611122
 [6,]  0.32998395 -0.30604006  0.38380894 -0.4918051 -1.5812120
 [7,] -0.07973010 -3.18843584 -0.23693940 -0.6774095  6.0377246
 [8,] -0.26544574  0.37775461  0.05580374 -0.5392411 -1.1082836
 [9,]  1.14907393  0.59404671  0.30330051  0.1348881 -1.6148858
[10,] -0.43364287 -0.40521653 -0.15203803 -0.4697165 -1.9364276
[11,] -0.02761949  1.45126260 -0.64504565 -0.9188402  2.7460852
[12,]  1.20987727  0.53863837  0.61093459  0.2046343 -1.7324980
[13,]  0.53687877 -0.22562027  0.33135027 -0.3680114 -1.4079289
[14,] -1.81475297 -1.30829014 -0.92003374  1.9593433  2.5790696
[15,] -0.07680810  1.08791375 -0.45747222 -0.8410347  0.2092947

$last.step$climb
[1]   2707847  -1093414  -5999916  -1219538 -13055982


$fixed
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
      FALSE       FALSE       FALSE       FALSE       FALSE 

$iterations
[1] 80

$type
[1] "BFGSR maximization"

$gradientObs
      (Intercept)          x1          x2 logSigmaMu logSigmaNu
 [1,] -0.85175430  0.22290949 -0.07377343 -0.1447541 -0.9691979
 [2,] -1.70296385  0.04629003 -1.19080213  1.6822755 -1.0122141
 [3,]  1.74907358  0.33375903  1.72376431  1.8330153  1.7922591
 [4,]  0.15576912 -0.20318775 -0.43313567 -0.6890717 -1.4286550
 [5,]  0.12973585  0.98247655  0.68669908 -0.6767772 -0.5634140
 [6,]  0.33008739 -0.30521101  0.38358448 -0.4923017 -1.5834612
 [7,] -0.07979061 -3.18337382 -0.23661010 -0.6769367  6.0261319
 [8,] -0.26569968  0.37785411  0.05563751 -0.5387889 -1.1088862
 [9,]  1.14853518  0.59324946  0.30319374  0.1348565 -1.6157529
[10,] -0.43372665 -0.40451880 -0.15215178 -0.4698142 -1.9374287
[11,] -0.02787949  1.44946264 -0.64441655 -0.9178346  2.7384544
[12,]  1.20997578  0.53829770  0.61110321  0.2050244 -1.7341848
[13,]  0.53634333 -0.22501828  0.33099734 -0.3686608 -1.4092027
[14,] -1.81412994 -1.30796665 -0.92004063  1.9580689  2.5748336
[15,] -0.07740373  1.08634580 -0.45720866 -0.8401950  0.2054853

$call
censReg(formula = y ~ x1 + x2, data = pData, method = "BFGSR")

$terms
y ~ x1 + x2
attr(,"variables")
list(y, x1, x2)
attr(,"factors")
   x1 x2
y   0  0
x1  1  0
x2  0  1
attr(,"term.labels")
[1] "x1" "x2"
attr(,"order")
[1] 1 1
attr(,"intercept")
[1] 1
attr(,"response")
[1] 1
attr(,".Environment")
<environment: R_GlobalEnv>
attr(,"predvars")
list(y, x1, x2)
attr(,"dataClasses")
        y        x1        x2 
"numeric" "numeric" "numeric" 

$nObs
         Total  Left-censored     Uncensored Right-censored 
            60             20             40              0 

$df.residual
[1] 55

$start
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
  0.4703506   1.0111600   1.6191826  -0.4962510  -0.0620962 

attr(,"class")
[1] "censReg" "maxLik"  "maxim"   "list"   
> 
> 
> ## BHHH with starting values
> randEffBhhhStart <- censReg( y ~ x1 + x2, data = pData, method = "BHHH",
+    start = c( -0.4, 1.7, 2.2, -0.1, -0.01 ) )
> print( randEffBhhhStart )

Call:
censReg(formula = y ~ x1 + x2, data = pData, start = c(-0.4, 
    1.7, 2.2, -0.1, -0.01), method = "BHHH")

Coefficients:
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
    -0.3657      1.6800      2.2406     -0.1296     -0.0124 

> summary( randEffBhhhStart )

Call:
censReg(formula = y ~ x1 + x2, data = pData, start = c(-0.4, 
    1.7, 2.2, -0.1, -0.01), method = "BHHH")

Observations:
         Total  Left-censored     Uncensored Right-censored 
            60             20             40              0 

Coefficients:
            Estimate Std. error t value  Pr(> t)    
(Intercept)  -0.3657     0.5551  -0.659  0.51003    
x1            1.6800     0.2938   5.719 1.07e-08 ***
x2            2.2406     0.7295   3.071  0.00213 ** 
logSigmaMu   -0.1295     0.2950  -0.439  0.66056    
logSigmaNu   -0.0124     0.1401  -0.088  0.92948    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

BHHH maximisation, 10 iterations
Return code 2: successive function values within tolerance limit
Log-likelihood: -73.19882 on 5 Df

> 
> 
> ## left-censoring at 5
> pData$yAdd <- pData$y + 5
> randEffAdd <- censReg( yAdd ~ x1 + x2, data = pData, method = "BFGSR", left = 5 )
> print( randEffAdd )

Call:
censReg(formula = yAdd ~ x1 + x2, left = 5, data = pData, method = "BFGSR")

Coefficients:
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
    4.63282     1.68018     2.24283    -0.12937    -0.01239 

> maxLik:::summary.maxLik( randEffAdd )
--------------------------------------------
Maximum Likelihood estimation
BFGSR maximization, 87 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -73.19883 
5  free parameters
Estimates:
             Estimate Std. error t value   Pr(> t)    
(Intercept)  4.632818   0.474637  9.7608 < 2.2e-16 ***
x1           1.680178   0.209248  8.0296 9.778e-16 ***
x2           2.242834   0.673979  3.3277 0.0008755 ***
logSigmaMu  -0.129366   0.258035 -0.5014 0.6161237    
logSigmaNu  -0.012395   0.129694 -0.0956 0.9238631    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> summary( randEffAdd )

Call:
censReg(formula = yAdd ~ x1 + x2, left = 5, data = pData, method = "BFGSR")

Observations:
         Total  Left-censored     Uncensored Right-censored 
            60             20             40              0 

Coefficients:
            Estimate Std. error t value  Pr(> t)    
(Intercept)  4.63282    0.47464   9.761  < 2e-16 ***
x1           1.68018    0.20925   8.030 9.78e-16 ***
x2           2.24283    0.67398   3.328 0.000876 ***
logSigmaMu  -0.12937    0.25804  -0.501 0.616124    
logSigmaNu  -0.01239    0.12969  -0.096 0.923863    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

BFGSR maximization, 87 iterations
Return code 2: successive function values within tolerance limit
Log-likelihood: -73.19883 on 5 Df

> coef( randEffAdd )
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
 4.63281849  1.68017849  2.24283439 -0.12936647 -0.01239473 
> coef( randEffAdd, logSigma = FALSE )
(Intercept)          x1          x2     sigmaMu     sigmaNu 
  4.6328185   1.6801785   2.2428344   0.8786519   0.9876818 
> vcov( randEffAdd )
             (Intercept)           x1           x2   logSigmaMu   logSigmaNu
(Intercept)  0.225280249 -0.020609436 -0.254738090 -0.023907169 -0.002998027
x1          -0.020609436  0.043784608  0.008600621  0.013409955  0.002972966
x2          -0.254738090  0.008600621  0.454248069  0.017228327  0.001563299
logSigmaMu  -0.023907169  0.013409955  0.017228327  0.066582291 -0.002633255
logSigmaNu  -0.002998027  0.002972966  0.001563299 -0.002633255  0.016820657
> vcov( randEffAdd, logSigma = FALSE )
             (Intercept)           x1           x2      sigmaMu      sigmaNu
(Intercept)  0.225280249 -0.020609436 -0.254738090 -0.021006080 -0.002961097
x1          -0.020609436  0.043784608  0.008600621  0.011782683  0.002936344
x2          -0.254738090  0.008600621  0.454248069  0.015137702  0.001544042
sigmaMu     -0.021006080  0.011782683  0.015137702  0.051403471 -0.002285213
sigmaNu     -0.002961097  0.002936344  0.001544042 -0.002285213  0.016408808
> logLik( randEffAdd )
'log Lik.' -73.19883 (df=5)
> extractAIC( randEffAdd )
[1] -40.0000 156.3977
> print.default( randEffAdd )
$maximum
[1] -73.19883

$estimate
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
 4.63281849  1.68017849  2.24283439 -0.12936647 -0.01239473 

$gradient
  (Intercept)            x1            x2    logSigmaMu    logSigmaNu 
 0.0029062113 -0.0018516545 -0.0033640335 -0.0004164336  0.0002905593 

$hessian
            (Intercept)         x1         x2  logSigmaMu  logSigmaNu
(Intercept)  -13.316137  -4.095972 -7.3052173  -2.1176237  -1.3020276
x1            -4.095972 -26.073013 -1.9897808   4.4838218   4.7650937
x2            -7.305217  -1.989781 -6.2350506  -0.6274941  -0.4691132
logSigmaMu    -2.117624   4.483822 -0.6274941 -16.6672170  -3.7208421
logSigmaNu    -1.302028   4.765094 -0.4691132  -3.7208421 -61.0638781

$code
[1] 2

$message
[1] "successive function values within tolerance limit"

$last.step
NULL

$fixed
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
      FALSE       FALSE       FALSE       FALSE       FALSE 

$iterations
[1] 87

$type
[1] "BFGSR maximization"

$gradientObs
      (Intercept)          x1          x2 logSigmaMu logSigmaNu
 [1,] -0.85274002  0.22488232 -0.07292966 -0.1441887 -0.9633175
 [2,] -1.70289269  0.04777677 -1.19006921  1.6810912 -1.0131354
 [3,]  1.75042372  0.33317750  1.72663610  1.8352506  1.8014606
 [4,]  0.15569264 -0.20272978 -0.43270530 -0.6890127 -1.4327966
 [5,]  0.12965901  0.98376756  0.68877563 -0.6769707 -0.5568101
 [6,]  0.33020809 -0.30857011  0.38443395 -0.4920755 -1.5801989
 [7,] -0.08132012 -3.18566285 -0.23710021 -0.6768592  6.0295385
 [8,] -0.26633974  0.37848073  0.05572157 -0.5387911 -1.1088439
 [9,]  1.14840595  0.59366818  0.30327450  0.1336056 -1.6166881
[10,] -0.43451859 -0.40599284 -0.15227578 -0.4691254 -1.9365255
[11,] -0.02815869  1.44866206 -0.64424442 -0.9177071  2.7372208
[12,]  1.21021206  0.53715860  0.61255414  0.2052496 -1.7345693
[13,]  0.53628173 -0.22537642  0.33125877 -0.3687153 -1.4082798
[14,] -1.81444803 -1.30679373 -0.91961158  1.9577575  2.5800524
[15,] -0.07755911  1.08570035 -0.45708252 -0.8399251  0.2031834

$call
censReg(formula = yAdd ~ x1 + x2, left = 5, data = pData, method = "BFGSR")

$terms
yAdd ~ x1 + x2
attr(,"variables")
list(yAdd, x1, x2)
attr(,"factors")
     x1 x2
yAdd  0  0
x1    1  0
x2    0  1
attr(,"term.labels")
[1] "x1" "x2"
attr(,"order")
[1] 1 1
attr(,"intercept")
[1] 1
attr(,"response")
[1] 1
attr(,".Environment")
<environment: R_GlobalEnv>
attr(,"predvars")
list(yAdd, x1, x2)
attr(,"dataClasses")
     yAdd        x1        x2 
"numeric" "numeric" "numeric" 

$nObs
         Total  Left-censored     Uncensored Right-censored 
            60             20             40              0 

$df.residual
[1] 55

$start
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
  5.4703506   1.0111600   1.6191826  -0.4962510  -0.0620962 

attr(,"class")
[1] "censReg" "maxLik"  "maxim"   "list"   
> 
> 
> ## right-censoring
> pData$yNeg <- - pData$y
> randEffNeg <- censReg( yNeg ~ x1 + x2, data = pData, method = "BFGSR",
+    left = -Inf, right = 0 )
> print( randEffNeg )

Call:
censReg(formula = yNeg ~ x1 + x2, left = -Inf, right = 0, data = pData, 
    method = "BFGSR")

Coefficients:
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
    0.37287    -1.68060    -2.25130    -0.12870    -0.01252 

> maxLik:::summary.maxLik( randEffNeg )
--------------------------------------------
Maximum Likelihood estimation
BFGSR maximization, 63 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -73.19896 
5  free parameters
Estimates:
             Estimate Std. error t value   Pr(> t)    
(Intercept)  0.372870   0.475267  0.7845 0.4327193    
x1          -1.680598   0.209296 -8.0298 9.765e-16 ***
x2          -2.251296   0.674214 -3.3391 0.0008404 ***
logSigmaMu  -0.128695   0.257865 -0.4991 0.6177240    
logSigmaNu  -0.012518   0.129689 -0.0965 0.9231055    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> summary( randEffNeg )

Call:
censReg(formula = yNeg ~ x1 + x2, left = -Inf, right = 0, data = pData, 
    method = "BFGSR")

Observations:
         Total  Left-censored     Uncensored Right-censored 
            60              0             40             20 

Coefficients:
            Estimate Std. error t value  Pr(> t)    
(Intercept)  0.37287    0.47527   0.785  0.43272    
x1          -1.68060    0.20930  -8.030 9.77e-16 ***
x2          -2.25130    0.67421  -3.339  0.00084 ***
logSigmaMu  -0.12870    0.25787  -0.499  0.61772    
logSigmaNu  -0.01252    0.12969  -0.097  0.92311    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

BFGSR maximization, 63 iterations
Return code 2: successive function values within tolerance limit
Log-likelihood: -73.19896 on 5 Df

> coef( randEffNeg )
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
 0.37286953 -1.68059777 -2.25129563 -0.12869516 -0.01251794 
> coef( randEffNeg, logSigma = FALSE )
(Intercept)          x1          x2     sigmaMu     sigmaNu 
  0.3728695  -1.6805978  -2.2512956   0.8792420   0.9875601 
> vcov( randEffNeg )
             (Intercept)           x1           x2   logSigmaMu   logSigmaNu
(Intercept)  0.225879034 -0.020748548 -0.255176421  0.024210326  0.003083049
x1          -0.020748548  0.043804726  0.008738926 -0.013425582 -0.002976551
x2          -0.255176421  0.008738926  0.454564104 -0.017398927 -0.001777711
logSigmaMu   0.024210326 -0.013425582 -0.017398927  0.066494604 -0.002611105
logSigmaNu   0.003083049 -0.002976551 -0.001777711 -0.002611105  0.016819282
> vcov( randEffNeg, logSigma = FALSE )
             (Intercept)           x1           x2      sigmaMu      sigmaNu
(Intercept)  0.225879034 -0.020748548 -0.255176421  0.021286734  0.003044696
x1          -0.020748548  0.043804726  0.008738926 -0.011804335 -0.002939523
x2          -0.255176421  0.008738926  0.454564104 -0.015297866 -0.001755596
sigmaMu      0.021286734 -0.011804335 -0.015297866  0.051404744 -0.002267234
sigmaNu      0.003044696 -0.002939523 -0.001755596 -0.002267234  0.016403424
> logLik( randEffNeg )
'log Lik.' -73.19896 (df=5)
> extractAIC( randEffNeg )
[1] -40.0000 156.3979
> print.default( randEffNeg )
$maximum
[1] -73.19896

$estimate
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
 0.37286953 -1.68059777 -2.25129563 -0.12869516 -0.01251794 

$gradient
 (Intercept)           x1           x2   logSigmaMu   logSigmaNu 
-0.013819482  0.003893520  0.015781801 -0.002500239  0.010858169 

$hessian
            (Intercept)         x1         x2  logSigmaMu  logSigmaNu
(Intercept)  -13.295759  -4.094721 -7.2975891   2.1547836   1.2757201
x1            -4.094721 -26.068598 -1.9875870  -4.4798255  -4.7683920
x2            -7.297589  -1.987587 -6.2320758   0.6417915   0.4268689
logSigmaMu     2.154784  -4.479826  0.6417915 -16.7057461  -3.7134329
logSigmaNu     1.275720  -4.768392  0.4268689  -3.7134329 -61.0646633

$code
[1] 2

$message
[1] "successive function values within tolerance limit"

$last.step
NULL

$fixed
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
      FALSE       FALSE       FALSE       FALSE       FALSE 

$iterations
[1] 63

$type
[1] "BFGSR maximization"

$gradientObs
      (Intercept)          x1          x2 logSigmaMu logSigmaNu
 [1,]  0.85146743 -0.22287983  0.07389661 -0.1449112 -0.9712986
 [2,]  1.70213729 -0.04587987  1.19075157  1.6822629 -1.0124540
 [3,] -1.74919475 -0.33171953 -1.72360523  1.8356182  1.7911128
 [4,] -0.15511639  0.20387424  0.43472126 -0.6888300 -1.4235139
 [5,] -0.13021777 -0.98201804 -0.68653952 -0.6768939 -0.5651892
 [6,] -0.32967920  0.30523965 -0.38334707 -0.4916567 -1.5830210
 [7,]  0.07836807  3.18809498  0.23661640 -0.6778100  6.0394328
 [8,]  0.26450056 -0.37705570 -0.05596690 -0.5396359 -1.1077757
 [9,] -1.14904271 -0.59325981 -0.30321019  0.1357314 -1.6141754
[10,]  0.43245211  0.40433447  0.15156671 -0.4705063 -1.9366116
[11,]  0.02722097 -1.45188758  0.64507611 -0.9196135  2.7477888
[12,] -1.20917201 -0.53910002 -0.60971430  0.2039220 -1.7319525
[13,] -0.53742774  0.22581746 -0.33147810 -0.3672772 -1.4081977
[14,]  1.81377733  1.30868440  0.91978190  1.9591681  2.5752940
[15,]  0.07610733 -1.08835131  0.45723254 -0.8420683  0.2114194

$call
censReg(formula = yNeg ~ x1 + x2, left = -Inf, right = 0, data = pData, 
    method = "BFGSR")

$terms
yNeg ~ x1 + x2
attr(,"variables")
list(yNeg, x1, x2)
attr(,"factors")
     x1 x2
yNeg  0  0
x1    1  0
x2    0  1
attr(,"term.labels")
[1] "x1" "x2"
attr(,"order")
[1] 1 1
attr(,"intercept")
[1] 1
attr(,"response")
[1] 1
attr(,".Environment")
<environment: R_GlobalEnv>
attr(,"predvars")
list(yNeg, x1, x2)
attr(,"dataClasses")
     yNeg        x1        x2 
"numeric" "numeric" "numeric" 

$nObs
         Total  Left-censored     Uncensored Right-censored 
            60              0             40             20 

$df.residual
[1] 55

$start
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
 -0.4703506  -1.0111600  -1.6191826  -0.4962510  -0.0620962 

attr(,"class")
[1] "censReg" "maxLik"  "maxim"   "list"   
> 
> 
> ## right-censoring at -5
> pData$yAddNeg <- - pData$yAdd
> randEffAddNeg <- censReg( yAddNeg ~ x1 + x2, data = pData, method = "BFGSR",
+    left = -Inf, right = -5 )
> print( randEffAddNeg )

Call:
censReg(formula = yAddNeg ~ x1 + x2, left = -Inf, right = -5, 
    data = pData, method = "BFGSR")

Coefficients:
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
    -4.6336     -1.6801     -2.2416     -0.1294     -0.0124 

> maxLik:::summary.maxLik( randEffAddNeg )
--------------------------------------------
Maximum Likelihood estimation
BFGSR maximization, 86 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -73.19882 
5  free parameters
Estimates:
             Estimate Std. error t value   Pr(> t)    
(Intercept) -4.633595   0.474565 -9.7639 < 2.2e-16 ***
x1          -1.680106   0.209236 -8.0297 9.769e-16 ***
x2          -2.241601   0.673938 -3.3261 0.0008806 ***
logSigmaMu  -0.129398   0.258040 -0.5015 0.6160452    
logSigmaNu  -0.012403   0.129692 -0.0956 0.9238092    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> summary( randEffAddNeg )

Call:
censReg(formula = yAddNeg ~ x1 + x2, left = -Inf, right = -5, 
    data = pData, method = "BFGSR")

Observations:
         Total  Left-censored     Uncensored Right-censored 
            60              0             40             20 

Coefficients:
            Estimate Std. error t value  Pr(> t)    
(Intercept)  -4.6336     0.4746  -9.764  < 2e-16 ***
x1           -1.6801     0.2092  -8.030 9.77e-16 ***
x2           -2.2416     0.6739  -3.326 0.000881 ***
logSigmaMu   -0.1294     0.2580  -0.501 0.616045    
logSigmaNu   -0.0124     0.1297  -0.096 0.923809    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

BFGSR maximization, 86 iterations
Return code 2: successive function values within tolerance limit
Log-likelihood: -73.19882 on 5 Df

> coef( randEffAddNeg )
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
-4.63359488 -1.68010591 -2.24160108 -0.12939768 -0.01240328 
> coef( randEffAddNeg, logSigma = FALSE )
(Intercept)          x1          x2     sigmaMu     sigmaNu 
 -4.6335949  -1.6801059  -2.2416011   0.8786245   0.9876733 
> vcov( randEffAddNeg )
             (Intercept)           x1           x2   logSigmaMu   logSigmaNu
(Intercept)  0.225212237 -0.020591555 -0.254679123  0.023869473  0.002984531
x1          -0.020591555  0.043779650  0.008581162 -0.013406319 -0.002971853
x2          -0.254679123  0.008581162  0.454192703 -0.017202239 -0.001531456
logSigmaMu   0.023869473 -0.013406319 -0.017202239  0.066584783 -0.002634343
logSigmaNu   0.002984531 -0.002971853 -0.001531456 -0.002634343  0.016819959
> vcov( randEffAddNeg, logSigma = FALSE )
             (Intercept)           x1           x2      sigmaMu      sigmaNu
(Intercept)  0.225212237 -0.020591555 -0.254679123  0.020972303  0.002947741
x1          -0.020591555  0.043779650  0.008581162 -0.011779120 -0.002935220
x2          -0.254679123  0.008581162  0.454192703 -0.015114309 -0.001512578
sigmaMu      0.020972303 -0.011779120 -0.015114309  0.051402186 -0.002286067
sigmaNu      0.002947741 -0.002935220 -0.001512578 -0.002286067  0.016407846
> logLik( randEffAddNeg )
'log Lik.' -73.19882 (df=5)
> extractAIC( randEffAddNeg )
[1] -40.0000 156.3976
> print.default( randEffAddNeg )
$maximum
[1] -73.19882

$estimate
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
-4.63359488 -1.68010591 -2.24160108 -0.12939768 -0.01240328 

$gradient
  (Intercept)            x1            x2    logSigmaMu    logSigmaNu 
-0.0019515367  0.0008657564  0.0011779471 -0.0010594581  0.0001526402 

$hessian
            (Intercept)         x1         x2  logSigmaMu  logSigmaNu
(Intercept)  -13.317868  -4.096136 -7.3058743   2.1136573   1.3052316
x1            -4.096136 -26.074710 -1.9900846  -4.4841550  -4.7637279
x2            -7.305874  -1.990085 -6.2354075   0.6262122   0.4750766
logSigmaMu     2.113657  -4.484155  0.6262122 -16.6644111  -3.7202999
logSigmaNu     1.305232  -4.763728  0.4750766  -3.7202999 -61.0658815

$code
[1] 2

$message
[1] "successive function values within tolerance limit"

$last.step
NULL

$fixed
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
      FALSE       FALSE       FALSE       FALSE       FALSE 

$iterations
[1] 86

$type
[1] "BFGSR maximization"

$gradientObs
      (Intercept)          x1          x2 logSigmaMu logSigmaNu
 [1,]  0.85282770 -0.22533712  0.07271278 -0.1441359 -0.9621512
 [2,]  1.70278812 -0.04818983  1.18980816  1.6806687 -1.0133124
 [3,] -1.75051381 -0.33331293 -1.72705533  1.8353272  1.8028932
 [4,] -0.15570946  0.20256288  0.43247980 -0.6890199 -1.4340880
 [5,] -0.12959509 -0.98405579 -0.68914150 -0.6770115 -0.5554777
 [6,] -0.33026612  0.30905158 -0.38458349 -0.4920499 -1.5797799
 [7,]  0.08169925  3.18546623  0.23717022 -0.6767919  6.0285005
 [8,]  0.26654655 -0.37866547 -0.05571551 -0.5387364 -1.1089149
 [9,] -1.14827460 -0.59379978 -0.30326580  0.1332403 -1.6169794
[10,]  0.43467817  0.40617189  0.15230662 -0.4689974 -1.9364931
[11,]  0.02824569 -1.44829406  0.64413480 -0.9175792  2.7361013
[12,] -1.21025671 -0.53687483 -0.61289354  0.2053113 -1.7348319
[13,] -0.53612687  0.22532664 -0.33123446 -0.3688506 -1.4082822
[14,]  1.81434648  1.30620915  0.91942706  1.9573353  2.5806969
[15,]  0.07765916 -1.08539282  0.45702812 -0.8397696  0.2022717

$call
censReg(formula = yAddNeg ~ x1 + x2, left = -Inf, right = -5, 
    data = pData, method = "BFGSR")

$terms
yAddNeg ~ x1 + x2
attr(,"variables")
list(yAddNeg, x1, x2)
attr(,"factors")
        x1 x2
yAddNeg  0  0
x1       1  0
x2       0  1
attr(,"term.labels")
[1] "x1" "x2"
attr(,"order")
[1] 1 1
attr(,"intercept")
[1] 1
attr(,"response")
[1] 1
attr(,".Environment")
<environment: R_GlobalEnv>
attr(,"predvars")
list(yAddNeg, x1, x2)
attr(,"dataClasses")
  yAddNeg        x1        x2 
"numeric" "numeric" "numeric" 

$nObs
         Total  Left-censored     Uncensored Right-censored 
            60              0             40             20 

$df.residual
[1] 55

$start
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
 -5.4703506  -1.0111600  -1.6191826  -0.4962510  -0.0620962 

attr(,"class")
[1] "censReg" "maxLik"  "maxim"   "list"   
> 
> 
> ## both right and left censoring
> pData$yBoth <- ifelse( pData$y < 3, pData$y, 3 )
> randEffBoth <- censReg( yBoth ~ x1 + x2, data = pData, method = "BFGSR",
+    left = 0, right = 3 )
> print( randEffBoth )

Call:
censReg(formula = yBoth ~ x1 + x2, left = 0, right = 3, data = pData, 
    method = "BFGSR")

Coefficients:
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
  -0.233287    1.893254    1.968929    0.001606    0.052836 

> maxLik:::summary.maxLik( randEffBoth )
--------------------------------------------
Maximum Likelihood estimation
BFGSR maximization, 103 iterations
Return code 3: Last step could not find a value above the current.
Boundary of parameter space?  
Consider switching to a more robust optimisation method temporarily.
Log-Likelihood: -64.31273 
5  free parameters
Estimates:
              Estimate Std. error t value   Pr(> t)    
(Intercept) -0.2332873  0.5482851 -0.4255   0.67048    
x1           1.8932541  0.3011048  6.2877 3.222e-10 ***
x2           1.9689291  0.8187643  2.4048   0.01618 *  
logSigmaMu   0.0016056  0.2778667  0.0058   0.99539    
logSigmaNu   0.0528360  0.1630092  0.3241   0.74584    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> summary( randEffBoth )

Call:
censReg(formula = yBoth ~ x1 + x2, left = 0, right = 3, data = pData, 
    method = "BFGSR")

Observations:
         Total  Left-censored     Uncensored Right-censored 
            60             20             28             12 

Coefficients:
             Estimate Std. error t value  Pr(> t)    
(Intercept) -0.233287   0.548285  -0.425   0.6705    
x1           1.893254   0.301105   6.288 3.22e-10 ***
x2           1.968929   0.818764   2.405   0.0162 *  
logSigmaMu   0.001606   0.277867   0.006   0.9954    
logSigmaNu   0.052836   0.163009   0.324   0.7458    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

BFGSR maximization, 103 iterations
Return code 3: Last step could not find a value above the current.
Boundary of parameter space?  
Consider switching to a more robust optimisation method temporarily.
Log-likelihood: -64.31273 on 5 Df

> print( summary( randEffBoth ), logSigma = FALSE )

Call:
censReg(formula = yBoth ~ x1 + x2, left = 0, right = 3, data = pData, 
    method = "BFGSR")

Observations:
         Total  Left-censored     Uncensored Right-censored 
            60             20             28             12 

Coefficients:
            Estimate Std. error t value  Pr(> t)    
(Intercept)  -0.2333     0.5483  -0.425  0.67048    
x1            1.8933     0.3011   6.288 3.22e-10 ***
x2            1.9689     0.8188   2.405  0.01618 *  
sigmaMu       1.0016     0.2783   3.599  0.00032 ***
sigmaNu       1.0543     0.1719   6.135 8.54e-10 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

BFGSR maximization, 103 iterations
Return code 3: Last step could not find a value above the current.
Boundary of parameter space?  
Consider switching to a more robust optimisation method temporarily.
Log-likelihood: -64.31273 on 5 Df

> coef( randEffBoth )
 (Intercept)           x1           x2   logSigmaMu   logSigmaNu 
-0.233287350  1.893254133  1.968929081  0.001605597  0.052836010 
> coef( randEffBoth, logSigma = FALSE )
(Intercept)          x1          x2     sigmaMu     sigmaNu 
 -0.2332873   1.8932541   1.9689291   1.0016069   1.0542567 
> vcov( randEffBoth )
            (Intercept)          x1          x2   logSigmaMu   logSigmaNu
(Intercept)  0.30061655 -0.03137608 -0.36399201 -0.015924611 -0.016369426
x1          -0.03137608  0.09066411  0.03178462  0.035193518  0.015928141
x2          -0.36399201  0.03178462  0.67037496  0.018615719  0.024476125
logSigmaMu  -0.01592461  0.03519352  0.01861572  0.077209896  0.004339449
logSigmaNu  -0.01636943  0.01592814  0.02447612  0.004339449  0.026571990
> vcov( randEffBoth, logSigma = FALSE )
            (Intercept)          x1          x2      sigmaMu      sigmaNu
(Intercept)  0.30061655 -0.03137608 -0.36399201 -0.015950200 -0.017257578
x1          -0.03137608  0.09066411  0.03178462  0.035250070  0.016792350
x2          -0.36399201  0.03178462  0.67037496  0.018645632  0.025804120
sigmaMu     -0.01595020  0.03525007  0.01864563  0.077458231  0.004582244
sigmaNu     -0.01725758  0.01679235  0.02580412  0.004582244  0.029533632
> coef( summary( randEffBoth ) )
                Estimate Std. error      t value      Pr(> t)
(Intercept) -0.233287350  0.5482851 -0.425485483 6.704828e-01
x1           1.893254133  0.3011048  6.287691435 3.222216e-10
x2           1.968929081  0.8187643  2.404756911 1.618323e-02
logSigmaMu   0.001605597  0.2778667  0.005778299 9.953896e-01
logSigmaNu   0.052836010  0.1630092  0.324129064 7.458403e-01
> coef( summary( randEffBoth ), logSigma = FALSE )
              Estimate Std. error    t value      Pr(> t)
(Intercept) -0.2332873  0.5482851 -0.4254855 6.704828e-01
x1           1.8932541  0.3011048  6.2876914 3.222216e-10
x2           1.9689291  0.8187643  2.4047569 1.618323e-02
sigmaMu      1.0016069  0.2783132  3.5988481 3.196298e-04
sigmaNu      1.0542567  0.1718535  6.1346242 8.536075e-10
> logLik( randEffBoth )
'log Lik.' -64.31273 (df=5)
> extractAIC( randEffBoth )
[1] -40.0000 138.6255
> print.default( randEffBoth )
$maximum
[1] -64.31273

$estimate
 (Intercept)           x1           x2   logSigmaMu   logSigmaNu 
-0.233287350  1.893254133  1.968929081  0.001605597  0.052836010 

$gradient
 (Intercept)           x1           x2   logSigmaMu   logSigmaNu 
-0.004190027 -0.002194604  0.002930506  0.001773892 -0.002355363 

$hessian
            (Intercept)          x1         x2   logSigmaMu  logSigmaNu
(Intercept) -9.92869316  -1.4916744 -5.3064941  -0.07030087  -0.3228936
x1          -1.49167442 -15.1390048 -0.5455567   6.29563344   7.6302862
x2          -5.30649415  -0.5455567 -4.3906597   0.15225741   1.0774904
logSigmaMu  -0.07030086   6.2956334  0.1522574 -15.79512731  -1.3778814
logSigmaNu  -0.32289361   7.6302862  1.0774904  -1.37788139 -43.1738612

$code
[1] 3

$message
[1] "Last step could not find a value above the current.\nBoundary of parameter space?  \nConsider switching to a more robust optimisation method temporarily."

$last.step
$last.step$theta0
 (Intercept)           x1           x2   logSigmaMu   logSigmaNu 
-0.233283377  1.893292783  1.968931261  0.001596196  0.052683471 

$last.step$f0
[1] -64.31273
attr(,"gradient")
             [,1]        [,2]        [,3]        [,4]       [,5]
 [1,] -0.85425040 -0.10604524 -0.18143247 -0.02343791 -0.8367066
 [2,] -1.41667776 -0.02680528 -0.97178743  1.45659091 -1.1646993
 [3,]  1.29732244  1.02096426  0.92543655  1.09184692  0.1540179
 [4,]  0.07060743 -0.25198943 -0.39838363 -0.70177458 -1.8266444
 [5,]  0.08910043  0.80754878  0.64778811 -0.69076427 -0.2842205
 [6,]  0.55915770  0.49452276  0.42896616 -0.29148913 -0.3601604
 [7,] -0.12054227 -3.06205046 -0.23677444 -0.70631727  6.3449057
 [8,] -0.20973606  0.33560637  0.08325521 -0.59064172 -1.0295415
 [9,]  1.03421019  0.66027909  0.28829239  0.19679180 -1.2971603
[10,] -0.42840809 -0.58577799 -0.11736759 -0.39555997 -1.8005888
[11,] -0.04069986  1.09486797 -0.50815375 -0.86669289  2.0011612
[12,]  1.14021273  0.50515631  0.83229632  0.58491266 -0.7448570
[13,]  0.53462769 -0.28171279  0.34781649 -0.28663582 -1.4337597
[14,] -1.63812261 -1.34743704 -0.83796178  2.12011411  2.7646815
[15,] -0.02105033  0.73886253 -0.29927722 -0.89456689 -0.4818877

$last.step$climb
[1]    68248.96   663988.62    37453.98  -161504.12 -2620602.09


$fixed
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
      FALSE       FALSE       FALSE       FALSE       FALSE 

$iterations
[1] 103

$type
[1] "BFGSR maximization"

$gradientObs
      (Intercept)          x1          x2 logSigmaMu logSigmaNu
 [1,] -0.85408018 -0.10596541 -0.18137401 -0.0235450 -0.8368634
 [2,] -1.41664191 -0.02675966 -0.97173355  1.4564501 -1.1646562
 [3,]  1.29723799  1.02104022  0.92537998  1.0916888  0.1539242
 [4,]  0.07078319 -0.25190543 -0.39813634 -0.7017432 -1.8270717
 [5,]  0.08910183  0.80755660  0.64767871 -0.6906915 -0.2844471
 [6,]  0.55916134  0.49463926  0.42890947 -0.2915113 -0.3605819
 [7,] -0.12056616 -3.06099515 -0.23670792 -0.7062109  6.3421083
 [8,] -0.20979455  0.33564062  0.08322222 -0.5905419 -1.0296721
 [9,]  1.03413392  0.66026378  0.28827558  0.1967923 -1.2972376
[10,] -0.42837090 -0.58553391 -0.11737759 -0.3956650 -1.8008423
[11,] -0.04081455  1.09460567 -0.50811107 -0.8665707  2.0003506
[12,]  1.14027554  0.50512062  0.83230966  0.5850509 -0.7450489
[13,]  0.53448335 -0.28154850  0.34772132 -0.2868223 -1.4340420
[14,] -1.63789470 -1.34702169 -0.83783887  2.1194825  2.7641479
[15,] -0.02120425  0.73866837 -0.29928710 -0.8943887 -0.4824231

$call
censReg(formula = yBoth ~ x1 + x2, left = 0, right = 3, data = pData, 
    method = "BFGSR")

$terms
yBoth ~ x1 + x2
attr(,"variables")
list(yBoth, x1, x2)
attr(,"factors")
      x1 x2
yBoth  0  0
x1     1  0
x2     0  1
attr(,"term.labels")
[1] "x1" "x2"
attr(,"order")
[1] 1 1
attr(,"intercept")
[1] 1
attr(,"response")
[1] 1
attr(,".Environment")
<environment: R_GlobalEnv>
attr(,"predvars")
list(yBoth, x1, x2)
attr(,"dataClasses")
    yBoth        x1        x2 
"numeric" "numeric" "numeric" 

$nObs
         Total  Left-censored     Uncensored Right-censored 
            60             20             28             12 

$df.residual
[1] 55

$start
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
  0.6056357   0.8113032   1.0023997  -0.7545646  -0.2748137 

attr(,"class")
[1] "censReg" "maxLik"  "maxim"   "list"   
> 
> 
> ## re-order observations/individuals
> set.seed( 234 )
> perm <- sample( nId )
> nData2 <- nData
> nData2$id <- NA
> for( i in 1:nId ) {
+    nData2$id[ nData$id == paste( "F", i, sep = "_" ) ] <-
+       paste( "G", perm[ i ], sep = "_" )
+ }
> pData2 <- pdata.frame( nData2, c( "id", "time" ) )
> randEffBfgsr2 <- censReg( y ~ x1 + x2, data = pData2, method = "BFGSR" )
> all.equal( randEffBfgsr2[ -c(11,12) ], randEffBfgsr[ -c(11,12) ] )
[1] "Component 1: Mean relative difference: 8.899623e-07"
[2] "Component 2: Mean relative difference: 0.002167755" 
[3] "Component 3: Mean relative difference: 4.702093"    
[4] "Component 4: Mean relative difference: 0.001300609" 
[5] "Component 5: Mean relative difference: 0.5"         
[6] "Component 6: 1 string mismatch"                     
[7] "Component 7: target is NULL, current is list"       
[8] "Component 9: Mean relative difference: 0.01265823"  
> all.equal( sort( randEffBfgsr2[[ 11 ]] ), sort( randEffBfgsr[[ 11 ]] ) )
[1] "Mean relative difference: 0.001299386"
> 
> # check if the order of observations/individuals influences the likelihood values
> d1c1 <- censReg( y ~ x1 + x2, data = pData, method = "BFGSR", start = coef(randEffBfgsr),
+    iterlim = 0 )
> all.equal( d1c1[-c(5,6,9,12,16)], randEffBfgsr[-c(5,6,9,12,16)] )
[1] "Component 5: target is NULL, current is list"
> d1c1$maximum -  randEffBfgsr$maximum
[1] 0
> 
> d2c2 <- censReg( y ~ x1 + x2, data = pData2, method = "BFGSR", start = coef(randEffBfgsr2),
+    iterlim = 0 )
> all.equal( d2c2[-c(5,6,9,12,16)], randEffBfgsr2[-c(5,6,9,12,16)] )
[1] TRUE
> d2c2$maximum -  randEffBfgsr2$maximum
[1] 0
> 
> d1c2 <- censReg( y ~ x1 + x2, data = pData, method = "BFGSR", 
+    start = coef(randEffBfgsr2), iterlim = 0 )
> d2c2$maximum - d1c2$maximum
[1] 0
> d2c2$gradient - d1c2$gradient
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
          0           0           0           0           0 
> 
> d2c1 <- censReg( y ~ x1 + x2, data = pData2, method = "BFGSR", 
+    start = coef(randEffBfgsr), iterlim = 0 )
> d1c1$maximum - d2c1$maximum
[1] 0
> d1c1$gradient - d2c1$gradient
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
          0           0           0           0           0 
> 
> d2c2$maximum - d2c1$maximum
[1] 6.51442e-05
> d1c1$maximum - d1c2$maximum
[1] -6.51442e-05
> 
> d1cS <- censReg( y ~ x1 + x2, data = pData, method = "BFGSR", 
+    start = randEffBfgsr$start, iterlim = 0 )
> d2cS <- censReg( y ~ x1 + x2, data = pData2, method = "BFGSR", 
+    start = randEffBfgsr$start, iterlim = 0 )
> d1cS$maximum - d2cS$maximum
[1] 0
> d1cS$gradient - d2cS$gradient
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
          0           0           0           0           0 
> 
> 
> ## unbalanced panel data
> nDataUnb <- nData[ -c( 2, 5, 6, 8 ), ]
> pDataUnb <- pdata.frame( nDataUnb, c( "id", "time" ) )
> randEffBfgsrUnb <- censReg( y ~ x1 + x2, data = pDataUnb, method = "BFGSR" )
> print( randEffBfgsrUnb )

Call:
censReg(formula = y ~ x1 + x2, data = pDataUnb, method = "BFGSR")

Coefficients:
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
   -0.02296     1.50294     1.86611    -0.18668     0.02110 

> maxLik:::summary.maxLik( randEffBfgsrUnb )
--------------------------------------------
Maximum Likelihood estimation
BFGSR maximization, 4 iterations
Return code 3: Last step could not find a value above the current.
Boundary of parameter space?  
Consider switching to a more robust optimisation method temporarily.
Log-Likelihood: -71.49672 
5  free parameters
Estimates:
             Estimate Std. error t value  Pr(> t)    
(Intercept) -0.022958   0.460324 -0.0499 0.960222    
x1           1.502943   0.205455  7.3152 2.57e-13 ***
x2           1.866114   0.689904  2.7049 0.006833 ** 
logSigmaMu  -0.186683   0.281550 -0.6631 0.507296    
logSigmaNu   0.021099   0.139846  0.1509 0.880078    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
--------------------------------------------
> summary( randEffBfgsrUnb )

Call:
censReg(formula = y ~ x1 + x2, data = pDataUnb, method = "BFGSR")

Observations:
         Total  Left-censored     Uncensored Right-censored 
            56             17             39              0 

Coefficients:
            Estimate Std. error t value  Pr(> t)    
(Intercept) -0.02296    0.46032  -0.050  0.96022    
x1           1.50294    0.20546   7.315 2.57e-13 ***
x2           1.86611    0.68990   2.705  0.00683 ** 
logSigmaMu  -0.18668    0.28155  -0.663  0.50730    
logSigmaNu   0.02110    0.13985   0.151  0.88008    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

BFGSR maximization, 4 iterations
Return code 3: Last step could not find a value above the current.
Boundary of parameter space?  
Consider switching to a more robust optimisation method temporarily.
Log-likelihood: -71.49672 on 5 Df

> logLik( randEffBfgsrUnb )
'log Lik.' -71.49672 (df=5)
> extractAIC( randEffBfgsrUnb )
[1] -36.0000 152.9934
> print.default( randEffBfgsrUnb )
$maximum
[1] -71.49672

$estimate
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
-0.02295848  1.50294301  1.86611371 -0.18668275  0.02109861 

$gradient
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
 -0.4249125   3.1785753   0.2491605  -0.5476893   2.5900264 

$hessian
            (Intercept)         x1         x2  logSigmaMu logSigmaNu
(Intercept) -14.2102056  -4.099765 -7.6231695  -0.1531391  -2.645589
x1           -4.0997647 -26.217706 -2.0447368   4.1192306  -1.070267
x2           -7.6231695  -2.044737 -6.2164764   0.2757744  -2.162619
logSigmaMu   -0.1531391   4.119231  0.2757744 -13.5768984  -3.054289
logSigmaNu   -2.6455891  -1.070267 -2.1626189  -3.0542889 -52.695128

$code
[1] 3

$message
[1] "Last step could not find a value above the current.\nBoundary of parameter space?  \nConsider switching to a more robust optimisation method temporarily."

$last.step
$last.step$theta0
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
-0.02295848  1.50294301  1.86611371 -0.18668275  0.02109861 

$last.step$f0
[1] -71.49672
attr(,"gradient")
             [,1]         [,2]        [,3]        [,4]        [,5]
 [1,] -0.43292464  0.371300669  0.21650471 -0.44109161  0.75854492
 [2,] -1.81201122  0.286965149 -1.17590279  1.69322984 -0.86212875
 [3,]  1.80692675  0.945162575  1.81786192  1.69181911  1.94375481
 [4,]  0.13441840 -0.059780904 -0.33213583 -0.76214120 -1.88536534
 [5,]  0.01829303  1.214987166  0.73632721 -0.68174503 -0.13767160
 [6,]  0.40877427  0.178042833  0.35916149 -0.49818046 -1.64749439
 [7,] -0.31394536 -2.627633464 -0.25222834 -0.54814752  4.18623240
 [8,] -0.03411451  0.007436108 -0.01951129 -0.39699138  2.46297550
 [9,]  0.97634952  0.962464523  0.24824680 -0.08386674 -1.70854434
[10,] -0.56410546 -0.266405586 -0.22339858 -0.39583743 -2.11440246
[11,] -0.11893045  1.344691101 -0.64920305 -0.76941886  2.31684013
[12,]  1.27224368  0.550046540  0.70671338  0.24696209 -1.82738044
[13,]  0.29216934 -0.029521608  0.20586400 -0.60159878 -1.53598295
[14,] -1.79210899 -0.727737990 -0.84971761  1.63758245  2.67508412
[15,] -0.26594689  1.028558138 -0.53942146 -0.63826376 -0.03443514

$last.step$climb
[1]  0.006641478 -0.017312805 -0.109692660  0.041322794 -0.088375188


$fixed
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
      FALSE       FALSE       FALSE       FALSE       FALSE 

$iterations
[1] 4

$type
[1] "BFGSR maximization"

$gradientObs
      (Intercept)           x1          x2  logSigmaMu  logSigmaNu
 [1,] -0.43292464  0.371300669  0.21650471 -0.44109161  0.75854492
 [2,] -1.81201122  0.286965149 -1.17590279  1.69322984 -0.86212875
 [3,]  1.80692675  0.945162575  1.81786192  1.69181911  1.94375481
 [4,]  0.13441840 -0.059780904 -0.33213583 -0.76214120 -1.88536534
 [5,]  0.01829303  1.214987166  0.73632721 -0.68174503 -0.13767160
 [6,]  0.40877427  0.178042833  0.35916149 -0.49818046 -1.64749439
 [7,] -0.31394536 -2.627633464 -0.25222834 -0.54814752  4.18623240
 [8,] -0.03411451  0.007436108 -0.01951129 -0.39699138  2.46297550
 [9,]  0.97634952  0.962464523  0.24824680 -0.08386674 -1.70854434
[10,] -0.56410546 -0.266405586 -0.22339858 -0.39583743 -2.11440246
[11,] -0.11893045  1.344691101 -0.64920305 -0.76941886  2.31684013
[12,]  1.27224368  0.550046540  0.70671338  0.24696209 -1.82738044
[13,]  0.29216934 -0.029521608  0.20586400 -0.60159878 -1.53598295
[14,] -1.79210899 -0.727737990 -0.84971761  1.63758245  2.67508412
[15,] -0.26594689  1.028558138 -0.53942146 -0.63826376 -0.03443514

$call
censReg(formula = y ~ x1 + x2, data = pDataUnb, method = "BFGSR")

$terms
y ~ x1 + x2
attr(,"variables")
list(y, x1, x2)
attr(,"factors")
   x1 x2
y   0  0
x1  1  0
x2  0  1
attr(,"term.labels")
[1] "x1" "x2"
attr(,"order")
[1] 1 1
attr(,"intercept")
[1] 1
attr(,"response")
[1] 1
attr(,".Environment")
<environment: R_GlobalEnv>
attr(,"predvars")
list(y, x1, x2)
attr(,"dataClasses")
        y        x1        x2 
"numeric" "numeric" "numeric" 

$nObs
         Total  Left-censored     Uncensored Right-censored 
            56             17             39              0 

$df.residual
[1] 51

$start
(Intercept)          x1          x2  logSigmaMu  logSigmaNu 
 0.48299720  1.03002625  1.63470549 -0.47772116 -0.04988945 

attr(,"class")
[1] "censReg" "maxLik"  "maxim"   "list"   
> 
> 
> ## NAs in data
> pDataNa <- pData
> obsNa <- which( ! rownames( pData ) %in% rownames( pDataUnb ) )
> pDataNa$y[ obsNa[ 1:2 ] ] <- NA
> pDataNa$x1[ obsNa[ 3 ] ] <- NA
> pDataNa$x2[ obsNa[ c( 1, 2, 4 ) ] ] <- NA
> randEffBfgsrNa <- censReg( y ~ x1 + x2, data = pDataNa, method = "BFGSR" )
> all.equal( randEffBfgsrNa[ -12 ], randEffBfgsrUnb[ -12 ] )
[1] TRUE
> 
> 
> # returning log-likelihood contributions only (no estimations)
> logLikRandEff <- censReg( y ~ x1 + x2, data = pData, start = coef( randEff ),
+    logLikOnly = TRUE )
> print( logLikRandEff )
 [1] -4.252049 -3.739068 -7.046358 -5.300447 -3.354337 -5.307797 -6.291576
 [8] -1.655650 -4.393946 -3.765898 -6.821870 -5.646158 -4.333350 -5.726405
[15] -5.563914
attr(,"gradient")
             [,1]        [,2]        [,3]       [,4]       [,5]
 [1,] -0.85308353  0.22558520 -0.07261010 -0.1440032 -0.9609402
 [2,] -1.70309357  0.04839424 -1.18987552  1.6807831 -1.0133141
 [3,]  1.75084247  0.33367482  1.72755770  1.8353812  1.8043727
 [4,]  0.15577733 -0.20240007 -0.43224660 -0.6891081 -1.4351382
 [5,]  0.12950026  0.98433620  0.68943625 -0.6770204 -0.5543803
 [6,]  0.33035909 -0.30928416  0.38471147 -0.4921375 -1.5793716
 [7,] -0.08212549 -3.18521871 -0.23724729 -0.6766315  6.0271932
 [8,] -0.26685300  0.37888544  0.05565473 -0.5385828 -1.1091111
 [9,]  1.14824183  0.59396387  0.30328556  0.1329802 -1.6172740
[10,] -0.43505392 -0.40640593 -0.15245982 -0.4687582 -1.9364984
[11,] -0.02839185  1.44795739 -0.64407731 -0.9172655  2.7349924
[12,]  1.21047881  0.53669833  0.61328528  0.2055542 -1.7351236
[13,]  0.53592707 -0.22523044  0.33117482 -0.3691166 -1.4082834
[14,] -1.81460674 -1.30608969 -0.91950989  1.9573174  2.5815580
[15,] -0.07791875  1.08513351 -0.45707928 -0.8393922  0.2013187
> all.equal( sum( logLikRandEff ), c( logLik( randEff ) ) )
[1] TRUE
> logLikStart <- censReg( y ~ x1 + x2, data = pData, 
+    start = c( -0.4, 1.7, 2.2, -0.1, -0.01 ), logLikOnly = TRUE )
> print( logLikStart )
 [1] -4.223693 -3.590625 -7.110342 -5.316228 -3.389378 -5.360380 -6.349353
 [8] -1.661668 -4.433769 -3.774324 -6.788058 -5.699416 -4.385225 -5.593147
[15] -5.548283
attr(,"gradient")
             [,1]        [,2]        [,3]       [,4]       [,5]
 [1,] -0.78780430  0.27899526 -0.03948865 -0.1781187 -1.0281108
 [2,] -1.58232641  0.09231159 -1.09619445  1.4850210 -1.0562683
 [3,]  1.72436737  0.26392132  1.72228285  1.9089216  1.8439353
 [4,]  0.18480626 -0.20993642 -0.40681657 -0.6139118 -1.5330720
 [5,]  0.16156500  0.97006006  0.71388764 -0.6642389 -0.5115526
 [6,]  0.36176010 -0.38785781  0.42046000 -0.4277169 -1.5829540
 [7,] -0.04900991 -3.19667670 -0.23065229 -0.6996566  6.1344398
 [8,] -0.21856969  0.35678338  0.07820116 -0.5684845 -1.0658263
 [9,]  1.13458709  0.55150636  0.30101863  0.1460472 -1.6130954
[10,] -0.35438475 -0.38788784 -0.10704963 -0.5248618 -1.9100687
[11,] -0.01373800  1.42364787 -0.62446618 -0.9654173  2.6815112
[12,]  1.16280483  0.49951850  0.60156788  0.2025718 -1.7537215
[13,]  0.59996890 -0.26781383  0.36925229 -0.2994739 -1.3806520
[14,] -1.71185020 -1.20078722 -0.84865925  1.8183688  2.4960866
[15,] -0.03387939  1.05747706 -0.42268903 -0.9163573  0.1985986
> 
> 
> 
> 
