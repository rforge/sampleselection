
R version 3.1.0 (2014-04-10) -- "Spring Dance"
Copyright (C) 2014 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> 
> options(digits=5)
> 
> ## Leeman Lucas (and many others): binary outcome
> 
> set.seed(0)
> N <- 500
> rho <- 0.7
> library( "mvtnorm" )
> eps <- rmvnorm(N, c(0,0), matrix(c(1,rho,rho,1), 2, 2) )
> xs <- runif(N)
> ysX <- 3*xs + eps[,1]
> ys <- ysX > 0
> xo <- runif(N)
> yoX <- -1 + 2*xo + eps[,2]
> yo <- factor((yoX > 0)*(ys > 0))
>                            # binary outcome, only observable if ys>0
> print(table(ys, yo, exclude=NULL))
       yo
ys        0   1 <NA>
  FALSE  74   0    0
  TRUE  202 224    0
  <NA>    0   0    0
> library( "sampleSelection" )
Loading required package: maxLik
Loading required package: miscTools

Please cite the 'maxLik' package as:
Henningsen, Arne and Toomet, Ott (2011). maxLik: A package for maximum likelihood estimation in R. Computational Statistics 26(3), 443-458. DOI 10.1007/s00180-010-0217-1.

If you have questions, suggestions, or comments regarding the 'maxLik' package, please use a forum or 'tracker' at maxLik's R-Forge site:
https://r-forge.r-project.org/projects/maxlik/
> 
> # estimation with BHHH method
> ss <- selection( ys ~ xs, yo ~ xo, steptol = 1e-12 )
> print( ss )

Call:
 selection(selection = ys ~ xs, outcome = yo ~ xo, steptol = 1e-12) 

Coefficients:
S:(Intercept)           S:xs  O:(Intercept)           O:xo            rho  
       -0.130          3.347         -1.054          1.997          0.803  

> summary( ss )
--------------------------------------------
Tobit 2 model (sample selection model)
Maximum Likelihood estimation
BHHH maximisation, 5 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -398.2 
500 observations (74 censored and 426 observed)
5 free parameters (df = 495)
Probit selection equation:
            Estimate Std. error t value Pr(> t)    
(Intercept)   -0.130      0.130   -1.00    0.32    
xs             3.347      0.392    8.54  <2e-16 ***
Outcome equation:
            Estimate Std. error t value Pr(> t)    
(Intercept)   -1.054      0.124   -8.47  <2e-16 ***
xo             1.997      0.220    9.07  <2e-16 ***
Error terms:
    Estimate Std. error t value Pr(> t)    
rho    0.803      0.158    5.07   4e-07 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
--------------------------------------------
> coef( ss )
S:(Intercept)           S:xs  O:(Intercept)           O:xo            rho  
       -0.130          3.347         -1.054          1.997          0.803  
> coef( ss, part = "outcome" )
(Intercept)           xo  
      -1.05         2.00  
> coef( summary( ss ) )
            Estimate Std. error  t value    Pr(> t)
(Intercept) -0.12973    0.12995 -0.99833 3.1812e-01
xs           3.34671    0.39207  8.53593 1.3903e-17
(Intercept) -1.05441    0.12450 -8.46935 2.4676e-17
xo           1.99744    0.22027  9.06804 1.2117e-19
rho          0.80251    0.15834  5.06815 4.0170e-07
> coef( summary( ss ), part = "outcome" )
            Estimate Std. error t value    Pr(> t)
(Intercept)  -1.0544    0.12450 -8.4694 2.4676e-17
xo            1.9974    0.22027  9.0680 1.2117e-19
> stdEr( ss )
(Intercept)          xs (Intercept)          xo         rho 
    0.12995     0.39207     0.12450     0.22027     0.15834 
> vcov( ss )
            (Intercept)          xs (Intercept)         xo        rho
(Intercept)  0.01688584 -3.9994e-02  5.5008e-04 -0.0024771  0.0069385
xs          -0.03999425  1.5372e-01 -3.2866e-05  0.0098757 -0.0161322
(Intercept)  0.00055008 -3.2866e-05  1.5500e-02 -0.0218237 -0.0043785
xo          -0.00247712  9.8757e-03 -2.1824e-02  0.0485198 -0.0051668
rho          0.00693847 -1.6132e-02 -4.3785e-03 -0.0051668  0.0250726
> vcov( ss, part = "outcome" )
            (Intercept)        xo
(Intercept)    0.015500 -0.021824
xo            -0.021824  0.048520
> nobs( ss )
[1] 500
> nObs( ss )
[1] 500
> fitted( ss )
          1           2           3           4           5           6 
-0.41389739 -0.00371971 -0.90792654  0.64289582 -0.20937787  0.91924979 
          7           8           9          10          11          12 
         NA  0.75465689 -1.01744497 -0.67061430 -0.28678051 -0.44032465 
         13          14          15          16          17          18 
 0.00081885  0.40017518  0.85025926          NA -0.79071332  0.16096832 
         19          20          21          22          23          24 
 0.92678513 -0.86523284  0.73386248 -0.38554601 -0.11126288 -0.70062749 
         25          26          27          28          29          30 
-0.35200080 -0.70174377  0.25000810 -0.58281248  0.73761876          NA 
         31          32          33          34          35          36 
 0.79081470 -0.06020763          NA          NA -0.62530506 -0.44456654 
         37          38          39          40          41          42 
 0.67037677 -0.66347101  0.64530023  0.83710498 -0.50599100  0.62314975 
         43          44          45          46          47          48 
         NA  0.45775067 -0.16329990  0.85400493  0.21461209 -0.72662809 
         49          50          51          52          53          54 
-0.24151378  0.90259907 -0.76090795          NA -0.66150666          NA 
         55          56          57          58          59          60 
 0.52864093  0.41130061  0.44710427          NA          NA -0.14382353 
         61          62          63          64          65          66 
-0.54705087          NA -0.18491889  0.48588378 -0.79642959  0.91090089 
         67          68          69          70          71          72 
 0.57185735  0.90643589 -0.98182317  0.07896417 -0.25200265 -0.14148838 
         73          74          75          76          77          78 
-0.24879453  0.08853673 -0.53457463  0.69152503  0.92921935  0.80361049 
         79          80          81          82          83          84 
 0.91611776  0.26058829 -0.45041385  0.67820736  0.28638897 -0.07726420 
         85          86          87          88          89          90 
 0.20114707  0.32514026  0.28845017          NA  0.31930400  0.94275440 
         91          92          93          94          95          96 
-0.55397898 -0.09870282 -1.02424671 -0.55101587 -0.40193049  0.28813164 
         97          98          99         100         101         102 
 0.44055460 -0.37041621 -0.49460818  0.41845658  0.19792218  0.21104995 
        103         104         105         106         107         108 
-0.62300007  0.75515031          NA -0.71767384  0.31023463 -0.82672028 
        109         110         111         112         113         114 
         NA  0.82619628 -0.75689833  0.12232346  0.69989206 -0.69855168 
        115         116         117         118         119         120 
-0.11394927          NA -0.85589893 -0.47445079 -0.56408667  0.38885699 
        121         122         123         124         125         126 
 0.01676499 -0.45717353          NA  0.76361152 -0.98855150  0.13671079 
        127         128         129         130         131         132 
-0.75298622  0.09940635 -0.14662113          NA -0.00334407          NA 
        133         134         135         136         137         138 
 0.80100519          NA -0.56551188  0.69585888 -0.68955780 -0.87399343 
        139         140         141         142         143         144 
-0.57670273  0.66624333  0.60856739 -0.32951442 -0.67907682          NA 
        145         146         147         148         149         150 
-0.17396245 -0.10221295          NA -0.87627513          NA  0.21529860 
        151         152         153         154         155         156 
-0.65784036 -0.53186971 -0.41770187          NA -0.95036575          NA 
        157         158         159         160         161         162 
 0.08864080 -0.98069251 -1.01827124 -0.66181380 -0.37332850 -0.48782995 
        163         164         165         166         167         168 
-0.68221892 -0.64609000          NA -0.24324675  0.67770666 -0.50349119 
        169         170         171         172         173         174 
 0.44877046 -0.37402102  0.86333607  0.20106122  0.63405006 -0.81015561 
        175         176         177         178         179         180 
 0.05558073  0.49645186 -0.53631556 -0.05772778  0.11292596 -0.08614596 
        181         182         183         184         185         186 
 0.16111034 -1.01273635 -0.28979100 -0.29214784 -0.91976760          NA 
        187         188         189         190         191         192 
 0.47311602  0.54670529 -0.64686993  0.77895784          NA          NA 
        193         194         195         196         197         198 
-0.02886310 -0.78918625 -0.37931117 -0.62895470          NA          NA 
        199         200         201         202         203         204 
-0.38276441 -0.76547948          NA -0.94590339  0.17178310  0.51483727 
        205         206         207         208         209         210 
 0.10299852 -0.00142182 -0.23443491  0.40476424  0.71052564 -0.82575274 
        211         212         213         214         215         216 
         NA -0.32183554 -0.54716325 -0.81322007  0.11003120          NA 
        217         218         219         220         221         222 
 0.10360906  0.12537238  0.89745894 -0.56278994 -0.10114840 -0.73432729 
        223         224         225         226         227         228 
 0.52190499 -0.86315956          NA -0.90309461          NA -0.66668592 
        229         230         231         232         233         234 
 0.37291643  0.85472184  0.42740501 -0.54300518          NA -0.78911384 
        235         236         237         238         239         240 
-0.69448484 -0.89474327 -0.51274229 -0.17528085  0.36668327          NA 
        241         242         243         244         245         246 
-0.75385884  0.14306630  0.72454418 -0.27800393          NA  0.55794502 
        247         248         249         250         251         252 
-0.81854354  0.47216254 -0.80222439  0.65246361  0.01775203  0.13644578 
        253         254         255         256         257         258 
 0.66948665  0.67824332 -0.93637431          NA -0.37032393  0.59261818 
        259         260         261         262         263         264 
 0.00281469 -0.18105904 -0.94170246 -0.55949541 -0.25925718 -0.83226792 
        265         266         267         268         269         270 
         NA          NA  0.64447487          NA          NA  0.37918798 
        271         272         273         274         275         276 
-0.86432360 -0.09718842 -0.80045122 -0.52661275 -0.60090783 -0.68587594 
        277         278         279         280         281         282 
-1.01994170 -0.49186352 -0.81263989 -0.24259997  0.52190331 -0.84294381 
        283         284         285         286         287         288 
-0.37209583 -0.38807570          NA          NA  0.51791569  0.53872446 
        289         290         291         292         293         294 
-0.60717158 -0.12328930 -0.41054778  0.03325478  0.88623886 -0.75619008 
        295         296         297         298         299         300 
-0.32797607          NA  0.11730511  0.02378583  0.69112244  0.48247137 
        301         302         303         304         305         306 
-0.15389010  0.82129150  0.06133678  0.08612711 -0.84006624 -0.27788155 
        307         308         309         310         311         312 
 0.89804088 -0.61207318 -0.61484699 -0.49079075 -0.81627266          NA 
        313         314         315         316         317         318 
-0.48624373  0.23249017  0.86383881 -0.91240166 -0.97866966 -0.97359123 
        319         320         321         322         323         324 
-0.22162857 -0.55052778 -0.83750130  0.66514266 -0.75201265  0.04194315 
        325         326         327         328         329         330 
-0.03426958          NA  0.30979533  0.44055164  0.84818576 -0.33010981 
        331         332         333         334         335         336 
-0.36271005 -0.14711314          NA  0.00241779 -1.04877425  0.66712793 
        337         338         339         340         341         342 
 0.05793438          NA  0.84380641  0.74361969  0.33170458          NA 
        343         344         345         346         347         348 
-0.12921935          NA -0.17733336  0.88294650 -0.49602823  0.90201733 
        349         350         351         352         353         354 
 0.30969035  0.75927518  0.28383090 -0.22933906  0.80597550 -0.75647389 
        355         356         357         358         359         360 
-1.02040971  0.09711446          NA -0.47641810 -0.50231276  0.16070790 
        361         362         363         364         365         366 
         NA -0.47318804          NA  0.58656985          NA  0.91450003 
        367         368         369         370         371         372 
 0.17490463  0.60840804 -0.58178409  0.48541711 -0.93701295 -0.02593003 
        373         374         375         376         377         378 
 0.66540861  0.91386884 -0.26190196 -0.11904266 -0.21417670  0.77451309 
        379         380         381         382         383         384 
-0.09101704  0.82799141 -0.80637001  0.07156143  0.40618953          NA 
        385         386         387         388         389         390 
 0.20069100          NA -0.88310549  0.29625071          NA -0.86245754 
        391         392         393         394         395         396 
-0.25762256          NA  0.53268914  0.19306251 -0.24541881 -1.04924146 
        397         398         399         400         401         402 
 0.16119133  0.12874602  0.76357234          NA          NA -0.54487536 
        403         404         405         406         407         408 
         NA -0.00524702 -0.14744007 -0.01230207 -0.88323428  0.13915779 
        409         410         411         412         413         414 
 0.31086971  0.04289522          NA -0.46269643 -0.48613926          NA 
        415         416         417         418         419         420 
-0.71949498  0.77801318  0.92487128  0.43901071 -0.07059479  0.80881898 
        421         422         423         424         425         426 
 0.17808683 -0.27200539 -0.66215682  0.38390246  0.81154003  0.32910280 
        427         428         429         430         431         432 
 0.72047461 -0.59766384  0.03732739 -0.64094165  0.01831346  0.88166144 
        433         434         435         436         437         438 
 0.54999935 -0.64683881 -0.25414272  0.60171492 -0.17328618 -0.26531562 
        439         440         441         442         443         444 
-0.99271119 -0.78302547  0.29822351 -0.92959345  0.93810987 -0.82700321 
        445         446         447         448         449         450 
         NA -1.00330187 -0.83806783 -0.14740671  0.54392222  0.61309899 
        451         452         453         454         455         456 
         NA -0.48949136  0.22974795          NA  0.01843183 -0.19260878 
        457         458         459         460         461         462 
 0.39197183 -0.70660750 -0.41458177 -0.27944849          NA -0.49927272 
        463         464         465         466         467         468 
 0.37466413 -0.39815945  0.14695909 -0.00791082  0.66448286  0.00976339 
        469         470         471         472         473         474 
-0.83185121          NA -0.92869114  0.35435316          NA  0.50622104 
        475         476         477         478         479         480 
 0.51185901  0.04932557  0.65361537 -0.63520330 -0.59488863          NA 
        481         482         483         484         485         486 
-0.16598286  0.26402923 -0.89896510 -0.36879276  0.55843032 -0.35735327 
        487         488         489         490         491         492 
-0.95037810  0.66994320  0.05800187          NA  0.46623231  0.03527581 
        493         494         495         496         497         498 
-0.09987043 -0.36043732          NA  0.84469171 -0.53232141 -0.84107230 
        499         500 
-0.54754405 -0.69306540 
> all.equal( fitted( ss ), fitted( ss, part = "outcome" ) )
[1] TRUE
> fitted( ss, part = "selection" )
      1       2       3       4       5       6       7       8       9      10 
0.87816 0.99735 0.99906 0.99721 0.90909 0.69590 0.55792 0.96584 0.54211 0.94910 
     11      12      13      14      15      16      17      18      19      20 
0.92659 0.51259 0.96856 0.99411 0.96957 0.48552 0.88389 0.58934 0.48045 0.99637 
     21      22      23      24      25      26      27      28      29      30 
0.83213 0.80378 0.99566 0.89562 0.46188 0.51821 0.98968 0.54614 0.54210 0.97740 
     31      32      33      34      35      36      37      38      39      40 
0.89499 0.90520 0.55521 0.78748 0.99426 0.56952 0.78706 0.62789 0.98172 0.99918 
     41      42      43      44      45      46      47      48      49      50 
0.71875 0.86765 0.60504 0.99361 0.53575 0.99367 0.61209 0.99328 0.85984 0.97330 
     51      52      53      54      55      56      57      58      59      60 
0.99836 0.58800 0.98824 0.65306 0.77207 0.99305 0.96861 0.57514 0.65565 0.98668 
     61      62      63      64      65      66      67      68      69      70 
0.77969 0.80612 0.96023 0.84743 0.99932 0.72222 0.96765 0.89234 0.95325 0.99507 
     71      72      73      74      75      76      77      78      79      80 
0.46252 0.98338 0.99757 0.89178 0.99790 0.99497 0.51803 0.99887 0.93823 0.93762 
     81      82      83      84      85      86      87      88      89      90 
0.70668 0.98420 0.95562 0.97196 0.81638 0.66251 0.99660 0.67827 0.96654 0.99911 
     91      92      93      94      95      96      97      98      99     100 
0.95132 0.99512 0.97975 0.99287 0.49439 0.95907 0.60725 0.98489 0.99830 0.95956 
    101     102     103     104     105     106     107     108     109     110 
0.96380 0.94517 0.98089 0.96708 0.55478 0.65277 0.99923 0.99929 0.80420 0.99396 
    111     112     113     114     115     116     117     118     119     120 
0.98495 0.88719 0.88462 0.99775 0.99562 0.77577 0.68318 0.99893 0.99624 0.84859 
    121     122     123     124     125     126     127     128     129     130 
0.99641 0.46183 0.72183 0.99830 0.51321 0.99733 0.98054 0.72723 0.46091 0.55384 
    131     132     133     134     135     136     137     138     139     140 
0.99263 0.49269 0.99313 0.88273 0.99373 0.49275 0.86339 0.71408 0.99904 0.96088 
    141     142     143     144     145     146     147     148     149     150 
0.91094 0.99478 0.66443 0.71229 0.85011 0.91606 0.58534 0.96997 0.58195 0.99894 
    151     152     153     154     155     156     157     158     159     160 
0.96521 0.66840 0.94584 0.52077 0.80445 0.49160 0.89507 0.98775 0.90941 0.92832 
    161     162     163     164     165     166     167     168     169     170 
0.87307 0.99344 0.99899 0.91248 0.78695 0.98007 0.99171 0.96715 0.86394 0.94238 
    171     172     173     174     175     176     177     178     179     180 
0.63794 0.77717 0.67437 0.99795 0.96014 0.84527 0.79384 0.99116 0.96028 0.96100 
    181     182     183     184     185     186     187     188     189     190 
0.97670 0.99901 0.99273 0.99222 0.64854 0.86459 0.99829 0.93717 0.48528 0.91571 
    191     192     193     194     195     196     197     198     199     200 
0.48455 0.47266 0.99735 0.99892 0.99787 0.99689 0.61168 0.72976 0.98539 0.97940 
    201     202     203     204     205     206     207     208     209     210 
0.56998 0.96880 0.99878 0.61824 0.94806 0.99860 0.91140 0.88792 0.86293 0.96306 
    211     212     213     214     215     216     217     218     219     220 
0.58924 0.98076 0.99460 0.65763 0.93831 0.63119 0.98518 0.93041 0.71422 0.98847 
    221     222     223     224     225     226     227     228     229     230 
0.83797 0.94972 0.96831 0.99210 0.50125 0.97630 0.67017 0.98737 0.77524 0.55531 
    231     232     233     234     235     236     237     238     239     240 
0.98800 0.99141 0.67002 0.72214 0.62865 0.82731 0.98114 0.91982 0.72990 0.51459 
    241     242     243     244     245     246     247     248     249     250 
0.99644 0.92087 0.50788 0.83516 0.85158 0.74564 0.71594 0.79939 0.80886 0.99789 
    251     252     253     254     255     256     257     258     259     260 
0.99230 0.58645 0.99201 0.89585 0.72907 0.45730 0.48864 0.76031 0.72847 0.81629 
    261     262     263     264     265     266     267     268     269     270 
0.99820 0.99870 0.93531 0.66734 0.69232 0.69545 0.94006 0.55635 0.99430 0.96266 
    271     272     273     274     275     276     277     278     279     280 
0.99906 0.99745 0.98721 0.60115 0.65875 0.83939 0.99926 0.99830 0.95165 0.75696 
    281     282     283     284     285     286     287     288     289     290 
0.99845 0.99162 0.99810 0.97986 0.47600 0.57580 0.99885 0.99776 0.91882 0.99385 
    291     292     293     294     295     296     297     298     299     300 
0.70645 0.82038 0.94983 0.68535 0.95074 0.84974 0.94271 0.99416 0.91099 0.79628 
    301     302     303     304     305     306     307     308     309     310 
0.99863 0.48890 0.99665 0.91205 0.97646 0.99344 0.79072 0.61126 0.99788 0.89045 
    311     312     313     314     315     316     317     318     319     320 
0.99174 0.59528 0.84195 0.95536 0.81987 0.91422 0.88939 0.93302 0.90988 0.77738 
    321     322     323     324     325     326     327     328     329     330 
0.97991 0.74867 0.99523 0.99499 0.96724 0.95388 0.51039 0.90242 0.97801 0.44926 
    331     332     333     334     335     336     337     338     339     340 
0.99720 0.58256 0.57561 0.99327 0.48765 0.84497 0.99382 0.59871 0.85140 0.83532 
    341     342     343     344     345     346     347     348     349     350 
0.98616 0.85399 0.89058 0.81625 0.99897 0.98539 0.99771 0.99866 0.99087 0.99628 
    351     352     353     354     355     356     357     358     359     360 
0.99454 0.99789 0.99600 0.86673 0.99735 0.99462 0.67853 0.66156 0.99878 0.91282 
    361     362     363     364     365     366     367     368     369     370 
0.55276 0.99923 0.46942 0.93656 0.90287 0.87332 0.99027 0.78982 0.98062 0.99343 
    371     372     373     374     375     376     377     378     379     380 
0.98890 0.99921 0.95435 0.98118 0.78545 0.88468 0.95922 0.99919 0.99903 0.72574 
    381     382     383     384     385     386     387     388     389     390 
0.88221 0.99003 0.98555 0.84069 0.98541 0.64945 0.99782 0.99777 0.63010 0.49624 
    391     392     393     394     395     396     397     398     399     400 
0.85507 0.87254 0.97306 0.94113 0.84166 0.83442 0.96319 0.51595 0.88728 0.77112 
    401     402     403     404     405     406     407     408     409     410 
0.66817 0.52797 0.51844 0.99911 0.99429 0.49053 0.95434 0.47176 0.99324 0.99191 
    411     412     413     414     415     416     417     418     419     420 
0.46239 0.99544 0.99689 0.90036 0.97687 0.89786 0.83067 0.99252 0.98708 0.99839 
    421     422     423     424     425     426     427     428     429     430 
0.97208 0.52281 0.99020 0.99811 0.98676 0.96436 0.96113 0.86414 0.95855 0.99796 
    431     432     433     434     435     436     437     438     439     440 
0.78270 0.99580 0.98352 0.99801 0.80596 0.87704 0.99814 0.99352 0.95410 0.99579 
    441     442     443     444     445     446     447     448     449     450 
0.99850 0.81129 0.86124 0.99898 0.89875 0.96068 0.99460 0.92931 0.99734 0.98673 
    451     452     453     454     455     456     457     458     459     460 
0.61786 0.97987 0.99455 0.74986 0.99713 0.92958 0.83493 0.99932 0.99207 0.92602 
    461     462     463     464     465     466     467     468     469     470 
0.76802 0.87570 0.80715 0.99271 0.90465 0.98057 0.75250 0.80460 0.99857 0.63195 
    471     472     473     474     475     476     477     478     479     480 
0.93117 0.99467 0.83950 0.95562 0.51582 0.98474 0.94852 0.87700 0.72579 0.51401 
    481     482     483     484     485     486     487     488     489     490 
0.84219 0.94906 0.85891 0.99929 0.51014 0.54415 0.98357 0.66043 0.96505 0.56908 
    491     492     493     494     495     496     497     498     499     500 
0.98059 0.85696 0.69888 0.98432 0.48904 0.90983 0.99912 0.89455 0.99840 0.57957 
> residuals( ss )
  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18  19  20 
 NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA 
 21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40 
 NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA 
 41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60 
 NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA 
 61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80 
 NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA 
 81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 
 NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA 
101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 
 NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA 
121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 
 NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA 
141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 
 NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA 
161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 
 NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA 
181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 
 NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA 
201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 
 NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA 
221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 
 NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA 
241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 
 NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA 
261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 
 NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA 
281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 
 NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA 
301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 
 NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA 
321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 
 NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA 
341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 
 NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA 
361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 
 NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA 
381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 
 NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA 
401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 
 NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA 
421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 
 NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA 
441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 
 NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA 
461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 
 NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA 
481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 
 NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA 
Warning message:
In Ops.factor(oResponse, fitted(object)) : - not meaningful for factors
> all.equal( residuals( ss ), residuals( ss, part = "outcome" ) )
[1] TRUE
Warning messages:
1: In Ops.factor(oResponse, fitted(object)) : - not meaningful for factors
2: In Ops.factor(oResponse, fitted(object)) : - not meaningful for factors
> residuals( ss, part = "selection" )
        1         2         3         4         5         6         7         8 
 0.509764  0.072879  0.043470  0.074741  0.436602  0.851535 -1.277697  0.263649 
        9        10        11        12        13        14        15        16 
 1.106604  0.323232  0.390487  1.156103  0.252768  0.108734  0.248607 -1.152910 
       17        18        19        20        21        22        23        24 
 0.496839  1.028356  1.210819  0.085305  0.606235  0.660954  0.093287  0.469556 
       25        26        27        28        29        30        31        32 
 1.242933  1.146621  0.144020  1.099899  1.106615 -2.753032  0.471058  0.446319 
       33        34        35        36        37        38        39        40 
-1.272910 -1.759948  0.107290  1.061098  0.692036  0.964764  0.192069  0.040614 
       41        42        43        44        45        46        47        48 
 0.812696  0.532861 -1.363055  0.113234  1.117211  0.112672  0.990835  0.116141 
       49        50        51        52        53        54        55        56 
 0.549562  0.232667  0.057374 -1.331721  0.153793 -1.455055  0.719273  0.118090 
       57        58        59        60        61        62        63        64 
 0.252557 -1.308426 -1.460201  0.163794  0.705491 -1.811352  0.284899  0.575406 
       65        66        67        68        69        70        71        72 
 0.036769  0.806756  0.256455  0.477311  0.309432  0.099455  1.241818  0.183062 
       73        74        75        76        77        78        79        80 
 0.069777  0.478625  0.064876  0.100404  1.146936  0.047576  0.357102  0.358908 
       81        82        83        84        85        86        87        88 
 0.833285  0.178487  0.301326  0.238516  0.636978  0.907428  0.082559 -1.506023 
       89        90        91        92        93        94        95        96 
 0.260912  0.042167  0.315941  0.098921  0.202263  0.119650  1.186961  0.289122 
       97        98        99       100       101       102       103       104 
 0.998808  0.174519  0.058284  0.287336  0.271568  0.335843  0.196424  0.258758 
      105       106       107       108       109       110       111       112 
-1.272159  0.923610  0.039250  0.037750 -1.805925  0.110066  0.174125  0.489276 
      113       114       115       116       117       118       119       120 
 0.495180  0.067185  0.093664 -1.729197  0.872930  0.046177  0.086811  0.573020 
      121       122       123       124       125       126       127       128 
 0.084797  1.243028 -1.599697  0.058407  1.155058  0.073096  0.198259  0.798145 
      129       130       131       132       133       134       135       136 
 1.244633 -1.270501  0.121633 -1.165018  0.117450 -2.070394  0.112118  1.189751 
      137       138       139       140       141       142       143       144 
 0.542014  0.820683  0.043787  0.282492  0.431926  0.102358  0.904233 -1.578484 
      145       146       147       148       149       150       151       152 
 0.569902  0.418757 -1.326873  0.246938 -1.320717  0.045993  0.266123  0.897621 
      153       154       155       156       157       158       159       160 
 0.333717 -1.212901  0.659690 -1.163182  0.470852  0.157022  0.435803  0.385686 
      161       162       163       164       165       166       167       168 
 0.521033  0.114715  0.044872  0.427986 -1.758545  0.200642  0.128993  0.258454 
      169       170       171       172       173       174       175       176 
 0.540847  0.344525  0.948164  0.710057  0.887675  0.064032  0.285237  0.579821 
      177       178       179       180       181       182       183       184 
 0.679512  0.133296  0.284705  0.282054  0.217162  0.044617  0.120793  0.125019 
      185       186       187       188       189       190       191       192 
 0.930621 -1.999730  0.058445  0.360264  1.202523  0.419666 -1.151272 -1.131294 
      193       194       195       196       197       198       199       200 
 0.072820  0.046511  0.065328  0.078912 -1.375446 -1.617679  0.171589  0.204033 
      201       202       203       204       205       206       207       208 
-1.299164  0.251775  0.049400  0.980699  0.326623  0.052925  0.430740  0.487588 
      209       210       211       212       213       214       215       216 
 0.543000  0.274368 -1.333971  0.197100  0.104043  0.915539  0.356847 -1.412432 
      217       218       219       220       221       222       223       224 
 0.172819  0.379820  0.820441  0.152329  0.594605  0.321222  0.253777  0.125966 
      225       226       227       228       229       230       231       232 
-1.179527  0.219039 -1.489414  0.159471  0.713556  1.084647  0.155380  0.131321 
      233       234       235       236       237       238       239       240 
-1.489108  0.806886  0.963511  0.615759  0.195129  0.408835  0.793530 -1.202296 
      241       242       243       244       245       246       247       248 
 0.084423  0.406045  1.164045  0.600223 -1.953308  0.766174  0.817512  0.669197 
      249       250       251       252       253       254       255       256 
 0.651346  0.065057  0.124364  1.033116  0.126675  0.469000  0.794960 -1.105618 
      257       258       259       260       261       262       263       264 
 1.196777  0.740316  0.795995  0.637153  0.059947  0.051031  0.365732  0.899391 
      265       266       267       268       269       270       271       272 
-1.535386 -1.542019  0.351601 -1.274933 -3.214473  0.275887  0.043349  0.071397 
      273       274       275       276       277       278       279       280 
 0.160447  1.008868  0.913679  0.591752  0.038459  0.058299  0.314821  0.746253 
      281       282       283       284       285       286       287       288 
 0.055749  0.129724  0.061699  0.201734 -1.136900 -1.309612  0.047990  0.066916 
      289       290       291       292       293       294       295       296 
 0.411507  0.111100  0.833667  0.629274  0.320842  0.869279  0.317849 -1.946981 
      297       298       299       300       301       302       303       304 
 0.343507  0.108255  0.431796  0.674988  0.052438  1.196319  0.081900  0.429099 
      305       306       307       308       309       310       311       312 
 0.218257  0.114744  0.685283  0.992206  0.065088  0.481714  0.128766 -1.345032 
      313       314       315       316       317       318       319       320 
 0.586580  0.302210  0.630245  0.423508  0.484193  0.372370  0.434600  0.709678 
      321       322       323       324       325       326       327       328 
 0.201462  0.760870  0.097771  0.100213  0.258121 -2.480564  1.159806  0.453147 
      329       330       331       332       333       334       335       336 
 0.210875  1.265033  0.074944  1.039546 -1.309283  0.116196  1.198464  0.580443 
      337       338       339       340       341       342       343       344 
 0.111325 -1.351340  0.567223  0.599902  0.166942 -1.961684  0.481413 -1.840742 
      345       346       347       348       349       350       351       352 
 0.045475  0.171591  0.067778  0.051781  0.135406  0.086358  0.104607  0.065017 
      353       354       355       356       357       358       359       360 
 0.089563  0.534843  0.072813  0.103902 -1.506552  0.909022  0.049369  0.427115 
      361       362       363       364       365       366       367       368 
-1.268583  0.039139 -1.125867  0.362063 -2.159480  0.520481  0.139839  0.686946 
      369       370       371       372       373       374       375       376 
 0.197855  0.114846  0.149444  0.039858  0.305684  0.194940  0.694972  0.495027 
      377       378       379       380       381       382       383       384 
 0.288567  0.040192  0.044022  0.800700  0.500654  0.141553  0.170626 -1.916704 
      385       386       387       388       389       390       391       392 
 0.171435 -1.447923  0.066139  0.066822 -1.410342  1.183798  0.559602 -2.029765 
      393       394       395       396       397       398       399       400 
 0.233721  0.348347  0.587159  0.601699  0.273890  1.150436  0.489075 -1.717289 
      401       402       403       404       405       406       407       408 
-1.485346  1.130231 -1.208911  0.042116  0.107016  1.193544  0.305726  1.225787 
      409       410       411       412       413       414       415       416 
 0.116507  0.127475 -1.114103  0.095598  0.078898 -2.147656  0.216325  0.464203 
      417       418       419       420       421       422       423       424 
 0.609129  0.122576  0.161284  0.056754  0.237997  1.138896  0.140338  0.061547 
      425       426       427       428       429       430       431       432 
 0.163282  0.269417  0.281582  0.540413  0.290969  0.063841  0.700007  0.091719 
      433       434       435       436       437       438       439       440 
 0.182290  0.063074  0.656843  0.512259  0.061095  0.114064  0.306534  0.091867 
      441       442       443       444       445       446       447       448 
 0.054730  0.646720  0.546590  0.045129 -2.140177  0.283250  0.104045  0.382926 
      449       450       451       452       453       454       455       456 
 0.072933  0.163443 -1.387069  0.201663  0.104530 -1.664761  0.075871  0.382163 
      457       458       459       460       461       462       463       464 
 0.600685  0.036970  0.126167  0.392065 -1.709438  0.515225  0.654596  0.120970 
      465       466       467       468       469       470       471       472 
 0.447687  0.198113  0.754130  0.659409  0.053495 -1.413886  0.377648  0.103421 
      473       474       475       476       477       478       479       480 
-1.912840  0.301329  1.150653  0.175348  0.325114  0.512355  0.800626 -1.201300 
      481       482       483       484       485       486       487       488 
 0.586098  0.323369  0.551535  0.037802  1.160234  1.103197  0.182005  0.910891 
      489       490       491       492       493       494       495       496 
 0.266725 -1.297566  0.198006  0.555642  0.846497  0.177781 -1.158852  0.434730 
      497       498       499       500 
 0.041895  0.472088  0.056534  1.044472 
> model.matrix( ss )
    (Intercept)        xo
1             1 0.3206670
2             1 0.5260191
3             1 0.0733354
4             1 0.8497418
5             1 0.4230580
6             1 0.9880961
7            NA        NA
8             1 0.9056940
9             1 0.0185059
10            1 0.1921438
11            1 0.3843070
12            1 0.3074364
13            1 0.5282913
14            1 0.7282257
15            1 0.9535565
16           NA        NA
17            1 0.1320172
18            1 0.6084688
19            1 0.9918686
20            1 0.0947097
21            1 0.8952835
22            1 0.3348609
23            1 0.4721785
24            1 0.1771180
25            1 0.3516550
26            1 0.1765591
27            1 0.6530458
28            1 0.2361011
29            1 0.8971640
30           NA        NA
31            1 0.9237961
32            1 0.4977389
33           NA        NA
34           NA        NA
35            1 0.2148275
36            1 0.3053128
37            1 0.8634999
38            1 0.1957201
39            1 0.8509455
40            1 0.9469710
41            1 0.2745611
42            1 0.8398560
43           NA        NA
44            1 0.7570504
45            1 0.4461266
46            1 0.9554318
47            1 0.6353251
48            1 0.1641010
49            1 0.4069694
50            1 0.9797600
51            1 0.1469391
52           NA        NA
53            1 0.1967035
54           NA        NA
55            1 0.7925410
56            1 0.7337955
57            1 0.7517203
58           NA        NA
59           NA        NA
60            1 0.4558772
61            1 0.2540048
62           NA        NA
63            1 0.4353032
64            1 0.7711350
65            1 0.1291554
66            1 0.9839163
67            1 0.8141769
68            1 0.9816809
69            1 0.0363397
70            1 0.5674141
71            1 0.4017183
72            1 0.4570463
73            1 0.4033244
74            1 0.5722065
75            1 0.2602510
76            1 0.8740876
77            1 0.9930873
78            1 0.9302022
79            1 0.9865280
80            1 0.6583427
81            1 0.3023853
82            1 0.8674202
83            1 0.6712596
84            1 0.4891996
85            1 0.6285839
86            1 0.6906601
87            1 0.6722915
88           NA        NA
89            1 0.6877382
90            1 0.9998635
91            1 0.2505363
92            1 0.4784666
93            1 0.0151007
94            1 0.2520198
95            1 0.3266581
96            1 0.6721320
97            1 0.7484413
98            1 0.3424355
99            1 0.2802598
100           1 0.7373781
101           1 0.6269694
102           1 0.6335417
103           1 0.2159815
104           1 0.9059410
105          NA        NA
106           1 0.1685839
107           1 0.6831977
108           1 0.1139907
109          NA        NA
110           1 0.9415096
111           1 0.1489464
112           1 0.5891215
113           1 0.8782764
114           1 0.1781572
115           1 0.4708335
116          NA        NA
117           1 0.0993826
118           1 0.2903515
119           1 0.2454760
120           1 0.7225593
121           1 0.5362746
122           1 0.2990012
123          NA        NA
124           1 0.9101771
125           1 0.0329712
126           1 0.5963244
127           1 0.1509050
128           1 0.5776483
129           1 0.4544767
130          NA        NA
131           1 0.5262071
132          NA        NA
133           1 0.9288979
134          NA        NA
135           1 0.2447625
136           1 0.8762573
137           1 0.1826599
138           1 0.0903238
139           1 0.2391599
140           1 0.8614305
141           1 0.8325555
142           1 0.3629126
143           1 0.1879071
144          NA        NA
145           1 0.4407884
146           1 0.4767092
147          NA        NA
148           1 0.0891814
149          NA        NA
150           1 0.6356688
151           1 0.1985390
152           1 0.2616052
153           1 0.3187623
154          NA        NA
155           1 0.0520886
156          NA        NA
157           1 0.5722586
158           1 0.0369057
159           1 0.0180923
160           1 0.1965497
161           1 0.3409775
162           1 0.2836533
163           1 0.1863341
164           1 0.2044217
165          NA        NA
166           1 0.4061018
167           1 0.8671695
168           1 0.2758126
169           1 0.7525545
170           1 0.3406308
171           1 0.9601033
172           1 0.6285409
173           1 0.8453132
174           1 0.1222836
175           1 0.5557073
176           1 0.7764258
177           1 0.2593794
178           1 0.4989804
179           1 0.5844167
180           1 0.4847530
181           1 0.6085399
182           1 0.0208633
183           1 0.3827998
184           1 0.3816199
185           1 0.0674073
186          NA        NA
187           1 0.7647429
188           1 0.8015848
189           1 0.2040312
190           1 0.9178601
191          NA        NA
192          NA        NA
193           1 0.5134312
194           1 0.1327818
195           1 0.3379823
196           1 0.2130004
197          NA        NA
198          NA        NA
199           1 0.3362535
200           1 0.1446504
201          NA        NA
202           1 0.0543226
203           1 0.6138831
204           1 0.7856303
205           1 0.5794467
206           1 0.5271695
207           1 0.4105134
208           1 0.7305232
209           1 0.8836001
210           1 0.1144751
211          NA        NA
212           1 0.3667570
213           1 0.2539486
214           1 0.1207494
215           1 0.5829675
216          NA        NA
217           1 0.5797523
218           1 0.5906479
219           1 0.9771867
220           1 0.2461252
221           1 0.4772422
222           1 0.1602464
223           1 0.7891687
224           1 0.0957476
225          NA        NA
226           1 0.0757545
227          NA        NA
228           1 0.1941105
229           1 0.7145788
230           1 0.9557907
231           1 0.7418581
232           1 0.2560303
233          NA        NA
234           1 0.1328180
235           1 0.1801932
236           1 0.0799355
237           1 0.2711811
238           1 0.4401284
239           1 0.7114582
240          NA        NA
241           1 0.1504681
242           1 0.5995063
243           1 0.8906183
244           1 0.3887009
245          NA        NA
246           1 0.8072118
247           1 0.1180843
248           1 0.7642656
249           1 0.1262543
250           1 0.8545318
251           1 0.5367687
252           1 0.5961918
253           1 0.8630542
254           1 0.8674382
255           1 0.0590933
256          NA        NA
257           1 0.3424817
258           1 0.8245707
259           1 0.5292905
260           1 0.4372356
261           1 0.0564258
262           1 0.2477746
263           1 0.3980863
264           1 0.1112133
265          NA        NA
266          NA        NA
267           1 0.8505323
268          NA        NA
269          NA        NA
270           1 0.7177186
271           1 0.0951649
272           1 0.4792247
273           1 0.1271421
274           1 0.2642370
275           1 0.2270418
276           1 0.1845032
277           1 0.0172560
278           1 0.2816339
279           1 0.1210399
280           1 0.4064256
281           1 0.7891679
282           1 0.1058685
283           1 0.3415946
284           1 0.3335944
285          NA        NA
286          NA        NA
287           1 0.7871715
288           1 0.7975892
289           1 0.2239059
290           1 0.4661575
291           1 0.3223440
292           1 0.5445300
293           1 0.9715694
294           1 0.1493010
295           1 0.3636828
296          NA        NA
297           1 0.5866091
298           1 0.5397895
299           1 0.8738860
300           1 0.7694266
301           1 0.4508375
302           1 0.9390541
303           1 0.5585891
304           1 0.5710001
305           1 0.1073091
306           1 0.3887622
307           1 0.9774780
308           1 0.2214520
309           1 0.2200633
310           1 0.2821710
311           1 0.1192212
312          NA        NA
313           1 0.2844474
314           1 0.6442756
315           1 0.9603550
316           1 0.0710950
317           1 0.0379185
318           1 0.0404609
319           1 0.4169248
320           1 0.2522641
321           1 0.1085932
322           1 0.8608794
323           1 0.1513924
324           1 0.5488798
325           1 0.5107245
326          NA        NA
327           1 0.6829778
328           1 0.7484398
329           1 0.9525185
330           1 0.3626146
331           1 0.3462935
332           1 0.4542303
333          NA        NA
334           1 0.5290917
335           1 0.0028212
336           1 0.8618734
337           1 0.5568857
338          NA        NA
339           1 0.9503260
340           1 0.9001683
341           1 0.6939464
342          NA        NA
343           1 0.4631887
344          NA        NA
345           1 0.4391008
346           1 0.9699211
347           1 0.2795489
348           1 0.9794688
349           1 0.6829252
350           1 0.9080061
351           1 0.6699789
352           1 0.4130646
353           1 0.9313862
354           1 0.1491589
355           1 0.0170217
356           1 0.5765008
357          NA        NA
358           1 0.2893665
359           1 0.2764026
360           1 0.6083384
361          NA        NA
362           1 0.2909836
363          NA        NA
364           1 0.8215426
365          NA        NA
366           1 0.9857181
367           1 0.6154459
368           1 0.8324757
369           1 0.2366159
370           1 0.7709013
371           1 0.0587736
372           1 0.5148996
373           1 0.8610126
374           1 0.9854021
375           1 0.3967623
376           1 0.4682836
377           1 0.4206555
378           1 0.9156348
379           1 0.4823144
380           1 0.9424083
381           1 0.1241789
382           1 0.5637079
383           1 0.7312367
384          NA        NA
385           1 0.6283556
386          NA        NA
387           1 0.0857619
388           1 0.6761968
389          NA        NA
390           1 0.0960991
391           1 0.3989047
392          NA        NA
393           1 0.7945677
394           1 0.6245364
395           1 0.4050144
396           1 0.0025873
397           1 0.6085804
398           1 0.5923369
399           1 0.9101575
400          NA        NA
401          NA        NA
402           1 0.2550940
403          NA        NA
404           1 0.5252544
405           1 0.4540667
406           1 0.5217224
407           1 0.0856974
408           1 0.5975495
409           1 0.6835156
410           1 0.5493564
411          NA        NA
412           1 0.2962362
413           1 0.2844997
414          NA        NA
415           1 0.1676721
416           1 0.9173871
417           1 0.9909104
418           1 0.7476684
419           1 0.4925386
420           1 0.9328098
421           1 0.6170390
422           1 0.3917041
423           1 0.1963780
424           1 0.7200789
425           1 0.9341721
426           1 0.6926439
427           1 0.8885809
428           1 0.2286659
429           1 0.5465690
430           1 0.2069992
431           1 0.5370498
432           1 0.9692778
433           1 0.8032339
434           1 0.2040468
435           1 0.4006469
436           1 0.8291249
437           1 0.4411270
438           1 0.3950532
439           1 0.0308887
440           1 0.1358661
441           1 0.6771844
442           1 0.0624881
443           1 0.9975382
444           1 0.1138490
445          NA        NA
446           1 0.0255866
447           1 0.1083096
448           1 0.4540834
449           1 0.8001914
450           1 0.8348242
451          NA        NA
452           1 0.2828215
453           1 0.6429027
454          NA        NA
455           1 0.5371090
456           1 0.4314533
457           1 0.7241187
458           1 0.1741241
459           1 0.3203244
460           1 0.3879777
461          NA        NA
462           1 0.2779246
463           1 0.7154538
464           1 0.3285461
465           1 0.6014551
466           1 0.5239208
467           1 0.8605491
468           1 0.5327693
469           1 0.1114219
470          NA        NA
471           1 0.0629398
472           1 0.7052853
473          NA        NA
474           1 0.7813167
475           1 0.7841393
476           1 0.5525757
477           1 0.8551084
478           1 0.2098720
479           1 0.2300553
480          NA        NA
481           1 0.4447834
482           1 0.6600653
483           1 0.0778219
484           1 0.3432483
485           1 0.8074548
486           1 0.3489754
487           1 0.0520824
488           1 0.8632828
489           1 0.5569195
490          NA        NA
491           1 0.7612966
492           1 0.5455418
493           1 0.4778820
494           1 0.3474314
495          NA        NA
496           1 0.9507692
497           1 0.2613790
498           1 0.1068054
499           1 0.2537579
500           1 0.1809039
attr(,"assign")
[1] 0 1
> all.equal( model.matrix( ss ), model.matrix( ss, part = "outcome" ) )
[1] TRUE
> model.matrix( ss, part = "selection" )
    (Intercept)         xs
1             1 0.38711299
2             1 0.87180502
3             1 0.96719705
4             1 0.86691627
5             1 0.43771530
6             1 0.19193779
7             1 0.08229440
8             1 0.58345164
9             1 0.07036150
10            1 0.52766266
11            1 0.47228829
12            1 0.04819137
13            1 0.59454081
14            1 0.79127122
15            1 0.59886868
16            1 0.02791593
17            1 0.39572663
18            1 0.10624396
19            1 0.02411139
20            1 0.84089777
21            1 0.32639993
22            1 0.29429765
23            1 0.82289798
24            1 0.41434742
25            1 0.01017122
26            1 0.05240839
27            1 0.73037038
28            1 0.07339495
29            1 0.07035663
30            1 0.63717197
31            1 0.41330587
32            1 0.43071783
33            1 0.08024637
34            1 0.27711668
35            1 0.79407102
36            1 0.09109747
37            1 0.27668218
38            1 0.13625546
39            1 0.66347610
40            1 0.97913002
41            1 0.21181133
42            1 0.37202698
43            1 0.11836472
44            1 0.78272381
45            1 0.06557821
46            1 0.78377509
47            1 0.12385221
48            1 0.77734167
49            1 0.36134907
50            1 0.61593001
51            1 0.91704273
52            1 0.10522010
53            1 0.71554579
54            1 0.15636656
55            1 0.26157572
56            1 0.77379137
57            1 0.59475907
58            1 0.09537672
59            1 0.15846793
60            1 0.70109071
61            1 0.26918273
62            1 0.29683006
63            1 0.56266529
64            1 0.34517651
65            1 0.99636331
66            1 0.21488963
67            1 0.59074720
68            1 0.40899105
69            1 0.53992893
70            1 0.80980688
71            1 0.01065314
72            1 0.67498956
73            1 0.88018155
74            1 0.40808877
75            1 0.89405213
76            1 0.80785131
77            1 0.05226842
78            1 0.95113947
79            1 0.49894035
80            1 0.49745918
81            1 0.20122201
82            1 0.68099732
83            1 0.54730418
84            1 0.60957774
85            1 0.30818300
86            1 0.16406116
87            1 0.84739973
88            1 0.17707073
89            1 0.58621073
90            1 0.97255655
91            1 0.53409931
92            1 0.81091625
93            1 0.65090651
94            1 0.77098111
95            1 0.03455832
96            1 0.55866028
97            1 0.12008737
98            1 0.68629963
99            1 0.91412566
100           1 0.56034976
101           1 0.57557604
102           1 0.51675016
103           1 0.65804858
104           1 0.58839658
105           1 0.07992458
106           1 0.15613625
107           1 0.98508137
108           1 0.99182980
109           1 0.29475619
110           1 0.78871246
111           1 0.68683107
112           1 0.40082666
113           1 0.39684114
114           1 0.88741394
115           1 0.82207810
116           1 0.26524504
117           1 0.18117087
118           1 0.95647407
119           1 0.83739984
120           1 0.34665263
121           1 0.84208644
122           1 0.01013018
123           1 0.21454192
124           1 0.91373498
125           1 0.04865535
126           1 0.87123094
127           1 0.65578801
128           1 0.21937188
129           1 0.00943714
130           1 0.07921450
131           1 0.76745085
132           1 0.03328786
133           1 0.77495206
134           1 0.39395963
135           1 0.78481726
136           1 0.03333230
137           1 0.36615158
138           1 0.20768844
139           1 0.96591254
140           1 0.56496601
141           1 0.44111595
142           1 0.80386812
143           1 0.16563328
144           1 0.20611856
145           1 0.34858668
146           1 0.45081491
147           1 0.10317673
148           1 0.60061846
149           1 0.10057791
150           1 0.95718611
151           1 0.58097444
152           1 0.16889438
153           1 0.51857113
154           1 0.05432284
155           1 0.29502327
156           1 0.03247447
157           1 0.41344840
158           1 0.71080473
159           1 0.43829422
160           1 0.47603035
161           1 0.37970472
162           1 0.77996834
163           1 0.96157720
164           1 0.44399841
165           1 0.27657652
166           1 0.65287494
167           1 0.75472404
168           1 0.58870638
169           1 0.36689807
170           1 0.50939103
171           1 0.14422911
172           1 0.26665454
173           1 0.17382091
174           1 0.89652730
175           1 0.56234313
176           1 0.34245432
177           1 0.28372968
178           1 0.74753848
179           1 0.56285019
180           1 0.56538600
181           1 0.63333183
182           1 0.96258659
183           1 0.76894120
184           1 0.76152418
185           1 0.15272215
186           1 0.36779797
187           1 0.91361579
188           1 0.49635015
189           1 0.02773473
190           1 0.45013939
191           1 0.02718772
192           1 0.01827093
193           1 0.87196248
194           1 0.95518889
195           1 0.89273842
196           1 0.85630873
197           1 0.12353308
198           1 0.22165474
199           1 0.69027218
200           1 0.64877213
201           1 0.09144519
202           1 0.59556958
203           1 0.94437824
204           1 0.12865765
205           1 0.52470189
206           1 0.93187571
207           1 0.44198207
208           1 0.40197161
209           1 0.36552250
210           1 0.57282998
211           1 0.10616740
212           1 0.65721383
213           1 0.80047916
214           1 0.16008114
215           1 0.49914981
216           1 0.13886577
217           1 0.68859821
218           1 0.48064193
219           1 0.20781287
220           1 0.71772134
221           1 0.33342107
222           1 0.52942738
223           1 0.59349875
224           1 0.75988901
225           1 0.03969591
226           1 0.63117995
227           1 0.17034981
228           1 0.70725659
229           1 0.26472227
230           1 0.08032245
231           1 0.71320727
232           1 0.75081412
233           1 0.17022553
234           1 0.21482216
235           1 0.13685529
236           1 0.32070479
237           1 0.65965331
238           1 0.45824660
239           1 0.22178384
240           1 0.04969162
241           1 0.84296750
242           1 0.46035598
243           1 0.04466906
244           1 0.33002011
245           1 0.35048202
246           1 0.23622100
247           1 0.20932283
248           1 0.28958497
249           1 0.29983004
250           1 0.89352400
251           1 0.76266063
252           1 0.10402937
253           1 0.75866955
254           1 0.41473379
255           1 0.22103568
256           1 0.00671870
257           1 0.03025054
258           1 0.25010184
259           1 0.22049498
260           1 0.30808099
261           1 0.90889258
262           1 0.93850277
263           1 0.49190460
264           1 0.16802027
265           1 0.18889455
266           1 0.19155522
267           1 0.50348194
268           1 0.08111215
269           1 0.79469655
270           1 0.57134723
271           1 0.96768789
272           1 0.87576877
273           1 0.70585316
274           1 0.11535468
275           1 0.16099235
276           1 0.33515433
277           1 0.98860919
278           1 0.91407894
279           1 0.53509718
280           1 0.24689369
281           1 0.92234682
282           1 0.75348962
283           1 0.90350731
284           1 0.65154816
285           1 0.02077916
286           1 0.09587903
287           1 0.94958696
288           1 0.88817659
289           1 0.45623399
290           1 0.78674386
291           1 0.20102676
292           1 0.31270320
293           1 0.52976181
294           1 0.18299944
295           1 0.53240564
296           1 0.34811359
297           1 0.51024816
298           1 0.79219569
299           1 0.44121055
300           1 0.28629224
301           1 0.93356032
302           1 0.03045106
303           1 0.84898560
304           1 0.44318272
305           1 0.63207523
306           1 0.77991436
307           1 0.28047391
308           1 0.12320406
309           1 0.89343319
310           1 0.40597330
311           1 0.75510823
312           1 0.11081726
313           1 0.33830931
314           1 0.54649319
315           1 0.31213205
316           1 0.44729456
317           1 0.40428107
318           1 0.48656426
319           1 0.43916804
320           1 0.26686363
321           1 0.65187784
322           1 0.23904947
323           1 0.81331562
324           1 0.80824450
325           1 0.58904475
326           1 0.54186686
327           1 0.04654761
328           1 0.42585569
329           1 0.64063982
330           1 0.00065635
331           1 0.86638836
332           1 0.10104517
333           1 0.09573974
334           1 0.77724037
335           1 0.02951141
336           1 0.34207188
337           1 0.78631587
338           1 0.11346253
339           1 0.35025276
340           1 0.33021388
341           1 0.69667667
342           1 0.35361430
343           1 0.40617907
344           1 0.30802990
345           1 0.95920293
346           1 0.69026885
347           1 0.88573951
348           1 0.93585514
349           1 0.74407990
350           1 0.83844616
351           1 0.79935678
352           1 0.89364029
353           1 0.83113700
354           1 0.37075010
355           1 0.87197977
356           1 0.80076160
357           1 0.17728454
358           1 0.16327769
359           1 0.94448911
360           1 0.44463760
361           1 0.07839259
362           1 0.98557162
363           1 0.01583822
364           1 0.49488251
365           1 0.42662624
366           1 0.38006543
367           1 0.73694438
368           1 0.27953835
369           1 0.65628387
370           1 0.77972610
371           1 0.72205251
372           1 0.98240604
373           1 0.54332272
374           1 0.65988784
375           1 0.27503936
376           1 0.39694412
377           1 0.55918458
378           1 0.98095030
379           1 0.96496678
380           1 0.21803987
381           1 0.39317087
382           1 0.73423125
383           1 0.69158886
384           1 0.33675154
385           1 0.69048167
386           1 0.15345024
387           1 0.89039881
388           1 0.88844603
389           1 0.13800335
390           1 0.03594922
391           1 0.35501715
392           1 0.37894608
393           1 0.61477670
394           1 0.50618944
395           1 0.33795513
396           1 0.32912965
397           1 0.57329704
398           1 0.05071004
399           1 0.40096299
400           1 0.26063104
401           1 0.16869968
402           1 0.05973101
403           1 0.05258214
404           1 0.97277025
405           1 0.79460759
406           1 0.03166770
407           1 0.54328481
408           1 0.01759703
409           1 0.77666990
410           1 0.75730149
411           1 0.01054815
412           1 0.81791408
413           1 0.85634588
414           1 0.42230970
415           1 0.63429571
416           1 0.41807503
417           1 0.32466435
418           1 0.76578723
419           1 0.70465551
420           1 0.91905136
421           1 0.61013655
422           1 0.05585486
423           1 0.73615214
424           1 0.90396792
425           1 0.70181488
426           1 0.57769951
427           1 0.56583925
428           1 0.36717551
429           1 0.55692171
430           1 0.89709017
431           1 0.27223061
432           1 0.82633317
433           1 0.67599566
434           1 0.89936691
435           1 0.29665981
436           1 0.38546442
437           1 0.90534968
438           1 0.78117641
439           1 0.54255092
440           1 0.82600849
441           1 0.92573612
442           1 0.30250844
443           1 0.36323521
444           1 0.96056095
445           1 0.41957629
446           1 0.56423950
447           1 0.80047633
448           1 0.47819496
449           1 0.87166353
450           1 0.70158742
451           1 0.12836664
452           1 0.65163356
453           1 0.79950837
454           1 0.24016515
455           1 0.86399533
456           1 0.47879486
457           1 0.32974162
458           1 0.99542562
459           1 0.75954221
460           1 0.47106496
461           1 0.25758437
462           1 0.38351123
463           1 0.29795361
464           1 0.76862628
465           1 0.42974047
466           1 0.65596690
467           1 0.24265688
468           1 0.29518460
469           1 0.92991936
470           1 0.13946574
471           1 0.48236118
472           1 0.80172571
473           1 0.33529812
474           1 0.54730093
475           1 0.05061376
476           1 0.68518484
477           1 0.52601657
478           1 0.38540146
479           1 0.21807817
480           1 0.04925604
481           1 0.33860385
482           1 0.52754284
483           1 0.36009953
484           1 0.99158904
485           1 0.04635811
486           1 0.07190189
487           1 0.67636723
488           1 0.16235961
489           1 0.58037379
490           1 0.09076585
491           1 0.65609916
492           1 0.35750658
493           1 0.19449135
494           1 0.68193416
495           1 0.03055500
496           1 0.43907404
497           1 0.97369032
498           1 0.41259327
499           1 0.91976987
500           1 0.09876388
attr(,"assign")
[1] 0 1
> model.frame( ss )
       ys         xs yo         xo
1    TRUE 0.38711299  0 0.32066701
2    TRUE 0.87180502  1 0.52601906
3    TRUE 0.96719705  0 0.07333542
4    TRUE 0.86691627  1 0.84974175
5    TRUE 0.43771530  1 0.42305801
6    TRUE 0.19193779  1 0.98809607
7   FALSE 0.08229440  0 0.47887413
8    TRUE 0.58345164  1 0.90569401
9    TRUE 0.07036150  0 0.01850593
10   TRUE 0.52766266  0 0.19214382
11   TRUE 0.47228829  1 0.38430702
12   TRUE 0.04819137  1 0.30743642
13   TRUE 0.59454081  1 0.52829125
14   TRUE 0.79127122  1 0.72822568
15   TRUE 0.59886868  1 0.95355653
16  FALSE 0.02791593  0 0.49599413
17   TRUE 0.39572663  0 0.13201725
18   TRUE 0.10624396  1 0.60846876
19   TRUE 0.02411139  1 0.99186858
20   TRUE 0.84089777  0 0.09470967
21   TRUE 0.32639993  1 0.89528346
22   TRUE 0.29429765  0 0.33486090
23   TRUE 0.82289798  0 0.47217847
24   TRUE 0.41434742  0 0.17711797
25   TRUE 0.01017122  0 0.35165503
26   TRUE 0.05240839  0 0.17655912
27   TRUE 0.73037038  1 0.65304578
28   TRUE 0.07339495  0 0.23610108
29   TRUE 0.07035663  1 0.89716400
30  FALSE 0.63717197  0 0.33914761
31   TRUE 0.41330587  1 0.92379611
32   TRUE 0.43071783  0 0.49773885
33  FALSE 0.08024637  0 0.56984138
34  FALSE 0.27711668  0 0.73677974
35   TRUE 0.79407102  0 0.21482752
36   TRUE 0.09109747  0 0.30531276
37   TRUE 0.27668218  1 0.86349986
38   TRUE 0.13625546  1 0.19572005
39   TRUE 0.66347610  1 0.85094550
40   TRUE 0.97913002  0 0.94697096
41   TRUE 0.21181133  1 0.27456111
42   TRUE 0.37202698  1 0.83985605
43  FALSE 0.11836472  0 0.14385577
44   TRUE 0.78272381  1 0.75705037
45   TRUE 0.06557821  1 0.44612657
46   TRUE 0.78377509  1 0.95543178
47   TRUE 0.12385221  0 0.63532506
48   TRUE 0.77734167  0 0.16410099
49   TRUE 0.36134907  1 0.40696944
50   TRUE 0.61593001  1 0.97976003
51   TRUE 0.91704273  0 0.14693906
52  FALSE 0.10522010  0 0.88998518
53   TRUE 0.71554579  0 0.19670349
54  FALSE 0.15636656  0 0.62058707
55   TRUE 0.26157572  1 0.79254099
56   TRUE 0.77379137  0 0.73379554
57   TRUE 0.59475907  1 0.75172034
58  FALSE 0.09537672  0 0.52445636
59  FALSE 0.15846793  0 0.62995162
60   TRUE 0.70109071  1 0.45587724
61   TRUE 0.26918273  0 0.25400483
62  FALSE 0.29683006  0 0.05748599
63   TRUE 0.56266529  1 0.43530320
64   TRUE 0.34517651  1 0.77113498
65   TRUE 0.99636331  0 0.12915545
66   TRUE 0.21488963  1 0.98391626
67   TRUE 0.59074720  1 0.81417693
68   TRUE 0.40899105  1 0.98168090
69   TRUE 0.53992893  0 0.03633969
70   TRUE 0.80980688  0 0.56741406
71   TRUE 0.01065314  1 0.40171827
72   TRUE 0.67498956  0 0.45704632
73   TRUE 0.88018155  0 0.40332439
74   TRUE 0.40808877  0 0.57220648
75   TRUE 0.89405213  0 0.26025095
76   TRUE 0.80785131  1 0.87408756
77   TRUE 0.05226842  1 0.99308725
78   TRUE 0.95113947  1 0.93020222
79   TRUE 0.49894035  1 0.98652805
80   TRUE 0.49745918  0 0.65834267
81   TRUE 0.20122201  0 0.30238535
82   TRUE 0.68099732  1 0.86742018
83   TRUE 0.54730418  1 0.67125956
84   TRUE 0.60957774  1 0.48919962
85   TRUE 0.30818300  0 0.62858391
86   TRUE 0.16406116  1 0.69066007
87   TRUE 0.84739973  0 0.67229149
88  FALSE 0.17707073  0 0.88211775
89   TRUE 0.58621073  0 0.68773820
90   TRUE 0.97255655  0 0.99986346
91   TRUE 0.53409931  0 0.25053633
92   TRUE 0.81091625  1 0.47846655
93   TRUE 0.65090651  0 0.01510070
94   TRUE 0.77098111  0 0.25201978
95   TRUE 0.03455832  1 0.32665814
96   TRUE 0.55866028  1 0.67213201
97   TRUE 0.12008737  1 0.74844130
98   TRUE 0.68629963  1 0.34243550
99   TRUE 0.91412566  0 0.28025983
100  TRUE 0.56034976  0 0.73737811
101  TRUE 0.57557604  0 0.62696940
102  TRUE 0.51675016  1 0.63354171
103  TRUE 0.65804858  1 0.21598149
104  TRUE 0.58839658  1 0.90594103
105 FALSE 0.07992458  0 0.58624594
106  TRUE 0.15613625  0 0.16858386
107  TRUE 0.98508137  0 0.68319769
108  TRUE 0.99182980  1 0.11399066
109 FALSE 0.29475619  0 0.52788504
110  TRUE 0.78871246  0 0.94150960
111  TRUE 0.68683107  0 0.14894644
112  TRUE 0.40082666  1 0.58912152
113  TRUE 0.39684114  0 0.87827645
114  TRUE 0.88741394  0 0.17815721
115  TRUE 0.82207810  1 0.47083355
116 FALSE 0.26524504  0 0.14146235
117  TRUE 0.18117087  1 0.09938261
118  TRUE 0.95647407  0 0.29035145
119  TRUE 0.83739984  0 0.24547600
120  TRUE 0.34665263  1 0.72255932
121  TRUE 0.84208644  0 0.53627455
122  TRUE 0.01013018  1 0.29900117
123 FALSE 0.21454192  0 0.19970041
124  TRUE 0.91373498  1 0.91017706
125  TRUE 0.04865535  0 0.03297120
126  TRUE 0.87123094  1 0.59632443
127  TRUE 0.65578801  1 0.15090501
128  TRUE 0.21937188  1 0.57764826
129  TRUE 0.00943714  1 0.45447665
130 FALSE 0.07921450  0 0.49380877
131  TRUE 0.76745085  1 0.52620712
132 FALSE 0.03328786  0 0.38301289
133  TRUE 0.77495206  1 0.92889790
134 FALSE 0.39395963  0 0.43341785
135  TRUE 0.78481726  0 0.24476248
136  TRUE 0.03333230  1 0.87625727
137  TRUE 0.36615158  0 0.18265992
138  TRUE 0.20768844  0 0.09032375
139  TRUE 0.96591254  1 0.23915987
140  TRUE 0.56496601  0 0.86143049
141  TRUE 0.44111595  0 0.83255551
142  TRUE 0.80386812  1 0.36291265
143  TRUE 0.16563328  1 0.18790714
144 FALSE 0.20611856  0 0.76874597
145  TRUE 0.34858668  0 0.44078845
146  TRUE 0.45081491  1 0.47670924
147 FALSE 0.10317673  0 0.98065696
148  TRUE 0.60061846  0 0.08918144
149 FALSE 0.10057791  0 0.09738549
150  TRUE 0.95718611  1 0.63566876
151  TRUE 0.58097444  1 0.19853899
152  TRUE 0.16889438  1 0.26160515
153  TRUE 0.51857113  0 0.31876233
154 FALSE 0.05432284  0 0.86957670
155  TRUE 0.29502327  0 0.05208858
156 FALSE 0.03247447  0 0.20391085
157  TRUE 0.41344840  1 0.57225858
158  TRUE 0.71080473  1 0.03690575
159  TRUE 0.43829422  0 0.01809226
160  TRUE 0.47603035  0 0.19654972
161  TRUE 0.37970472  0 0.34097749
162  TRUE 0.77996834  0 0.28365329
163  TRUE 0.96157720  1 0.18633407
164  TRUE 0.44399841  0 0.20442171
165 FALSE 0.27657652  0 0.23185302
166  TRUE 0.65287494  1 0.40610184
167  TRUE 0.75472404  1 0.86716951
168  TRUE 0.58870638  0 0.27581262
169  TRUE 0.36689807  1 0.75255450
170  TRUE 0.50939103  0 0.34063079
171  TRUE 0.14422911  1 0.96010333
172  TRUE 0.26665454  1 0.62854093
173  TRUE 0.17382091  1 0.84531320
174  TRUE 0.89652730  0 0.12228363
175  TRUE 0.56234313  0 0.55570733
176  TRUE 0.34245432  1 0.77642580
177  TRUE 0.28372968  0 0.25937937
178  TRUE 0.74753848  1 0.49898037
179  TRUE 0.56285019  1 0.58441675
180  TRUE 0.56538600  0 0.48475304
181  TRUE 0.63333183  1 0.60853986
182  TRUE 0.96258659  1 0.02086326
183  TRUE 0.76894120  0 0.38279984
184  TRUE 0.76152418  0 0.38161991
185  TRUE 0.15272215  0 0.06740730
186 FALSE 0.36779797  0 0.28922640
187  TRUE 0.91361579  1 0.76474291
188  TRUE 0.49635015  1 0.80158476
189  TRUE 0.02773473  0 0.20403125
190  TRUE 0.45013939  0 0.91786007
191 FALSE 0.02718772  0 0.10216107
192 FALSE 0.01827093  0 0.89088460
193  TRUE 0.87196248  1 0.51343123
194  TRUE 0.95518889  1 0.13278176
195  TRUE 0.89273842  1 0.33798232
196  TRUE 0.85630873  1 0.21300036
197 FALSE 0.12353308  0 0.82870218
198 FALSE 0.22165474  0 0.46433438
199  TRUE 0.69027218  0 0.33625348
200  TRUE 0.64877213  0 0.14465036
201 FALSE 0.09144519  0 0.86807104
202  TRUE 0.59556958  0 0.05432263
203  TRUE 0.94437824  0 0.61388308
204  TRUE 0.12865765  1 0.78563030
205  TRUE 0.52470189  1 0.57944665
206  TRUE 0.93187571  1 0.52716948
207  TRUE 0.44198207  0 0.41051341
208  TRUE 0.40197161  1 0.73052316
209  TRUE 0.36552250  1 0.88360006
210  TRUE 0.57282998  1 0.11447506
211 FALSE 0.10616740  0 0.32414774
212  TRUE 0.65721383  0 0.36675701
213  TRUE 0.80047916  0 0.25394857
214  TRUE 0.16008114  1 0.12074943
215  TRUE 0.49914981  1 0.58296751
216 FALSE 0.13886577  0 0.20343487
217  TRUE 0.68859821  0 0.57975232
218  TRUE 0.48064193  0 0.59064794
219  TRUE 0.20781287  1 0.97718666
220  TRUE 0.71772134  0 0.24612520
221  TRUE 0.33342107  1 0.47724220
222  TRUE 0.52942738  1 0.16024645
223  TRUE 0.59349875  1 0.78916870
224  TRUE 0.75988901  0 0.09574764
225 FALSE 0.03969591  0 0.48240387
226  TRUE 0.63117995  0 0.07575449
227 FALSE 0.17034981  0 0.93754979
228  TRUE 0.70725659  0 0.19411054
229  TRUE 0.26472227  0 0.71457881
230  TRUE 0.08032245  1 0.95579069
231  TRUE 0.71320727  1 0.74185807
232  TRUE 0.75081412  0 0.25603027
233 FALSE 0.17022553  0 0.61253227
234  TRUE 0.21482216  0 0.13281801
235  TRUE 0.13685529  0 0.18019323
236  TRUE 0.32070479  1 0.07993552
237  TRUE 0.65965331  0 0.27118114
238  TRUE 0.45824660  1 0.44012840
239  TRUE 0.22178384  1 0.71145823
240 FALSE 0.04969162  0 0.34678797
241  TRUE 0.84296750  0 0.15046814
242  TRUE 0.46035598  0 0.59950625
243  TRUE 0.04466906  1 0.89061833
244  TRUE 0.33002011  1 0.38870094
245 FALSE 0.35048202  0 0.09813411
246  TRUE 0.23622100  1 0.80721184
247  TRUE 0.20932283  0 0.11808428
248  TRUE 0.28958497  1 0.76426556
249  TRUE 0.29983004  0 0.12625433
250  TRUE 0.89352400  1 0.85453179
251  TRUE 0.76266063  1 0.53676871
252  TRUE 0.10402937  0 0.59619175
253  TRUE 0.75866955  1 0.86305423
254  TRUE 0.41473379  1 0.86743818
255  TRUE 0.22103568  0 0.05909328
256 FALSE 0.00671870  0 0.46948969
257  TRUE 0.03025054  1 0.34248170
258  TRUE 0.25010184  1 0.82457067
259  TRUE 0.22049498  1 0.52929045
260  TRUE 0.30808099  0 0.43723560
261  TRUE 0.90889258  0 0.05642579
262  TRUE 0.93850277  0 0.24777458
263  TRUE 0.49190460  1 0.39808635
264  TRUE 0.16802027  1 0.11121328
265 FALSE 0.18889455  0 0.42162257
266 FALSE 0.19155522  0 0.23918923
267  TRUE 0.50348194  1 0.85053229
268 FALSE 0.08111215  0 0.22702517
269 FALSE 0.79469655  0 0.74771232
270  TRUE 0.57134723  0 0.71771862
271  TRUE 0.96768789  0 0.09516487
272  TRUE 0.87576877  1 0.47922473
273  TRUE 0.70585316  0 0.12714205
274  TRUE 0.11535468  0 0.26423701
275  TRUE 0.16099235  0 0.22704179
276  TRUE 0.33515433  0 0.18450321
277  TRUE 0.98860919  0 0.01725596
278  TRUE 0.91407894  0 0.28163392
279  TRUE 0.53509718  0 0.12103989
280  TRUE 0.24689369  1 0.40642564
281  TRUE 0.92234682  1 0.78916786
282  TRUE 0.75348962  1 0.10586849
283  TRUE 0.90350731  0 0.34159462
284  TRUE 0.65154816  0 0.33359442
285 FALSE 0.02077916  0 0.77440194
286 FALSE 0.09587903  0 0.53716716
287  TRUE 0.94958696  1 0.78717149
288  TRUE 0.88817659  0 0.79758922
289  TRUE 0.45623399  0 0.22390589
290  TRUE 0.78674386  0 0.46615754
291  TRUE 0.20102676  0 0.32234397
292  TRUE 0.31270320  0 0.54453003
293  TRUE 0.52976181  0 0.97156943
294  TRUE 0.18299944  0 0.14930102
295  TRUE 0.53240564  0 0.36368281
296 FALSE 0.34811359  0 0.78710683
297  TRUE 0.51024816  0 0.58660913
298  TRUE 0.79219569  0 0.53978948
299  TRUE 0.44121055  1 0.87388601
300  TRUE 0.28629224  1 0.76942658
301  TRUE 0.93356032  0 0.45083750
302  TRUE 0.03045106  1 0.93905407
303  TRUE 0.84898560  1 0.55858905
304  TRUE 0.44318272  0 0.57100013
305  TRUE 0.63207523  0 0.10730912
306  TRUE 0.77991436  0 0.38876221
307  TRUE 0.28047391  1 0.97747801
308  TRUE 0.12320406  0 0.22145195
309  TRUE 0.89343319  0 0.22006326
310  TRUE 0.40597330  0 0.28217099
311  TRUE 0.75510823  0 0.11922118
312 FALSE 0.11081726  0 0.18013366
313  TRUE 0.33830931  0 0.28444742
314  TRUE 0.54649319  1 0.64427558
315  TRUE 0.31213205  1 0.96035503
316  TRUE 0.44729456  0 0.07109499
317  TRUE 0.40428107  0 0.03791847
318  TRUE 0.48656426  0 0.04046094
319  TRUE 0.43916804  1 0.41692480
320  TRUE 0.26686363  1 0.25226414
321  TRUE 0.65187784  0 0.10859324
322  TRUE 0.23904947  1 0.86087945
323  TRUE 0.81331562  0 0.15139242
324  TRUE 0.80824450  1 0.54887979
325  TRUE 0.58904475  1 0.51072452
326 FALSE 0.54186686  0 0.31056503
327  TRUE 0.04654761  1 0.68297776
328  TRUE 0.42585569  1 0.74843982
329  TRUE 0.64063982  1 0.95251846
330  TRUE 0.00065635  0 0.36261457
331  TRUE 0.86638836  0 0.34629353
332  TRUE 0.10104517  1 0.45423033
333 FALSE 0.09573974  0 0.66870470
334  TRUE 0.77724037  1 0.52909175
335  TRUE 0.02951141  1 0.00282119
336  TRUE 0.34207188  0 0.86187336
337  TRUE 0.78631587  0 0.55688567
338 FALSE 0.11346253  0 0.90191987
339  TRUE 0.35025276  1 0.95032597
340  TRUE 0.33021388  0 0.90016832
341  TRUE 0.69667667  1 0.69394645
342 FALSE 0.35361430  0 0.83622388
343  TRUE 0.40617907  0 0.46318871
344 FALSE 0.30802990  0 0.62909969
345  TRUE 0.95920293  1 0.43910083
346  TRUE 0.69026885  1 0.96992113
347  TRUE 0.88573951  0 0.27954889
348  TRUE 0.93585514  1 0.97946878
349  TRUE 0.74407990  1 0.68292520
350  TRUE 0.83844616  1 0.90800611
351  TRUE 0.79935678  1 0.66997889
352  TRUE 0.89364029  1 0.41306461
353  TRUE 0.83113700  0 0.93138624
354  TRUE 0.37075010  0 0.14915893
355  TRUE 0.87197977  0 0.01702166
356  TRUE 0.80076160  1 0.57650085
357 FALSE 0.17728454  0 0.50874104
358  TRUE 0.16327769  1 0.28936654
359  TRUE 0.94448911  0 0.27640259
360  TRUE 0.44463760  1 0.60833838
361 FALSE 0.07839259  0 0.39051814
362  TRUE 0.98557162  0 0.29098364
363 FALSE 0.01583822  0 0.38593572
364  TRUE 0.49488251  1 0.82154263
365 FALSE 0.42662624  0 0.23298005
366  TRUE 0.38006543  1 0.98571814
367  TRUE 0.73694438  0 0.61544585
368  TRUE 0.27953835  1 0.83247573
369  TRUE 0.65628387  0 0.23661593
370  TRUE 0.77972610  1 0.77090134
371  TRUE 0.72205251  0 0.05877355
372  TRUE 0.98240604  0 0.51489965
373  TRUE 0.54332272  1 0.86101260
374  TRUE 0.65988784  1 0.98540214
375  TRUE 0.27503936  1 0.39676226
376  TRUE 0.39694412  1 0.46828359
377  TRUE 0.55918458  0 0.42065552
378  TRUE 0.98095030  1 0.91563484
379  TRUE 0.96496678  1 0.48231438
380  TRUE 0.21803987  1 0.94240832
381  TRUE 0.39317087  1 0.12417886
382  TRUE 0.73423125  1 0.56370794
383  TRUE 0.69158886  1 0.73123671
384 FALSE 0.33675154  0 0.00057052
385  TRUE 0.69048167  1 0.62835559
386 FALSE 0.15345024  0 0.37072625
387  TRUE 0.89039881  0 0.08576187
388  TRUE 0.88844603  1 0.67619676
389 FALSE 0.13800335  0 0.60915775
390  TRUE 0.03594922  1 0.09609910
391  TRUE 0.35501715  1 0.39890471
392 FALSE 0.37894608  0 0.09832177
393  TRUE 0.61477670  1 0.79456769
394  TRUE 0.50618944  1 0.62453644
395  TRUE 0.33795513  0 0.40501441
396  TRUE 0.32912965  1 0.00258728
397  TRUE 0.57329704  1 0.60858040
398  TRUE 0.05071004  1 0.59233692
399  TRUE 0.40096299  1 0.91015745
400 FALSE 0.26063104  0 0.39395101
401 FALSE 0.16869968  0 0.96420028
402  TRUE 0.05973101  0 0.25509398
403 FALSE 0.05258214  0 0.14077180
404  TRUE 0.97277025  1 0.52525442
405  TRUE 0.79460759  0 0.45406666
406  TRUE 0.03166770  1 0.52172237
407  TRUE 0.54328481  0 0.08569740
408  TRUE 0.01759703  1 0.59754950
409  TRUE 0.77666990  0 0.68351564
410  TRUE 0.75730149  0 0.54935644
411 FALSE 0.01054815  0 0.62022547
412  TRUE 0.81791408  0 0.29623618
413  TRUE 0.85634588  1 0.28449972
414 FALSE 0.42230970  0 0.60198276
415  TRUE 0.63429571  0 0.16767212
416  TRUE 0.41807503  1 0.91738714
417  TRUE 0.32466435  1 0.99091042
418  TRUE 0.76578723  0 0.74766836
419  TRUE 0.70465551  0 0.49253861
420  TRUE 0.91905136  1 0.93280980
421  TRUE 0.61013655  1 0.61703900
422  TRUE 0.05585486  1 0.39170406
423  TRUE 0.73615214  1 0.19637799
424  TRUE 0.90396792  0 0.72007888
425  TRUE 0.70181488  1 0.93417207
426  TRUE 0.57769951  1 0.69264389
427  TRUE 0.56583925  0 0.88858093
428  TRUE 0.36717551  0 0.22866587
429  TRUE 0.55692171  0 0.54656895
430  TRUE 0.89709017  0 0.20699919
431  TRUE 0.27223061  0 0.53704978
432  TRUE 0.82633317  1 0.96927778
433  TRUE 0.67599566  1 0.80323391
434  TRUE 0.89936691  0 0.20404682
435  TRUE 0.29665981  1 0.40064686
436  TRUE 0.38546442  1 0.82912488
437  TRUE 0.90534968  0 0.44112702
438  TRUE 0.78117641  1 0.39505324
439  TRUE 0.54255092  0 0.03088869
440  TRUE 0.82600849  0 0.13586611
441  TRUE 0.92573612  1 0.67718442
442  TRUE 0.30250844  0 0.06248807
443  TRUE 0.36323521  1 0.99753821
444  TRUE 0.96056095  0 0.11384902
445 FALSE 0.41957629  0 0.62533250
446  TRUE 0.56423950  0 0.02558656
447  TRUE 0.80047633  0 0.10830961
448  TRUE 0.47819496  1 0.45408336
449  TRUE 0.87166353  1 0.80019144
450  TRUE 0.70158742  0 0.83482422
451 FALSE 0.12836664  0 0.72468771
452  TRUE 0.65163356  0 0.28282152
453  TRUE 0.79950837  1 0.64290270
454 FALSE 0.24016515  0 0.95878588
455  TRUE 0.86399533  1 0.53710904
456  TRUE 0.47879486  1 0.43145332
457  TRUE 0.32974162  1 0.72411874
458  TRUE 0.99542562  0 0.17412413
459  TRUE 0.75954221  1 0.32032438
460  TRUE 0.47106496  0 0.38797774
461 FALSE 0.25758437  0 0.05449391
462  TRUE 0.38351123  0 0.27792456
463  TRUE 0.29795361  0 0.71545379
464  TRUE 0.76862628  1 0.32854608
465  TRUE 0.42974047  1 0.60145515
466  TRUE 0.65596690  0 0.52392082
467  TRUE 0.24265688  1 0.86054913
468  TRUE 0.29518460  1 0.53276926
469  TRUE 0.92991936  0 0.11142191
470 FALSE 0.13946574  0 0.77589348
471  TRUE 0.48236118  1 0.06293980
472  TRUE 0.80172571  0 0.70528527
473 FALSE 0.33529812  0 0.04925588
474  TRUE 0.54730093  0 0.78131666
475  TRUE 0.05061376  0 0.78413926
476  TRUE 0.68518484  0 0.55257574
477  TRUE 0.52601657  1 0.85510841
478  TRUE 0.38540146  0 0.20987204
479  TRUE 0.21807817  0 0.23005525
480 FALSE 0.04925604  0 0.67341043
481  TRUE 0.33860385  1 0.44478336
482  TRUE 0.52754284  0 0.66006534
483  TRUE 0.36009953  1 0.07782189
484  TRUE 0.99158904  0 0.34324827
485  TRUE 0.04635811  1 0.80745480
486  TRUE 0.07190189  1 0.34897536
487  TRUE 0.67636723  0 0.05208240
488  TRUE 0.16235961  1 0.86328280
489  TRUE 0.58037379  0 0.55691945
490 FALSE 0.09076585  0 0.90995534
491  TRUE 0.65609916  0 0.76129663
492  TRUE 0.35750658  1 0.54554184
493  TRUE 0.19449135  1 0.47788200
494  TRUE 0.68193416  0 0.34743135
495 FALSE 0.03055500  0 0.56820780
496  TRUE 0.43907404  1 0.95076919
497  TRUE 0.97369032  0 0.26137901
498  TRUE 0.41259327  1 0.10680544
499  TRUE 0.91976987  1 0.25375792
500  TRUE 0.09876388  0 0.18090387
> logLik( ss )
'log Lik.' -398.2 (df=5)
> 
> # estimation with BFGS method
> ssBFGS <- selection( ys ~ xs, yo ~ xo, maxMethod = "BFGS" )
> print( ssBFGS )

Call:
 selection(selection = ys ~ xs, outcome = yo ~ xo, maxMethod = "BFGS") 

Coefficients:
S:(Intercept)           S:xs  O:(Intercept)           O:xo            rho  
       -0.127          3.339         -1.053          1.987          0.811  

> summary( ssBFGS )
--------------------------------------------
Tobit 2 model (sample selection model)
Maximum Likelihood estimation
BFGS maximisation, 77 iterations
Return code 0: successful convergence 
Log-Likelihood: -398.19 
500 observations (74 censored and 426 observed)
5 free parameters (df = 495)
Probit selection equation:
            Estimate Std. error t value Pr(> t)    
(Intercept)   -0.127      0.133   -0.96    0.34    
xs             3.339      0.397    8.40  <2e-16 ***
Outcome equation:
            Estimate Std. error t value Pr(> t)    
(Intercept)   -1.053      0.121   -8.69  <2e-16 ***
xo             1.987      0.225    8.83  <2e-16 ***
Error terms:
    Estimate Std. error t value Pr(> t)    
rho    0.811      0.147    5.51 3.6e-08 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
--------------------------------------------
> all.equal( coef( ssBFGS ), coef( ss ), tol = 1e-2 )
[1] TRUE
> all.equal( stdEr( ssBFGS ), stdEr( ss ), tol = 1e-1 )
[1] TRUE
> all.equal( vcov( ssBFGS ), vcov( ss ), tol = 1e-1 )
[1] TRUE
> nobs( ssBFGS )
[1] 500
> nObs( ssBFGS )
[1] 500
> all.equal( fitted( ss ), fitted( ssBFGS ), tol = 1e-2 )
[1] TRUE
> all.equal( fitted( ss, part = "selection" ),
+    fitted( ssBFGS, part = "selection" ), tol = 1e-2 )
[1] TRUE
> all.equal( fitted( ssBFGS ), fitted( ssBFGS, part = "outcome" ) )
[1] TRUE
> all.equal( residuals( ss ), residuals( ssBFGS ), tol = 1e-2 )
[1] TRUE
Warning messages:
1: In Ops.factor(oResponse, fitted(object)) : - not meaningful for factors
2: In Ops.factor(oResponse, fitted(object)) : - not meaningful for factors
> all.equal( residuals( ss, part = "selection" ),
+    residuals( ssBFGS, part = "selection" ), tol = 1e-2 )
[1] TRUE
> all.equal( residuals( ssBFGS ), residuals( ssBFGS, part = "outcome" ) )
[1] TRUE
Warning messages:
1: In Ops.factor(oResponse, fitted(object)) : - not meaningful for factors
2: In Ops.factor(oResponse, fitted(object)) : - not meaningful for factors
> all.equal( model.matrix( ss ), model.matrix( ssBFGS ) )
[1] TRUE
> all.equal( model.matrix( ss, part = "selection" ),
+    model.matrix( ssBFGS, part = "selection" ) )
[1] TRUE
> all.equal( model.matrix( ssBFGS ), model.matrix( ssBFGS, part = "outcome" ) )
[1] TRUE
> all.equal( logLik( ss ), logLik( ssBFGS ), tol = 1e-3 )
[1] TRUE
> 
> # BHHH estimation with equal weights
> we <- rep( 0.7, N )
> ssWe <- selection( ys ~ xs, yo ~ xo, weights = we, steptol = 1e-12 )
> summary( ssWe )
--------------------------------------------
Tobit 2 model (sample selection model)
Maximum Likelihood estimation
BHHH maximisation, 8 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -278.74 
500 observations (74 censored and 426 observed)
5 free parameters (df = 495)
Probit selection equation:
            Estimate Std. error t value Pr(> t)    
(Intercept)   -0.127      0.186   -0.69    0.49    
xs             3.342      0.561    5.96 2.5e-09 ***
Outcome equation:
            Estimate Std. error t value Pr(> t)    
(Intercept)   -1.057      0.178   -5.93 3.0e-09 ***
xo             2.000      0.315    6.35 2.2e-10 ***
Error terms:
    Estimate Std. error t value Pr(> t)    
rho    0.798      0.231    3.46 0.00055 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
--------------------------------------------
> all.equal( coef( ssWe ), coef( ss ), tol = 1e-2 )
[1] TRUE
> 
> # BHHH estimation with equal weights
> ssWeBFGS <- selection( ys ~ xs, yo ~ xo, weights = we, maxMethod = "BFGS" )
> summary( ssWeBFGS )
--------------------------------------------
Tobit 2 model (sample selection model)
Maximum Likelihood estimation
BFGS maximisation, 68 iterations
Return code 0: successful convergence 
Log-Likelihood: -278.74 
500 observations (74 censored and 426 observed)
5 free parameters (df = 495)
Probit selection equation:
            Estimate Std. error t value Pr(> t)    
(Intercept)   -0.122      0.158   -0.77    0.44    
xs             3.325      0.474    7.02 2.2e-12 ***
Outcome equation:
            Estimate Std. error t value Pr(> t)    
(Intercept)   -1.049      0.145   -7.24 4.6e-13 ***
xo             1.980      0.269    7.36 1.8e-13 ***
Error terms:
    Estimate Std. error t value Pr(> t)    
rho    0.807      0.181    4.45 8.5e-06 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
--------------------------------------------
> all.equal( coef( ssWeBFGS ), coef( ssBFGS ), tol = 1e-2 )
[1] TRUE
> 
> # BHHH estimation with unequal weights
> wu <- 2 * runif( N )
> ssWu <- selection( ys ~ xs, yo ~ xo, weights = wu )
> summary( ssWu )
--------------------------------------------
Tobit 2 model (sample selection model)
Maximum Likelihood estimation
BHHH maximisation, 26 iterations
Return code 1: gradient close to zero
Log-Likelihood: -395.66 
500 observations (74 censored and 426 observed)
5 free parameters (df = 495)
Probit selection equation:
            Estimate Std. error t value Pr(> t)    
(Intercept)   -0.111      0.102   -1.08    0.28    
xs             3.355      0.275   12.20  <2e-16 ***
Outcome equation:
            Estimate Std. error t value Pr(> t)    
(Intercept)   -1.069      0.106   -10.1  <2e-16 ***
xo             1.989      0.181    11.0  <2e-16 ***
Error terms:
    Estimate Std. error t value Pr(> t)    
rho   0.9572     0.0666    14.4  <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
--------------------------------------------
> 
> # BFGS estimation with unequal weights
> ssWuBFGS <- selection( ys ~ xs, yo ~ xo, weights = wu, maxMethod = "BFGS" )
> summary( ssWuBFGS )
--------------------------------------------
Tobit 2 model (sample selection model)
Maximum Likelihood estimation
BFGS maximisation, 48 iterations
Return code 0: successful convergence 
Log-Likelihood: -395.66 
500 observations (74 censored and 426 observed)
5 free parameters (df = 495)
Probit selection equation:
            Estimate Std. error t value Pr(> t)    
(Intercept)   -0.110      0.129   -0.85    0.39    
xs             3.355      0.387    8.66  <2e-16 ***
Outcome equation:
            Estimate Std. error t value Pr(> t)    
(Intercept)   -1.070      0.120   -8.93  <2e-16 ***
xo             1.992      0.215    9.27  <2e-16 ***
Error terms:
    Estimate Std. error t value Pr(> t)    
rho   0.9568     0.0633    15.1  <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
--------------------------------------------
> all.equal( coef( ssWuBFGS ), coef( ssWu ), tol = 1e-2 )
[1] TRUE
> 
> # comparison of estimated coefficients, standard errors, and logLik values
> round( rbind( coef( ss ), coef( ssBFGS ), coef( ssWe ), coef( ssWeBFGS ),
+    coef( ssWu ), coef( ssWuBFGS ) ), 3 )
     (Intercept)    xs (Intercept)    xo   rho
[1,]      -0.130 3.347      -1.054 1.997 0.803
[2,]      -0.127 3.339      -1.053 1.987 0.811
[3,]      -0.127 3.342      -1.057 2.000 0.798
[4,]      -0.122 3.325      -1.049 1.980 0.807
[5,]      -0.111 3.355      -1.069 1.989 0.957
[6,]      -0.110 3.355      -1.070 1.992 0.957
> round( rbind( coef( summary( ss ) )[ , 2 ], coef( summary( ssBFGS ) )[ , 2 ],
+    coef( summary( ssWe ) )[ , 2 ], coef( summary( ssWeBFGS ) )[ , 2 ],
+    coef( summary( ssWu ) )[ , 2 ], coef( summary( ssWuBFGS ) )[ , 2 ] ), 3 )
     (Intercept)    xs (Intercept)    xo   rho
[1,]       0.130 0.392       0.124 0.220 0.158
[2,]       0.133 0.397       0.121 0.225 0.147
[3,]       0.186 0.561       0.178 0.315 0.231
[4,]       0.158 0.474       0.145 0.269 0.181
[5,]       0.102 0.275       0.106 0.181 0.067
[6,]       0.129 0.387       0.120 0.215 0.063
> print( rbind( logLik( ss ), logLik( ssBFGS ), logLik( ssWe ),
+    logLik( ssWeBFGS ), logLik( ssWu ), logLik( ssWuBFGS ) ), digits = 6 )
         [,1]
[1,] -398.197
[2,] -398.192
[3,] -278.739
[4,] -278.737
[5,] -395.660
[6,] -395.660
> 
> # binary outcome NA if unobserved
> yo[ !ys ] <- NA
> print(table(ys, yo, exclude=NULL))
       yo
ys        0   1 <NA>
  FALSE   0   0   74
  TRUE  202 224    0
  <NA>    0   0    0
> ssN <- selection( ys ~ xs, yo ~ xo, steptol = 1e-12 )
> print(summary(ssN))
--------------------------------------------
Tobit 2 model (sample selection model)
Maximum Likelihood estimation
BHHH maximisation, 5 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -398.2 
500 observations (74 censored and 426 observed)
5 free parameters (df = 495)
Probit selection equation:
            Estimate Std. error t value Pr(> t)    
(Intercept)   -0.130      0.130   -1.00    0.32    
xs             3.347      0.392    8.54  <2e-16 ***
Outcome equation:
            Estimate Std. error t value Pr(> t)    
(Intercept)   -1.054      0.124   -8.47  <2e-16 ***
xo             1.997      0.220    9.07  <2e-16 ***
Error terms:
    Estimate Std. error t value Pr(> t)    
rho    0.803      0.158    5.07   4e-07 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
--------------------------------------------
> all.equal(ss,ssN)
[1] TRUE
> 
> # binary outcome logical
> yo <- yoX > 0 & ys
> print(table(ys, yo, exclude=NULL))
       yo
ys      FALSE TRUE <NA>
  FALSE    74    0    0
  TRUE    202  224    0
  <NA>      0    0    0
> ssL <- selection( ys ~ xs, yo ~ xo, steptol = 1e-12 )
> print(summary(ssL))
--------------------------------------------
Tobit 2 model (sample selection model)
Maximum Likelihood estimation
BHHH maximisation, 5 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -398.2 
500 observations (74 censored and 426 observed)
5 free parameters (df = 495)
Probit selection equation:
            Estimate Std. error t value Pr(> t)    
(Intercept)   -0.130      0.130   -1.00    0.32    
xs             3.347      0.392    8.54  <2e-16 ***
Outcome equation:
            Estimate Std. error t value Pr(> t)    
(Intercept)   -1.054      0.124   -8.47  <2e-16 ***
xo             1.997      0.220    9.07  <2e-16 ***
Error terms:
    Estimate Std. error t value Pr(> t)    
rho    0.803      0.158    5.07   4e-07 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
--------------------------------------------
> all.equal(ss,ssL)
[1] "Component \"twoStep\": Component \"lm\": Component \"model\": Attributes: < Component \"row.names\": Modes: numeric, character >"              
[2] "Component \"twoStep\": Component \"lm\": Component \"model\": Attributes: < Component \"row.names\": target is numeric, current is character >"
[3] "Component \"twoStep\": Component \"lm\": Component \"model\": Component \"YO\": Modes: numeric, logical"                                       
[4] "Component \"twoStep\": Component \"lm\": Component \"model\": Component \"YO\": names for current but not for target"                          
[5] "Component \"twoStep\": Component \"lm\": Component \"model\": Component \"YO\": target is numeric, current is logical"                         
> 
> # binary outcome logical and NA if unobserved
> yo[ !ys ] <- NA
> print(table(ys, yo, exclude=NULL))
       yo
ys      FALSE TRUE <NA>
  FALSE     0    0   74
  TRUE    202  224    0
  <NA>      0    0    0
> ssLN <- selection( ys ~ xs, yo ~ xo, steptol = 1e-12 )
> print(summary(ssLN))
--------------------------------------------
Tobit 2 model (sample selection model)
Maximum Likelihood estimation
BHHH maximisation, 5 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -398.2 
500 observations (74 censored and 426 observed)
5 free parameters (df = 495)
Probit selection equation:
            Estimate Std. error t value Pr(> t)    
(Intercept)   -0.130      0.130   -1.00    0.32    
xs             3.347      0.392    8.54  <2e-16 ***
Outcome equation:
            Estimate Std. error t value Pr(> t)    
(Intercept)   -1.054      0.124   -8.47  <2e-16 ***
xo             1.997      0.220    9.07  <2e-16 ***
Error terms:
    Estimate Std. error t value Pr(> t)    
rho    0.803      0.158    5.07   4e-07 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
--------------------------------------------
> all.equal(ssL,ssLN)
[1] TRUE
> 
> proc.time()
   user  system elapsed 
 66.067   0.163  66.283 
