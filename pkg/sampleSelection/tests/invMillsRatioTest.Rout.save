
R version 3.1.0 (2014-04-10) -- "Spring Dance"
Copyright (C) 2014 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> library( "sampleSelection" )
Loading required package: maxLik
Loading required package: miscTools

Please cite the 'maxLik' package as:
Henningsen, Arne and Toomet, Ott (2011). maxLik: A package for maximum likelihood estimation in R. Computational Statistics 26(3), 443-458. DOI 10.1007/s00180-010-0217-1.

If you have questions, suggestions, or comments regarding the 'maxLik' package, please use a forum or 'tracker' at maxLik's R-Forge site:
https://r-forge.r-project.org/projects/maxlik/
> options( digits = 3 )
> 
> ## Wooldridge( 2003 ): example 17.5, page 590
> data(Mroz87)
> myProbit <- glm( lfp ~ nwifeinc + educ + exper + I( exper^2 ) + age +
+       kids5 + kids618, family = binomial( link = "probit" ), data=Mroz87 )
> Mroz87$IMR <- invMillsRatio( myProbit )$IMR1
> myHeckit <- lm( log( wage ) ~ educ + exper + I( exper^2 ) + IMR,
+    data = Mroz87[ Mroz87$lfp == 1, ] )
> 
> # using NO labor force participation as endogenous variable
> Mroz87$nolfp <- 1 - Mroz87$lfp
> myProbit2 <- glm( nolfp ~ nwifeinc + educ + exper + I( exper^2 ) + age +
+       kids5 + kids618, family = binomial( link = "probit" ), data=Mroz87 )
> all.equal( invMillsRatio( myProbit )$IMR1, invMillsRatio( myProbit2 )$IMR0 )
[1] TRUE
> # should be true
> 
> # example for bivariate probit
> library( "mvtnorm" )
> library( "VGAM" )
Loading required package: splines
Loading required package: stats4

Attaching package: 'VGAM'

The following object is masked from 'package:stats4':

    coef

The following objects are masked from 'package:splines':

    bs, ns

The following object is masked from 'package:sampleSelection':

    probit

The following objects are masked from 'package:stats':

    case.names, coef, coefficients, df.residual, dfbeta, fitted,
    fitted.values, formula, hatvalues, poly, residuals, variable.names,
    weights

The following objects are masked from 'package:base':

    identity, scale.default

> 
> nObs <- 10000
> 
> # error terms (trivariate normal)
> sigma <- symMatrix( c( 2, 0.7, 1.2, 1, 0.5, 1 ) )
> myData <- as.data.frame( rmvnorm( nObs, c( 0, 0, 0 ), sigma ) )
> names( myData ) <- c( "e0", "e1", "e2" )
> 
> # exogenous variables (indepently normal)
> myData$x0 <- rnorm( nObs )
> myData$x1 <- rnorm( nObs )
> myData$x2 <- rnorm( nObs )
> 
> # endogenous variables
> myData$y0 <-   -1.5 + 0.8 * myData$x1 + myData$e0
> myData$y1 <- (  0.3 + 0.4 * myData$x1 + 0.3 * myData$x2 + myData$e1 ) > 0
> myData$y2 <- ( -0.1 + 0.6 * myData$x1 + 0.7 * myData$x2 + myData$e2 ) > 0
> 
> # bivariate probit (using rhobit transformation)
> bProbit <- vglm( cbind( y1, y2 ) ~ x1 + x2, family = binom2.rho,
+    data = myData )
> summary( bProbit )

Call:
vglm(formula = cbind(y1, y2) ~ x1 + x2, family = binom2.rho, 
    data = myData)

Pearson residuals:
            Min   1Q Median  3Q Max
probit(mu1)  -5 -0.9    0.4 0.7   4
probit(mu2)  -9 -0.6   -0.1 0.7   9
rhobit(rho) -10 -0.6    0.2 0.5   8

Coefficients:
              Estimate Std. Error z value
(Intercept):1     0.31       0.01      23
(Intercept):2    -0.08       0.01      -6
(Intercept):3     1.18       0.04      29
x1:1              0.41       0.01      29
x1:2              0.61       0.02      38
x2:1              0.31       0.01      23
x2:2              0.71       0.02      43

Number of linear predictors:  3 

Names of linear predictors: probit(mu1), probit(mu2), rhobit(rho)

Dispersion Parameter for binom2.rho family:   1

Log-likelihood: -10644 on 29993 degrees of freedom

Number of iterations: 3 
> 
> # bivariate probit (NOT using rhobit transformation)
> bProbit2 <- vglm( cbind( y1, y2 ) ~ x1 + x2, family = binom2.rho(
+    lrho = "identity" ), data = myData )
> summary( bProbit2 )

Call:
vglm(formula = cbind(y1, y2) ~ x1 + x2, family = binom2.rho(lrho = "identity"), 
    data = myData)

Pearson residuals:
            Min   1Q Median  3Q Max
probit(mu1)  -5 -0.9    0.4 0.7   4
probit(mu2)  -9 -0.6   -0.1 0.7   8
rho         -11 -0.5    0.2 0.5   7

Coefficients:
              Estimate Std. Error z value
(Intercept):1     0.31       0.01      23
(Intercept):2    -0.08       0.01      -6
(Intercept):3     0.53       0.01      36
x1:1              0.41       0.01      29
x1:2              0.61       0.02      38
x2:1              0.31       0.01      23
x2:2              0.71       0.02      43

Number of linear predictors:  3 

Names of linear predictors: probit(mu1), probit(mu2), rho

Dispersion Parameter for binom2.rho family:   1

Log-likelihood: -10644 on 29993 degrees of freedom

Number of iterations: 3 
> 
> # inverse Mills Ratios
> imr  <- invMillsRatio( bProbit )
> imr2 <- invMillsRatio( bProbit2 )
> all.equal( imr, imr2, tolerance = .Machine$double.eps ^ 0.25)
[1] TRUE
> 
> # tests
> # E[ e0 | y1* > 0 & y2* > 0 ]
> mean( myData$e0[ myData$y1 & myData$y2 ] )
[1] 0.822
> mean( sigma[1,2] * imr$IMR11a + sigma[1,3] * imr$IMR11b, na.rm = TRUE )
[1] 0.807
> # E[ e0 | y1* > 0 & y2* <= 0 ]
> mean( myData$e0[ myData$y1 & !myData$y2 ] )
[1] -0.33
> mean( sigma[1,2] * imr$IMR10a + sigma[1,3] * imr$IMR10b, na.rm = TRUE )
[1] -0.376
> # E[ e0 | y1* <= 0 & y2* > 0 ]
> mean( myData$e0[ !myData$y1 & myData$y2 ] )
[1] 0.325
> mean( sigma[1,2] * imr$IMR01a + sigma[1,3] * imr$IMR01b, na.rm = TRUE )
[1] 0.353
> # E[ e0 | y1* <= 0 & y2* <= 0 ]
> mean( myData$e0[ !myData$y1 & !myData$y2 ] )
[1] -0.858
> mean( sigma[1,2] * imr$IMR00a + sigma[1,3] * imr$IMR00b, na.rm = TRUE )
[1] -0.852
> # E[ e0 | y1* > 0 ]
> mean( myData$e0[ myData$y1 ] )
[1] 0.419
> mean( sigma[1,2] * imr$IMR1X, na.rm = TRUE )
[1] 0.393
> # E[ e0 | y1* <= 0 ]
> mean( myData$e0[ !myData$y1 ] )
[1] -0.618
> mean( sigma[1,2] * imr$IMR0X, na.rm = TRUE )
[1] -0.608
> # E[ e0 | y2* > 0 ]
> mean( myData$e0[ myData$y2 ] )
[1] 0.738
> mean( sigma[1,3] * imr$IMRX1, na.rm = TRUE )
[1] 0.731
> # E[ e0 | y2* <= 0 ]
> mean( myData$e0[ !myData$y2 ] )
[1] -0.644
> mean( sigma[1,3] * imr$IMRX0, na.rm = TRUE )
[1] -0.66
> 
> # estimation for y1* > 0 and y2* > 0
> selection <- myData$y1 & myData$y2
> # OLS estimation
> ols11 <- lm( y0 ~ x1, data = myData, subset = selection )
> summary( ols11 )

Call:
lm(formula = y0 ~ x1, data = myData, subset = selection)

Residuals:
   Min     1Q Median     3Q    Max 
-4.112 -0.805 -0.019  0.785  4.330 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  -0.5379     0.0209   -25.8   <2e-16 ***
x1            0.4762     0.0202    23.6   <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 1.19 on 3946 degrees of freedom
Multiple R-squared:  0.123,	Adjusted R-squared:  0.123 
F-statistic:  556 on 1 and 3946 DF,  p-value: <2e-16

> # heckman type estimation
> heckit11 <- lm( y0 ~ x1 + IMR11a + IMR11b, data = cbind( myData, imr ),
+    subset = selection )
> summary( heckit11 )

Call:
lm(formula = y0 ~ x1 + IMR11a + IMR11b, data = cbind(myData, 
    imr), subset = selection)

Residuals:
   Min     1Q Median     3Q    Max 
-3.699 -0.754 -0.047  0.686  4.861 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept) -1.26829    0.22116   -5.73  1.1e-08 ***
x1           0.72698    0.05764   12.61  < 2e-16 ***
IMR11a      -0.00532    0.73397   -0.01     0.99    
IMR11b       1.28857    0.10748   11.99  < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 1.13 on 3944 degrees of freedom
Multiple R-squared:  0.214,	Adjusted R-squared:  0.214 
F-statistic:  359 on 3 and 3944 DF,  p-value: <2e-16

> 
> # estimation for y1* > 0 and y2* <= 0
> selection <- myData$y1 & !myData$y2
> # OLS estimation
> ols10 <- lm( y0 ~ x1, data = myData, subset = selection )
> summary( ols10 )

Call:
lm(formula = y0 ~ x1, data = myData, subset = selection)

Residuals:
   Min     1Q Median     3Q    Max 
-3.945 -0.719  0.004  0.736  3.690 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  -1.8824     0.0245   -76.8   <2e-16 ***
x1            0.4406     0.0271    16.2   <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 1.12 on 2123 degrees of freedom
Multiple R-squared:  0.11,	Adjusted R-squared:  0.11 
F-statistic:  264 on 1 and 2123 DF,  p-value: <2e-16

> # heckman type estimation
> heckit10 <- lm( y0 ~ x1 + IMR10a + IMR10b, data = cbind( myData, imr ),
+    subset = selection )
> summary( heckit10 )

Call:
lm(formula = y0 ~ x1 + IMR10a + IMR10b, data = cbind(myData, 
    imr), subset = selection)

Residuals:
   Min     1Q Median     3Q    Max 
-3.574 -0.613  0.027  0.681  2.876 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)   -1.474      0.510   -2.89   0.0039 ** 
x1             0.845      0.067   12.62   <2e-16 ***
IMR10a         0.717      0.467    1.53   0.1253    
IMR10b         1.188      0.076   15.62   <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.995 on 2121 degrees of freedom
Multiple R-squared:  0.292,	Adjusted R-squared:  0.291 
F-statistic:  292 on 3 and 2121 DF,  p-value: <2e-16

> 
> # estimation for y1* <= 0 and y2* > 0
> selection <- !myData$y1 & myData$y2
> # OLS estimation
> ols01 <- lm( y0 ~ x1, data = myData, subset = selection )
> summary( ols01 )

Call:
lm(formula = y0 ~ x1, data = myData, subset = selection)

Residuals:
   Min     1Q Median     3Q    Max 
-3.558 -0.731 -0.023  0.751  4.334 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  -1.1375     0.0383  -29.73  < 2e-16 ***
x1            0.3277     0.0402    8.15  1.4e-15 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 1.08 on 795 degrees of freedom
Multiple R-squared:  0.0771,	Adjusted R-squared:  0.076 
F-statistic: 66.4 on 1 and 795 DF,  p-value: 1.4e-15

> # heckman type estimation
> heckit01 <- lm( y0 ~ x1 + IMR01a + IMR01b, data = cbind( myData, imr ),
+    subset = selection )
> summary( heckit01 )

Call:
lm(formula = y0 ~ x1 + IMR01a + IMR01b, data = cbind(myData, 
    imr), subset = selection)

Residuals:
   Min     1Q Median     3Q    Max 
-2.611 -0.672  0.015  0.602  4.303 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  -3.5802     1.7628   -2.03  0.04259 *  
x1            0.5620     0.1644    3.42  0.00066 ***
IMR01a       -0.5395     1.0596   -0.51  0.61078    
IMR01b        1.2648     0.0956   13.23  < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.936 on 793 degrees of freedom
Multiple R-squared:  0.304,	Adjusted R-squared:  0.302 
F-statistic:  116 on 3 and 793 DF,  p-value: <2e-16

> 
> # estimation for y1* <= 0 and y2* <= 0
> selection <- !myData$y1 & !myData$y2
> # OLS estimation
> ols00 <- lm( y0 ~ x1, data = myData, subset = selection )
> summary( ols00 )

Call:
lm(formula = y0 ~ x1, data = myData, subset = selection)

Residuals:
   Min     1Q Median     3Q    Max 
-4.151 -0.791  0.015  0.817  4.078 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  -2.4889     0.0243  -102.5   <2e-16 ***
x1            0.5274     0.0231    22.9   <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 1.21 on 3128 degrees of freedom
Multiple R-squared:  0.143,	Adjusted R-squared:  0.143 
F-statistic:  522 on 1 and 3128 DF,  p-value: <2e-16

> # heckman type estimation
> heckit00 <- lm( y0 ~ x1 + IMR00a + IMR00b, data = cbind( myData, imr ),
+    subset = selection )
> summary( heckit00 )

Call:
lm(formula = y0 ~ x1 + IMR00a + IMR00b, data = cbind(myData, 
    imr), subset = selection)

Residuals:
   Min     1Q Median     3Q    Max 
-4.596 -0.717  0.043  0.777  3.563 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  -1.3249     0.2413   -5.49  4.3e-08 ***
x1            0.8464     0.0507   16.71  < 2e-16 ***
IMR00a        0.9421     0.3751    2.51    0.012 *  
IMR00b        1.1808     0.1501    7.87  4.9e-15 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 1.15 on 3126 degrees of freedom
Multiple R-squared:  0.218,	Adjusted R-squared:  0.217 
F-statistic:  291 on 3 and 3126 DF,  p-value: <2e-16

> 
> # estimation for y1* > 0
> selection <- myData$y1
> # OLS estimation
> ols1X <- lm( y0 ~ x1, data = myData, subset = selection )
> summary( ols1X )

Call:
lm(formula = y0 ~ x1, data = myData, subset = selection)

Residuals:
   Min     1Q Median     3Q    Max 
-4.772 -0.889 -0.017  0.890  4.710 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  -1.0482     0.0174   -60.3   <2e-16 ***
x1            0.6567     0.0176    37.4   <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 1.32 on 6071 degrees of freedom
Multiple R-squared:  0.187,	Adjusted R-squared:  0.187 
F-statistic: 1.4e+03 on 1 and 6071 DF,  p-value: <2e-16

> # heckman type estimation
> heckit1X <- lm( y0 ~ x1 + IMR1X, data = cbind( myData, imr ),
+    subset = selection )
> summary( heckit1X )

Call:
lm(formula = y0 ~ x1 + IMR1X, data = cbind(myData, imr), subset = selection)

Residuals:
   Min     1Q Median     3Q    Max 
-4.696 -0.887 -0.017  0.878  4.944 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  -1.4919     0.0651  -22.93  < 2e-16 ***
x1            0.8048     0.0273   29.50  < 2e-16 ***
IMR1X         0.7295     0.1031    7.07  1.7e-12 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 1.31 on 6070 degrees of freedom
Multiple R-squared:  0.194,	Adjusted R-squared:  0.194 
F-statistic:  730 on 2 and 6070 DF,  p-value: <2e-16

> 
> # estimation for y1* <= 0
> selection <- !myData$y1
> # OLS estimation
> ols0X <- lm( y0 ~ x1, data = myData, subset = selection )
> summary( ols0X )

Call:
lm(formula = y0 ~ x1, data = myData, subset = selection)

Residuals:
   Min     1Q Median     3Q    Max 
-4.555 -0.862 -0.008  0.857  5.321 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  -2.1847     0.0222   -98.5   <2e-16 ***
x1            0.6178     0.0215    28.8   <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 1.3 on 3925 degrees of freedom
Multiple R-squared:  0.174,	Adjusted R-squared:  0.174 
F-statistic:  827 on 1 and 3925 DF,  p-value: <2e-16

> # heckman type estimation
> heckit0X <- lm( y0 ~ x1 + IMR0X, data = cbind( myData, imr ),
+    subset = selection )
> summary( heckit0X )

Call:
lm(formula = y0 ~ x1 + IMR0X, data = cbind(myData, imr), subset = selection)

Residuals:
   Min     1Q Median     3Q    Max 
-4.533 -0.844 -0.002  0.861  5.247 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  -1.4707     0.1019  -14.43  < 2e-16 ***
x1            0.8008     0.0333   24.08  < 2e-16 ***
IMR0X         0.7451     0.1038    7.18  8.6e-13 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 1.29 on 3924 degrees of freedom
Multiple R-squared:  0.185,	Adjusted R-squared:  0.184 
F-statistic:  445 on 2 and 3924 DF,  p-value: <2e-16

> 
> # estimation for y2* > 0
> selection <- myData$y2
> # OLS estimation
> olsX1 <- lm( y0 ~ x1, data = myData, subset = selection )
> summary( olsX1 )

Call:
lm(formula = y0 ~ x1, data = myData, subset = selection)

Residuals:
   Min     1Q Median     3Q    Max 
-4.004 -0.814 -0.012  0.787  4.430 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  -0.6439     0.0186   -34.5   <2e-16 ***
x1            0.4851     0.0183    26.5   <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 1.19 on 4743 degrees of freedom
Multiple R-squared:  0.129,	Adjusted R-squared:  0.129 
F-statistic:  704 on 1 and 4743 DF,  p-value: <2e-16

> # heckman type estimation
> heckitX1 <- lm( y0 ~ x1 + IMRX1, data = cbind( myData, imr ),
+    subset = selection )
> summary( heckitX1 )

Call:
lm(formula = y0 ~ x1 + IMRX1, data = cbind(myData, imr), subset = selection)

Residuals:
   Min     1Q Median     3Q    Max 
-3.586 -0.760 -0.043  0.686  5.031 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  -1.4820     0.0386   -38.3   <2e-16 ***
x1            0.7749     0.0210    37.0   <2e-16 ***
IMRX1         1.1979     0.0492    24.4   <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 1.13 on 4742 degrees of freedom
Multiple R-squared:  0.226,	Adjusted R-squared:  0.226 
F-statistic:  692 on 2 and 4742 DF,  p-value: <2e-16

> 
> # estimation for y2* <= 0
> selection <- !myData$y2
> # OLS estimation
> olsX0 <- lm( y0 ~ x1, data = myData, subset = selection )
> summary( olsX0 )

Call:
lm(formula = y0 ~ x1, data = myData, subset = selection)

Residuals:
   Min     1Q Median     3Q    Max 
-4.438 -0.782  0.011  0.799  4.193 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  -2.2299     0.0178  -125.2   <2e-16 ***
x1            0.5525     0.0179    30.9   <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 1.21 on 5253 degrees of freedom
Multiple R-squared:  0.153,	Adjusted R-squared:  0.153 
F-statistic:  951 on 1 and 5253 DF,  p-value: <2e-16

> # heckman type estimation
> heckitX0 <- lm( y0 ~ x1 + IMRX0, data = cbind( myData, imr ),
+    subset = selection )
> summary( heckitX0 )

Call:
lm(formula = y0 ~ x1 + IMRX0, data = cbind(myData, imr), subset = selection)

Residuals:
   Min     1Q Median     3Q    Max 
-4.831 -0.724  0.063  0.771  3.819 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  -1.4663     0.0351   -41.8   <2e-16 ***
x1            0.8306     0.0203    40.9   <2e-16 ***
IMRX0         1.2142     0.0489    24.8   <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 1.15 on 5252 degrees of freedom
Multiple R-squared:  0.242,	Adjusted R-squared:  0.242 
F-statistic:  839 on 2 and 5252 DF,  p-value: <2e-16

> 
> proc.time()
   user  system elapsed 
 10.576   0.094  10.655 
